{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29a61aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "577d6e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge_score in /opt/conda/lib/python3.9/site-packages (0.1.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from rouge_score) (1.21.4)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.9/site-packages (from rouge_score) (3.6.5)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.9/site-packages (from rouge_score) (0.12.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.9/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (4.62.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (2021.11.10)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (8.0.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (1.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: datasets==1.0.2 in /opt/conda/lib/python3.9/site-packages (1.0.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (1.3.3)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (0.3.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (2.0.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (1.21.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (2.26.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (4.62.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (3.4.0)\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (6.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.0.2) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.0.2) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.0.2) (2.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.0.2) (2.10)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets==1.0.2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets==1.0.2) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->datasets==1.0.2) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: transformers==4.24.0 in /opt/conda/lib/python3.9/site-packages (4.24.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (3.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (0.10.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (0.13.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (2021.11.10)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (1.21.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (2.26.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.24.0) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->transformers==4.24.0) (3.0.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.24.0) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.24.0) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.24.0) (2.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.24.0) (2021.10.8)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: transformer-utils in /opt/conda/lib/python3.9/site-packages (0.1.1)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.9/site-packages (from transformer-utils) (1.9.1+cu111)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.9/site-packages (from transformer-utils) (0.11.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from transformer-utils) (4.62.3)\n",
      "Requirement already satisfied: colorcet in /opt/conda/lib/python3.9/site-packages (from transformer-utils) (3.0.1)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.9/site-packages (from transformer-utils) (4.24.0)\n",
      "Requirement already satisfied: pyct>=0.4.4 in /opt/conda/lib/python3.9/site-packages (from colorcet->transformer-utils) (0.4.8)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.9/site-packages (from seaborn->transformer-utils) (1.21.4)\n",
      "Requirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.9/site-packages (from seaborn->transformer-utils) (1.3.3)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /opt/conda/lib/python3.9/site-packages (from seaborn->transformer-utils) (3.4.3)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.9/site-packages (from seaborn->transformer-utils) (1.7.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch->transformer-utils) (4.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (0.13.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (2.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (2021.11.10)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (0.10.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (3.4.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (8.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (3.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.23->seaborn->transformer-utils) (2021.3)\n",
      "Requirement already satisfied: param>=1.7.0 in /opt/conda/lib/python3.9/site-packages (from pyct>=0.4.4->colorcet->transformer-utils) (1.12.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers->transformer-utils) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->transformers->transformer-utils) (2.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers->transformer-utils) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers->transformer-utils) (1.26.12)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn->transformer-utils) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging) (3.0.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.9/site-packages (0.13.5)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (3.1.29)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (3.19.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from wandb) (59.4.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (8.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (2.26.0)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (1.11.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.9/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.9/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.9/site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (1.0.11)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.9/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.0.8)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score\n",
    "!pip install datasets==1.0.2\n",
    "!pip install transformers==4.24.0\n",
    "!pip install transformer-utils\n",
    "!pip install packaging\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89963c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "import datasets\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    LineByLineTextDataset\n",
    "\n",
    ")\n",
    "\n",
    "from transformers import RobertaTokenizerFast\n",
    "from transformers import EncoderDecoderModel\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21dcc80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoints = \"gogamza/kobart-base-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90588f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.data.datasets.language_modeling.LineByLineTextDataset"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa6f59a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train_total.csv')\n",
    "val_df = pd.read_csv('data/val_total.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "822e897f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fd321028-d5b4-55f7-9e20-2eaa262f9154</td>\n",
       "      <td>['ê·¸ëŸ¼ ë‚ ì§œëŠ” ê°€ê²© í° ë³€ë™ ì—†ìœ¼ë©´ 6.28-7.13ë¡œ í™•ì •í• ê¹Œ?', 'ìš°ë¦¬ ë¹„í–‰...</td>\n",
       "      <td>ë¹„í–‰ê¸° í‘œ ê°€ê²©ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ë©°, íŠ¹ê°€ ì´ë²¤íŠ¸ë¥¼ ê¸°ë‹¤ë¦¬ê³  ìˆë‹¤.</td>\n",
       "      <td>ìƒê±°ë˜(ì‡¼í•‘)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c51be2e4-c8d0-5cea-b1ae-cde1fe8f8ab6</td>\n",
       "      <td>['Kfë§ˆìŠ¤í¬ë§Œ 5ë¶€ì œ í•˜ëŠ”ê±°ì§€?', 'ì‘. ë©´ë§ˆìŠ¤í¬ëŠ” ì•„ë¬´ë•Œë‚˜ ì‚¬ë„ë ê»€?', 'ë©´...</td>\n",
       "      <td>ë¹„ì—¼ì´ ìˆì–´ì„œ ì‹¸ê²Œ ë‚˜ì˜¨ ì¼íšŒìš© ë¶€ì§í¬ ë§ˆìŠ¤í¬ë¥¼ ì‚¬ë‘ë ¤ê³  í•œë‹¤.</td>\n",
       "      <td>ìƒê±°ë˜(ì‡¼í•‘)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e90e721f-00d1-5114-aa5d-5f1061472a29</td>\n",
       "      <td>['ì•„ ê·¼ë° ì¼€ì´í¬ ì—…ì²´ë“¤ ë´¤ëŠ”ë° ì¤‘ì•™ë™ìª½ ê±°ê¸°ëŠ” ë§›ë§Œìˆê³  ë””ìì¸ì€ ê·¸ëƒ¥ê·¸ëŸ°ê²ƒê°™ì• '...</td>\n",
       "      <td>ì¼€ì´í¬ ì—…ì²´ ì¤‘ ì¤‘ì•™ë™ ìª½ì€ ë§›ë§Œ ìˆê³  ë””ìì¸ì€ ë³„ë¡œê³  ê³ ì”ë™ ì¼€ì´í¬ ì—…ì²´ëŠ” ë°°ë‹¬ë„...</td>\n",
       "      <td>ìƒê±°ë˜(ì‡¼í•‘)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b215f3a2-d647-59f9-8410-1274ee5edd97</td>\n",
       "      <td>['ì¹«ì†”ì‚¬ì•¼í•˜ëŠ”ë° ì“±ìœ¼ë¡œ ì‚´ê¹Œ?', 'ë­˜ ì¹«ì†”ì‚¬ëŠ”ê²ƒê¹Œì§€ ë¬¼ì–´ë³´ì‹œë‚¨ã…‹ã…‹ã…‹', 'ì•„ ê·¸...</td>\n",
       "      <td>ì¹«ì†”ì„ 3ê°œì›”ì— í•˜ë‚˜ì”© ë°”ê¿”ì„œ ì™• ì¹«ì†” ì‚¬ëŸ¬ ì‹ ì„¸ê³„(ì“±) ê°€ìê³  í–ˆë‹¤.</td>\n",
       "      <td>ìƒê±°ë˜(ì‡¼í•‘)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0bda61b6-1396-5a2a-a049-0b4035e40d59</td>\n",
       "      <td>['ì ë„ì•ˆì˜¤ë„¤ã…ì–¼ë¦‰ ê³ êµ¬ë§ˆì¸„ ë¨¹ê³ ì‹¶ë‹¨', 'ê·¸ê²Œ ê·¸ë ‡ê²Œ ë§›ìˆì—ˆì–´??? ì•„ì£¼ ì—¬ë³´ ë¹¼...</td>\n",
       "      <td>ì ë„ ì•ˆ ì™€ì„œ ê³ êµ¬ë§ˆ ë§ë­ì´ë¥¼ ì–‘ì‹¬ìƒ í•˜ë‚˜ë§Œ ë¨¹ìœ¼ë ¤ê³  í•œë‹¤.</td>\n",
       "      <td>ìƒê±°ë˜(ì‡¼í•‘)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id  \\\n",
       "0  fd321028-d5b4-55f7-9e20-2eaa262f9154   \n",
       "1  c51be2e4-c8d0-5cea-b1ae-cde1fe8f8ab6   \n",
       "2  e90e721f-00d1-5114-aa5d-5f1061472a29   \n",
       "3  b215f3a2-d647-59f9-8410-1274ee5edd97   \n",
       "4  0bda61b6-1396-5a2a-a049-0b4035e40d59   \n",
       "\n",
       "                                                Text  \\\n",
       "0  ['ê·¸ëŸ¼ ë‚ ì§œëŠ” ê°€ê²© í° ë³€ë™ ì—†ìœ¼ë©´ 6.28-7.13ë¡œ í™•ì •í• ê¹Œ?', 'ìš°ë¦¬ ë¹„í–‰...   \n",
       "1  ['Kfë§ˆìŠ¤í¬ë§Œ 5ë¶€ì œ í•˜ëŠ”ê±°ì§€?', 'ì‘. ë©´ë§ˆìŠ¤í¬ëŠ” ì•„ë¬´ë•Œë‚˜ ì‚¬ë„ë ê»€?', 'ë©´...   \n",
       "2  ['ì•„ ê·¼ë° ì¼€ì´í¬ ì—…ì²´ë“¤ ë´¤ëŠ”ë° ì¤‘ì•™ë™ìª½ ê±°ê¸°ëŠ” ë§›ë§Œìˆê³  ë””ìì¸ì€ ê·¸ëƒ¥ê·¸ëŸ°ê²ƒê°™ì• '...   \n",
       "3  ['ì¹«ì†”ì‚¬ì•¼í•˜ëŠ”ë° ì“±ìœ¼ë¡œ ì‚´ê¹Œ?', 'ë­˜ ì¹«ì†”ì‚¬ëŠ”ê²ƒê¹Œì§€ ë¬¼ì–´ë³´ì‹œë‚¨ã…‹ã…‹ã…‹', 'ì•„ ê·¸...   \n",
       "4  ['ì ë„ì•ˆì˜¤ë„¤ã…ì–¼ë¦‰ ê³ êµ¬ë§ˆì¸„ ë¨¹ê³ ì‹¶ë‹¨', 'ê·¸ê²Œ ê·¸ë ‡ê²Œ ë§›ìˆì—ˆì–´??? ì•„ì£¼ ì—¬ë³´ ë¹¼...   \n",
       "\n",
       "                                             Summary Category  \n",
       "0               ë¹„í–‰ê¸° í‘œ ê°€ê²©ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ë©°, íŠ¹ê°€ ì´ë²¤íŠ¸ë¥¼ ê¸°ë‹¤ë¦¬ê³  ìˆë‹¤.  ìƒê±°ë˜(ì‡¼í•‘)  \n",
       "1                ë¹„ì—¼ì´ ìˆì–´ì„œ ì‹¸ê²Œ ë‚˜ì˜¨ ì¼íšŒìš© ë¶€ì§í¬ ë§ˆìŠ¤í¬ë¥¼ ì‚¬ë‘ë ¤ê³  í•œë‹¤.  ìƒê±°ë˜(ì‡¼í•‘)  \n",
       "2  ì¼€ì´í¬ ì—…ì²´ ì¤‘ ì¤‘ì•™ë™ ìª½ì€ ë§›ë§Œ ìˆê³  ë””ìì¸ì€ ë³„ë¡œê³  ê³ ì”ë™ ì¼€ì´í¬ ì—…ì²´ëŠ” ë°°ë‹¬ë„...  ìƒê±°ë˜(ì‡¼í•‘)  \n",
       "3            ì¹«ì†”ì„ 3ê°œì›”ì— í•˜ë‚˜ì”© ë°”ê¿”ì„œ ì™• ì¹«ì†” ì‚¬ëŸ¬ ì‹ ì„¸ê³„(ì“±) ê°€ìê³  í–ˆë‹¤.  ìƒê±°ë˜(ì‡¼í•‘)  \n",
       "4                  ì ë„ ì•ˆ ì™€ì„œ ê³ êµ¬ë§ˆ ë§ë­ì´ë¥¼ ì–‘ì‹¬ìƒ í•˜ë‚˜ë§Œ ë¨¹ìœ¼ë ¤ê³  í•œë‹¤.  ìƒê±°ë˜(ì‡¼í•‘)  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12002e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id          279992\n",
      "Text        279992\n",
      "Summary     279992\n",
      "Category    279992\n",
      "dtype: int64\n",
      "Id          35004\n",
      "Text        35004\n",
      "Summary     35004\n",
      "Category    35004\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df.count())\n",
    "print(val_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80066445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ê°œì¸ ë° ê´€ê³„    71130\n",
       "ì£¼ê±°ì™€ ìƒí™œ     45179\n",
       "ì—¬ê°€ ìƒí™œ      35247\n",
       "ì‹ìŒë£Œ        30184\n",
       "ìƒê±°ë˜(ì‡¼í•‘)    26298\n",
       "í–‰ì‚¬         21338\n",
       "ì¼ê³¼ ì§ì—…      20428\n",
       "ë¯¸ìš©ê³¼ ê±´ê°•     17069\n",
       "ì‹œì‚¬/êµìœ¡      13119\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b325ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df= train_df.drop(['Id', 'Category'], axis=1)\n",
    "val_df = val_df.drop(['Id', 'Category'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "961cf8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.to_csv('data/train_df.csv', index = False)\n",
    "# val_df.to_csv('data/val_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59d6d8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ì›…', 'ì˜ì—…íŒ€ê³¼ì¥ë‹˜ì´ ë³´ë‚´ì¤¬ëŠ”ë° íŒ€ì¥ë‹˜ì´ í•´ì¤„ì§€ ëª¨ë¥´ê² ë‹¤ ì €ë²ˆì— ë¶€ì‚°ê°ˆë•Œë„ ìˆ™...</td>\n",
       "      <td>íŒ€ì¥ë‹˜ì´ ì¶œì¥ ê°€ì„œ ë¨¸ë¬¼ ìˆ™ì†Œë¥¼ ê³„ì†í•´ì„œ ë” ì‹¼ ë°ë¡œ í•˜ê²Œ í•œë‹¤ê³  ì´ì•¼ê¸°í•˜ê³  ìˆë‹¤.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['ë„ˆëŠ” ì˜ê°€ë¼....íšŒì‚¬.... ì„ íƒ ì˜í•´..', 'ì•Œê² ì–´ ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ ë§...</td>\n",
       "      <td>ì´ì œ ì´ë ¥ì„œë¥¼ ì“°ê³  ì˜ì–´ë„ í•´ì•¼ í•œë‹¤ê³  í•´ì„œ ì²« íšŒì‚¬ë¥¼ ì˜ ë“¤ì–´ê°€ë¼ê³  í–ˆë‹¤.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['ëŠë‚Œìƒ ëŒ€í†µë ¹ê¹Œì§€ëŠ” ì•„ë‹ˆê³  ì˜¤ì‹œë©´ ì—¬ì‚¬ë‹˜ì •ë„ì˜¤ì‹œì§€ì•Šì„ê¹Œ ã…‹ã…‹ã…‹', 'ê·¸ëŸ¬ë©´ì„œ',...</td>\n",
       "      <td>ëŠë‚Œìƒ ëŒ€í†µë ¹ê¹Œì§€ëŠ” ì•„ë‹ˆê³  ì˜¤ì‹œë©´ ì—¬ì‚¬ë‹˜ ì •ë„ ì˜¤ì‹œì§€ ì•Šì„ê¹Œë¼ë©° ì´ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['ìˆ¨ë§Œìˆ˜ì´ã…“ë„ ìˆ¨ë§Œì‰¬ì–´ë„ 100 ì´ë‚´', 'í•œë‹¬ì•ˆì— ì¼ ë¬´ì¡°ê±´ í•´ì•¼ëŒ€', 'ì•„ ë”±...</td>\n",
       "      <td>í•œ ë‹¬ ì•ˆì— ë¬´ì¡°ê±´ ì¼ì„ ì‹œì‘í•´ì„œ ëˆì„ ë²Œì–´ì•¼ í•œë‹¤.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['ëª©ìš”ì¼ì€ ì™¸ê·¼ì´êµ¬ ê¸ˆìš”ì¼ì€ ì¶œì¥!!!', 'ê¸ˆìš”ì¼ì´ ë‹¹ì§„ì´ì–‘?', 'ì•„ë‹ì•„ë‹ 1...</td>\n",
       "      <td>ëª©ìš”ì¼ì— ì™¸ê·¼ì´ê³  ê¸ˆìš”ì¼ì— ì¶œì¥ì¸ë° ë‹¹ì§„ì€ 10ì¼ì— ê°„ë‹¤.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  ['ì›…', 'ì˜ì—…íŒ€ê³¼ì¥ë‹˜ì´ ë³´ë‚´ì¤¬ëŠ”ë° íŒ€ì¥ë‹˜ì´ í•´ì¤„ì§€ ëª¨ë¥´ê² ë‹¤ ì €ë²ˆì— ë¶€ì‚°ê°ˆë•Œë„ ìˆ™...   \n",
       "1  ['ë„ˆëŠ” ì˜ê°€ë¼....íšŒì‚¬.... ì„ íƒ ì˜í•´..', 'ì•Œê² ì–´ ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ ë§...   \n",
       "2  ['ëŠë‚Œìƒ ëŒ€í†µë ¹ê¹Œì§€ëŠ” ì•„ë‹ˆê³  ì˜¤ì‹œë©´ ì—¬ì‚¬ë‹˜ì •ë„ì˜¤ì‹œì§€ì•Šì„ê¹Œ ã…‹ã…‹ã…‹', 'ê·¸ëŸ¬ë©´ì„œ',...   \n",
       "3  ['ìˆ¨ë§Œìˆ˜ì´ã…“ë„ ìˆ¨ë§Œì‰¬ì–´ë„ 100 ì´ë‚´', 'í•œë‹¬ì•ˆì— ì¼ ë¬´ì¡°ê±´ í•´ì•¼ëŒ€', 'ì•„ ë”±...   \n",
       "4  ['ëª©ìš”ì¼ì€ ì™¸ê·¼ì´êµ¬ ê¸ˆìš”ì¼ì€ ì¶œì¥!!!', 'ê¸ˆìš”ì¼ì´ ë‹¹ì§„ì´ì–‘?', 'ì•„ë‹ì•„ë‹ 1...   \n",
       "\n",
       "                                             Summary  \n",
       "0     íŒ€ì¥ë‹˜ì´ ì¶œì¥ ê°€ì„œ ë¨¸ë¬¼ ìˆ™ì†Œë¥¼ ê³„ì†í•´ì„œ ë” ì‹¼ ë°ë¡œ í•˜ê²Œ í•œë‹¤ê³  ì´ì•¼ê¸°í•˜ê³  ìˆë‹¤.  \n",
       "1         ì´ì œ ì´ë ¥ì„œë¥¼ ì“°ê³  ì˜ì–´ë„ í•´ì•¼ í•œë‹¤ê³  í•´ì„œ ì²« íšŒì‚¬ë¥¼ ì˜ ë“¤ì–´ê°€ë¼ê³  í–ˆë‹¤.  \n",
       "2  ëŠë‚Œìƒ ëŒ€í†µë ¹ê¹Œì§€ëŠ” ì•„ë‹ˆê³  ì˜¤ì‹œë©´ ì—¬ì‚¬ë‹˜ ì •ë„ ì˜¤ì‹œì§€ ì•Šì„ê¹Œë¼ë©° ì´ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜...  \n",
       "3                      í•œ ë‹¬ ì•ˆì— ë¬´ì¡°ê±´ ì¼ì„ ì‹œì‘í•´ì„œ ëˆì„ ë²Œì–´ì•¼ í•œë‹¤.  \n",
       "4                   ëª©ìš”ì¼ì— ì™¸ê·¼ì´ê³  ê¸ˆìš”ì¼ì— ì¶œì¥ì¸ë° ë‹¹ì§„ì€ 10ì¼ì— ê°„ë‹¤.  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train_df.csv')\n",
    "val_df = pd.read_csv('data/val_df.csv')\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f81649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"data/train_df.csv\",\n",
    "    block_size=128, # how many lines to read at a time \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3bf34074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/data/datasets/language_modeling.py:121: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ğŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "val_dataset = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"data/val_df.csv\",\n",
    "    block_size=128, # how many lines to read at a time \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1d2e18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer,mlm=True,mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72ab3877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63792f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9620bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set special tokens\n",
    "# #from transformers import EncoderDecoderConfig\n",
    "# model.config.decoder_start_token_id = tokenizer.bos_token_id                                             \n",
    "# model.config.eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# sensible parameters for beam search\n",
    "# set decoding params                               \n",
    "model.config.max_length = 128 # 256ì€ ì¿ ë‹¤ ë©”ëª¨ë¦¬ ì˜¤ë¥˜ ìƒê¹€\n",
    "model.config.early_stopping = True\n",
    "model.config.no_repeat_ngram_size = 2\n",
    "model.config.length_penalty = 2.0\n",
    "model.config.num_beams = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40f944ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = datasets.load_metric(\"rouge\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # all unnecessary tokens are removed\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge1\"])[\"rouge1\"].mid\n",
    "    rouge_output2 = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
    "    rouge_outputL = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rougeL\"])[\"rougeL\"].mid\n",
    "    \n",
    "\n",
    "    return {\n",
    "        \"rouge1_precision\": round(rouge_output.precision, 4),\n",
    "        \"rouge1_recall\": round(rouge_output.recall, 4),\n",
    "        \"rouge1_fmeasure\": round(rouge_output.fmeasure, 4),\n",
    "        \n",
    "        \"rouge2_precision\": round(rouge_output2.precision, 4),\n",
    "        \"rouge2_recall\": round(rouge_output2.recall, 4),\n",
    "        \"rouge2_fmeasure\": round(rouge_output2.fmeasure, 4), \n",
    "        \n",
    "        \"rougeL_precision\": round(rouge_outputL.precision, 4),\n",
    "        \"rougeL_recall\": round(rouge_outputL.recall, 4),\n",
    "        \"rougeL_fmeasure\": round(rouge_outputL.fmeasure, 4),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e994865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"results221115\",\n",
    "    num_train_epochs=1,  # demo\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=16,  # demo\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=3e-05,\n",
    "    warmup_steps=50,\n",
    "    weight_decay=0.1,\n",
    "    label_smoothing_factor=0.1,\n",
    "    predict_with_generate=True, # ìƒì„±ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ê³  ì‹¶ë‹¤ê³  ì§€ì •í•œë‹¤.\n",
    "    logging_dir=\"logs2\",\n",
    "    logging_steps=50,\n",
    "    save_total_limit=3,\n",
    "    max_steps=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "526055b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model, \n",
    "    training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed271625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 280026\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 100\n",
      "  Number of trainable parameters = 123859968\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjx7789\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/aiffel/aiffel/Korean_Conversation_Summary/wandb/run-20221115_084328-3ce5qj5e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jx7789/huggingface/runs/3ce5qj5e\" target=\"_blank\">results221115</a></strong> to <a href=\"https://wandb.ai/jx7789/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 00:48, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.333800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.403900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=4.868830413818359, metrics={'train_runtime': 56.3023, 'train_samples_per_second': 28.418, 'train_steps_per_second': 1.776, 'total_flos': 121947291648000.0, 'train_loss': 4.868830413818359, 'epoch': 0.01})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c43c3769",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_val_df = pd.read_csv('data/val_total.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c58977da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF > data Setìœ¼ë¡œ ì „í™˜\n",
    "\n",
    "\n",
    "test_val_df=Dataset.from_pandas(test_val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb3e236c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /aiffel/.cache/huggingface/hub/models--gogamza--kobart-base-v2/snapshots/d9a1f640896cef8dcfd693b1bc57510a2b09a18f/config.json\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"gogamza/kobart-base-v2\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.1,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"kobart_version\": 2.0,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 1026,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"tokenizer_class\": \"PreTrainedTokenizerFast\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /aiffel/.cache/huggingface/hub/models--gogamza--kobart-base-v2/snapshots/d9a1f640896cef8dcfd693b1bc57510a2b09a18f/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at gogamza/kobart-base-v2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 128 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "max_target = 128\n",
    "def generate_summary(test_samples, model):\n",
    "    inputs = tokenizer(\n",
    "        test_samples[\"Text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_target,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    input_ids = inputs.input_ids.to(model.device)\n",
    "    \n",
    "    attention_mask = inputs.attention_mask.to(model.device)\n",
    "    outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
    "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return outputs, output_str\n",
    "\n",
    "\n",
    "model_before_tuning = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoints)# ì—¬ê¸°ì— ê¸°ë³¸ kobartê°€ì ¸ì˜¤ê¸°?\n",
    "import random\n",
    "from random import randrange\n",
    "test_samples = test_val_df.select(range(16))# 0, len(test_data), 200\n",
    "\n",
    "summaries_before_tuning = generate_summary(test_samples, model_before_tuning)[1]\n",
    "summaries_after_tuning = generate_summary(test_samples, model)[1] # ì—¬ê¸°ì— ì²´í¬í¬ì¸íŠ¸ ê°€ì ¸ì˜¤ê¸° \n",
    "# ì—°êµ¬í•´ë´ì•¼í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "26174c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx_0 \n",
      "Summary before \n",
      " \n",
      "\n",
      "Summary after \n",
      " \"['ì•„ë‹ˆë‹¤' 'ì•„ë‹ˆ ì´ê±° ì´ê±° ë˜ ë˜ë˜ ë§ì´ê°€ë„ ë˜ê²Œ ë˜ê²Œ ë§ì´ ë§ì´í•´ì„œ',''ì›… ê·¸ë˜ì„œê±°ê±°ë„ì•„ê±°ë‹ˆê³  3ì¼ê°€ëŠ”ë° ì¢€í•˜ëŠ”ë° ì¢€ê°€ì„œ ì¢€í•´ ë­ ë­ë‹¤ ë­í•œë‹¤êµ¬ ë­ì•¼',''', 'ì´ê±° ë­ í•´ë´¤ì 3ì¼ ë‹¤ í•©í•´ë„ ëª‡ë§Œì›ì¸ë° ëª‡ëª‡ëª‡ ëª‡ì´ì¸ë°ì¸ë° í•˜ëŠ”ë° ê·¸ê±° ê·¸ê±°ì¸ë°ëŠ”ë°ëŠ”ë° ë­ í•˜ë‚˜ì¸ë°ì´ê³ ì¸ë° ë„ˆë¬´í•´ ê·¸ë•ŒëŠ” 2ì¼ì¸ë° ê·¸ ë•Œì—ì„œ ìê¾¸ ìê¾¸ ìë¼ê³ ... ë„˜' '' 'ì•„ë˜ë˜ ë­í•˜ëŠ”ë°í•˜ëŠ”ë° ìê¾¸ìë¼ê³ ì—ì„œ ê³„ì† ìë ¤ê³ í•˜ëŠ”ë° ê±°ê¸°ì„œ ê±°ê¸°ì„œì—ì„œ ê±” ë­ ë§ì´í•˜ëŠ”ë° ê·¸ëŸ¼\n",
      "\n",
      "Target summary \n",
      " íŒ€ì¥ë‹˜ì´ ì¶œì¥ ê°€ì„œ ë¨¸ë¬¼ ìˆ™ì†Œë¥¼ ê³„ì†í•´ì„œ ë” ì‹¼ ë°ë¡œ í•˜ê²Œ í•œë‹¤ê³  ì´ì•¼ê¸°í•˜ê³  ìˆë‹¤.\n",
      "\n",
      "Text ['ì›…', 'ì˜ì—…íŒ€ê³¼ì¥ë‹˜ì´ ë³´ë‚´ì¤¬ëŠ”ë° íŒ€ì¥ë‹˜ì´ í•´ì¤„ì§€ ëª¨ë¥´ê² ë‹¤ ì €ë²ˆì— ë¶€ì‚°ê°ˆë•Œë„ ìˆ™ì†Œë¡œ ì—„ì²­ ì‹¸ì›Œì„œ', 'ì›… í¥ 4ê°œì›”ê°€ëŠ”ê±°ë„ì•„ë‹ˆê³  3ì¼ê°€ëŠ”ë° ì¢€í•´ì£¼ì§€ ê±° ì–¼ë§ˆí•œë‹¤êµ¬', 'ë‚´ë§ì´... ì•„ë‹ˆ í•´ë´¤ì 3ì¼ ë‹¤ í•©í•´ë„ ëª‡ë§Œì› ì°¨ì´ì¸ë° ë„ˆë¬´í•´ ê·¸ë•ŒëŠ” 2ì¼ì´ì—ˆëŠ”ë°ë„ ë§Œì› ë” ì‹¼ë°ì—ì„œ ìê¾¸ ìë¼ê³ ... ë„˜ ì‹œëŸ¬..', 'ì¼ë‹¨']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_1 \n",
      "Summary before \n",
      " \n",
      "\n",
      "Summary after \n",
      " \"[',''',',' '''', 'ì´ë ¥ì„œ ì“°ê³  ì˜ì–´ë„ í•´ì•¼í•´..', 'ì—¬.....', 'ìš°ë¦¬  ë˜¥.................................................'... '........', 'ë‚˜''...'...' '...''.....'......'..... 'ì¢‹ì€ ì‹œì ˆ ë‹¤ ì§€ë‚¬ë‹¤... '...'ë‹¤'' ''ê·¸' 'ë‚˜'ë„ˆëŠ”ëŠ”......... '....íšŒì‚¬....'.... ê·¸ëŸ¼... ê·¸ëŸ¼.....\"... ë‚˜..!!',...' á„á„ ', 'ì•„'ë‚˜ ë‚˜...... \\á„'á„...á„ 'á„\n",
      "\n",
      "Target summary \n",
      " ì´ì œ ì´ë ¥ì„œë¥¼ ì“°ê³  ì˜ì–´ë„ í•´ì•¼ í•œë‹¤ê³  í•´ì„œ ì²« íšŒì‚¬ë¥¼ ì˜ ë“¤ì–´ê°€ë¼ê³  í–ˆë‹¤.\n",
      "\n",
      "Text ['ë„ˆëŠ” ì˜ê°€ë¼....íšŒì‚¬.... ì„ íƒ ì˜í•´..', 'ì•Œê² ì–´ ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ ë§ì´ í˜ë“¤êµ¬ë‚˜... ë‚˜ë„ ì´ì œ ì´ë ¥ì„œì“°ê³  ì˜ì–´ë„ í•´ì•¼í•´..', 'ìš°ë¦¬ ë˜¥ê°±ì• ì§€.... í™”ì´íŒ….... ì²« íšŒì‚¬ ì˜ë“¤ì–´ê°€ì•¼í•œë‹¤!', 'ì¢‹ì€ ì‹œì ˆ ë‹¤ ì§€ë‚¬ë‹¤..']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_2 \n",
      "Summary before \n",
      " \n",
      "\n",
      "Summary after \n",
      " \"['ê·¸ëŸ¼ìš” ì˜¤ì‹œë©´ ì—¬ì‚¬ë‹˜ì •ë„ì˜¤ì‹œì§€ì•Šì„ê¹Œ á„á„','' ì—¬ê¸°ìˆì—ˆêµ¬ë‚­',' 'ë‚´ê°€ ì˜†ì—ì„œ ì˜†ì—ì„œ ì„œí¬íŠ¸ í•œë‹¤ê³  í•´ì„œ ê·¸ë˜ì„œ ê·¸ë˜ì„œ.... ê·¸ë˜ì„œ ë­ë­ë­ê°€ á„’á„’',', 'ì–´ë¥´ë¥´ë“¤ë‘ ì„¤ëª… ì„¤ëª… ë‹¤ë“¤ ë‹¤ í•˜ëŠ”ë°', 'ê·¸ëŸ¼ ê·¸ëŸ¼ ë‹¤ ë‹¤ í•˜ì‹œë©´ ë˜ê² ë„¹', 'ë‚˜''', 'ì•„'ë‹¤''   'ë‹ˆê¹Œë‹ˆê¹Œ ë‹¤í•˜ì‹œë©´', 'ì´ë‹ˆê¹Œ' 'ì•„ë˜ë‹¤ë‹¤ í•˜ì‹œì‹œë©´', 'ì˜¤ì‹œë©´ ë‹¤ë‹¤ ë‹¤ í•˜ì…¨ìœ¼ë©´',ë‹¤'ë‹¤' ''ë„¤ ì˜¤ë¹  ì˜¤ë¹  ë‹¤ì˜¤ì‹œë©´ ê·¸ëŸ¼ ê·¸ëŸ¼ ë‚˜ì‚¬ë‹˜ì€ì •ë„ ì˜¤ì‹œì‹œ\n",
      "\n",
      "Target summary \n",
      " ëŠë‚Œìƒ ëŒ€í†µë ¹ê¹Œì§€ëŠ” ì•„ë‹ˆê³  ì˜¤ì‹œë©´ ì—¬ì‚¬ë‹˜ ì •ë„ ì˜¤ì‹œì§€ ì•Šì„ê¹Œë¼ë©° ì´ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ê³  ìˆë‹¤.\n",
      "\n",
      "Text ['ëŠë‚Œìƒ ëŒ€í†µë ¹ê¹Œì§€ëŠ” ì•„ë‹ˆê³  ì˜¤ì‹œë©´ ì—¬ì‚¬ë‹˜ì •ë„ì˜¤ì‹œì§€ì•Šì„ê¹Œ ã…‹ã…‹ã…‹', 'ê·¸ëŸ¬ë©´ì„œ', 'ìƒ˜ ì—¬ê¸°ìˆì—ˆêµ¬ë‚­ã…‹', 'ì¢…ì´ê°•ì‚¬ë‘ ìê¸°ê°€ ì˜†ì—ì„œ ì„œí¬íŠ¸ í•œë‹¤ëŠ” ì‹ìœ¼ë¡œ ã…‹ã…‹ã…‹', 'ë²Œì¨ ì‹œë‚˜ë¦¬ì˜¤ê°€ ã…‹ã…‹ã…‹', 'ì–´ë¥´ì‹ ë“¤ ëª»í•˜ëŠ” ì„¤ëª… ìê¸°ê°€ í•œë‹¤ëŠ” ì‹ìœ¼ë¡œ ã…‹ã…‹ã…‹ã…‹', 'ê·¸ëŸ¼ ë³¸ì¸ì´ ë‹¤ í•˜ì‹œë©´ ë˜ê² ë„¹', 'ê·¸ë‹ˆê¹Œìš” ã…‹ã…‹ã…‹']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_3 \n",
      "Summary before \n",
      " \n",
      "\n",
      "Summary after \n",
      " \"[' '''', 'ì•„',',''', 'ê·¸ëŸ¼ ê·¸ëŸ¼ ê·¸ëŸ¼',' 'ê·¸ëƒ¥ ë­ì•¼', 'ì´ê±°ê±°ë„¤ë„¤ ê·¸ëŸ¼ ë­í•˜ëŠ”ë° 'ëˆì€ ìˆëŠ”ê±°ì•¼ ê·¸ê±° ê·¸ê±°í• êº¼?', 'ì–´', 'ì¼ ë¬´ì¡°ê±´ ì¼í•´ì•¼í•˜ëŠ”ë° ì¼ í•´ì•¼ í•˜ëŠ”ë°''ì•„,,', 'ì—¬ 'ë‹¤','ë‹¤'' 'ì•„ 'ì•„ì•„ì•„', 'ë‚˜']]''ì´''['##ì´ë¦„ë§Œ.......ëŒ€ì´ì´ë‹ˆê¹Œ..', 'í•œë‹¬ì•ˆì— ì¼ ë¬´ì¡°ê±´ í•˜ë©´',,'',ë‹¤' 'ëƒ¥..' 'ì´ë ‡ê²Œí•´ë„  ëƒ¥ëƒ¥ ì¼ë§Œ í•˜ë©´...', 'ì•ˆ', ì´ê±°\n",
      "\n",
      "Target summary \n",
      " í•œ ë‹¬ ì•ˆì— ë¬´ì¡°ê±´ ì¼ì„ ì‹œì‘í•´ì„œ ëˆì„ ë²Œì–´ì•¼ í•œë‹¤.\n",
      "\n",
      "Text ['ìˆ¨ë§Œìˆ˜ì´ã…“ë„ ìˆ¨ë§Œì‰¬ì–´ë„ 100 ì´ë‚´', 'í•œë‹¬ì•ˆì— ì¼ ë¬´ì¡°ê±´ í•´ì•¼ëŒ€', 'ì•„ ë”±í•œë‹¬', 'ê·¸ëƒ¥ ì•„ë¬´ì½”í†  í•˜ë©´ ì•ˆë¼', 'ëˆì€ ìˆëŠ”ê±°ë„¤ ë¬´ìŠ¨ì¼í• êº¼?', 'ì›… ê·¸ë‹ˆê¹Œ 15ì¼ ì´í›„ë¡œëŠ” ë¬´ì¡°ê±´ ì¼í•´ì•¼ë° ëª°ë¼ ì•„ì§,,', 'í•˜ ê³ ë¯¼ì´ë‹¹']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_4 \n",
      "Summary before \n",
      " '' '''''''', 'ì•„ë‹ì•„ë‹ 10ì¼ì´ ë‹¹ì§„ì´\n",
      "\n",
      "Summary after \n",
      " \"['ì•„'', ''' 'ì´ë¦„?', 'ì•„ë‹ì•„ë‹ 10ì¼ì´ ë‹¹ì§„ì´ì•¼', 'ê·¸ëŸ¼ ê·¸ëŸ¼ì€ ì–´ë””ê°€ê°€...',', 'ì´''', 'ì˜¤',' 'ë‚˜', ì˜¤í™?']', 'ë‚˜'  'ë‹¤'' 'ì•„', 'ì—¬''ì´'ë‹¤'''ì•„''ì´' 'ì£¼' 'ì´', 'ì¼ìš”ì¼ì€ ì™¸ê·¼ì´ì´êµ¬ ', 'ë‚´ 'ê±°', 'ì§€'..', 'ì–´ëŠì´ê±°ì´ë‹ˆê¹Œ...ì€ì€ì´ë„¤',ëŸ¼ì€ '..'ì´ ''ì´ì´',, 'ì•„ë‹ˆì•„ë„ˆ' = =', '201 'ê¸ˆìš”??\n",
      "\n",
      "Target summary \n",
      " ëª©ìš”ì¼ì— ì™¸ê·¼ì´ê³  ê¸ˆìš”ì¼ì— ì¶œì¥ì¸ë° ë‹¹ì§„ì€ 10ì¼ì— ê°„ë‹¤.\n",
      "\n",
      "Text ['ëª©ìš”ì¼ì€ ì™¸ê·¼ì´êµ¬ ê¸ˆìš”ì¼ì€ ì¶œì¥!!!', 'ê¸ˆìš”ì¼ì´ ë‹¹ì§„ì´ì–‘?', 'ì•„ë‹ì•„ë‹ 10ì¼ì´ ë‹¹ì§„ì´ì•¼', 'ê·¸ëŸ¼ ê¸ˆìš”ì¼ì€ ì–´ë””ë¡œê°€...?', 'ì˜ì™•! ì² ê¸°ì—°ìœ¼ë¡œ ê°€', 'ì˜¤í™?']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_5 \n",
      "Summary before \n",
      " \n",
      "\n",
      "Summary after \n",
      " \"[' '',''' 'ì•„ë‹ˆê¹ ë‚˜ ì§„ì§œ ì§„ì§œ íšŒì‚¬ ë‹¤ë‹ˆê¸° ì‹«ìœ¼ë©´ ë©´ì ‘ ë“¤ì–´ê°€ê³  ì‹¶ì–´ì„œ ê·¸ë˜ì„œ ê·¸ë´ ê·¸ê·¸ë¦¬ê³  ë˜ ê·¸  ì˜á„á„',','' ê·¸ëŸ¼ ê·¸ëŸ¼ ê·¸í•œí…Œ ë¬¼ì–´ë³´ëŠ”ê²Œ á„ ë˜ê²Œ ë¹ ë¥´ë¥´'', 'ì•„ 'ì•„' 'ê·¸ëŸ¼ ê·¸ë ‡ê²Œ ê·¸ë ‡ê²Œ ë”°ì§€ë“¯ í•  í•„ìš”ê°€ ìˆ ìˆë„¤ ê·¸ëŸ¼ ê·¸ê±° ê·¸ê±° ì´ê±° ë˜ê²Œ ë˜ê²Œ ê·¸ë ‡ê²Œ ì«Œ ì´ë ‡ê²Œ í•´ì„œ ê±”ê±”  ë˜ ë˜ì–´ì„œ', 'ë‚˜' ì´ê±°''ì•„'ì´ê±° ì´ê±° ê·¸ê±° ê·¸ê±¸ ê·¸ê±¸ ë˜ê²Œ ë§ì´ ë§ì´ ë¬¼ì–´ë³´ë©´ ë˜ë„¤ á„‹á„ ', 'ê·¸ëŸ¼ ë‚˜' ê·¸ 'ê·¸ëŸ¼ ê·¸ëŸ¼ ì§„ì§œë¡œ ë” ë§ì´\n",
      "\n",
      "Target summary \n",
      " ê·¸ë§Œ ë‘˜ ì „ì„ìì—ê²Œ ë©´ì ‘ ìë¦¬ì—ì„œ ë”°ì§€ë“¯ì´ ë¬¸ì˜í•˜ëŠ” ë©´ì ‘ìì— ëŒ€í•´ ì´ì•¼ê¸°í•œë‹¤.\n",
      "\n",
      "Text ['ì°¸ ë‚˜ã…¡ã…¡ ì•„ë‹ˆ íšŒì‚¬ ë‹¤ë‹ˆê¸° ì‹«ìœ¼ë©´ ë©´ì ‘ ì˜¤ì§ˆ ë§ë˜ê°˜ã…‹ã…‹ã…‹ ì–´ì´ê°€ ì—†ë„¤ã…‹ã…‹ã…‹ ê·¸ë¦¬ê³  ì „ì„ìí•œí…Œ ì™œ ê·¸ë´ ê·¸ë§Œë‘ëŠ” ì• ë¥¼ã…‹ã…‹ã…‹ íšŒì‚¬ì— ë¬¼ì–´ë´ì•¼ì§˜ã…‹ã…‹ã…‹', 'ì‚¬ì‹¤ ì „ì„ìí•œí…Œ ë¬¼ì–´ë³´ëŠ”ê²Œ ë¹ ë¥´ê¸´í•˜ì§˜ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ ì¹˜ê³  ë¹ ì§€ê¸°ëŠ”', 'ì•„ë‹ˆ ê·¸ê±´ ê·¸ëŸ°ë° ê·¸ë ‡ê²Œ ë”°ì§€ë“¯ í•  í•„ìš”ê°€ ìˆëƒê³¸ã…‹ã…‹ã…‹', 'ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ ê·¸ëŸ¬ê²Œ ã…‹ã…‹ã…‹ã…‹', 'ë”°ë¡œ ì‚´ì§ ë¬¼ì–´ë³´ë©´ ë˜ì§˜ã…‹ã…‹ã…‹', 'ë‚˜ë„ ë©´ì ‘ ë“¤ì–´ê°€ê³  ì‹¶ì–´ì„œ ë“¤ì–´ê°„ê²Œ ì•„ë‹ˆì•¼ ì–˜ì•¼', 'ê·¸ë¦¬ê³  ë³´í†µ ì „ì„ìë„ ì§€ê°€ ë¹ ì§ˆë¼ê³  ì–˜ê¸° ì˜ ì•ˆí•´ì£¼ë˜ëˆã…‹ã…‹ã…‹ ë©´ì ‘ìë¦¬ë©´ ë‹¤ ìˆëŠ”ë°ì„´ã…‹ã…‹ã…‹']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_6 \n",
      "Summary before \n",
      " 'ë©”ì¼ ì£¼ì†Œ ì•Œë ¤ì£¼ì„¸ì—¬ ì œê°€ ì ì‹¬ë¨¹ê³ ì™€ì„œ ë³´ë‚¼ê²Œì—¬', '\n",
      "\n",
      "Summary after \n",
      " \"[''ë©”ì¼ ì£¼ì†Œ ì•Œë ¤ì£¼ì„¸ì—¬, ì œê°€ ì ì‹¬ë¨¹ê³ ì™€ì„œ ë³´ë‚¼ê²Œì—¬',''',',' '#@ì´ë¦„#ì”¨ ì›í‹°ë¹„ Qí‹°ë¹„ì—ë¹„ ì—£ ì‚¬ì§„ ì‚¬ì§„ì‚¬ì§„ # #ì”¨ ë³´ë„¤ì—¬' ë‚˜ì„'ë„¤', 'ì•„ 'ì•„' 'ì•„ '' ì‚¬ì§„'', 'ì´ë¦„í•˜ê³ í•˜ê³ ì„œ í• ê±°ì•¼', 'ê·¸ëŸ¼..ê³ ì„œì„œí• ê²Œ  ìª„ìª„ì„œ ë¹¨ë¦¬ ë¹¨ë¦¬ë¹¨ë¦¬ë¹¨ë¦¬ì•¼ì•¼ì„œ ë³´ë‚´ì£¼ê±°ê±°ì—¬ì„œ''ì´ë¦„ë¨¹ê³  ë˜ ë˜ë˜ì„œ ë‚¼ê²Œ ì—¬', 'ì—¬ ''ì™€'ì‘ì‘ì´ë¡œ ë¹¨ë¦¬ì„œì•„ì„œ ë˜ ë¹¨ë¦¬\n",
      "\n",
      "Target summary \n",
      " ì ì‹¬ì„ ë¨¹ê³  ì™€ì„œ ì•Œë ¤ì¤€ ë©”ì¼ ì£¼ì†Œë¡œ ë¡¯ë° ì›í‹°ë¹„ íì—ì´(QA) ë‹´ë‹¹ìì—ê²Œ ë©”ì¼ì„ ë³´ëƒˆë‹¤.\n",
      "\n",
      "Text ['ë©”ì¼ ì£¼ì†Œ ì•Œë ¤ì£¼ì„¸ì—¬ ì œê°€ ì ì‹¬ë¨¹ê³ ì™€ì„œ ë³´ë‚¼ê²Œì—¬', 'ã„´ë„µë„µ!! #@ì‹œìŠ¤í…œ#ì‚¬ì§„# #@URL# ë¡¯ë° ì›í‹°ë¹„ QAë‹´ë‹¹ë‹˜ì…ë‹ˆë‹¤!', 'ë„¤ì— #@ì´ë¦„#ì”¨ ë³´ëƒ‡ì–´ì—¬', 'ë„µ ê°ì‚¬í•©ë‹ˆë‹¤!']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_7 \n",
      "Summary before \n",
      " \n",
      "\n",
      "Summary after \n",
      " \"[ 'ì•„ë‹ˆ ê·¸ëŸ¼ ê·¸ëŸ¼ì œì œ ê·¸ì œì¸ê³„ë°›ì§€ ì¸ìˆ˜ì¸ê³„ë¥¼ë°›ê³ ë°›ê³ ì–´ì¼€...', 'ì•„..á„’ ì œì†¡í•¨ë‹¤ ì œê°€ ë­˜ ë„ˆë¬´ ë„ˆë¬´ ë˜ê²Œ ë˜ê²Œë„¤ë„¤ì—¬', 'ì•— ë‚˜ë„ˆë„ˆ ë‚˜ì—ìˆì–´?? ë‚˜ì•„ë„ˆì— ë‚˜..ê±°ë„¤ê·¸ëŸ¼ ë‚˜ ë‚˜ ë„ˆ ë‚˜ë‚˜ë„ˆë¬´ë‚˜ë‚˜ì—ì—ê±°ê±°ì§„ê±° ë‚˜ë‘ê±° ','''ì§„ì €ê±°ë‘ì§„í‹€í‹€ëŸ¼ê±°ì„œ ê·¸ëŸ°ê°€?']',', 'ì´ ''' 'ì•„ 'ì•„ë‹ˆ ê·¸ëŸ¼ ê·¸ëŸ¼ ë‚¼ì¸ë°ì¸ë° ê°œê°• ì²«ë‚ ì´ë¼ì„œì„œ......ê·¸ë˜ì„œ?',\n",
      "\n",
      "Target summary \n",
      " ì¼ì£¼ì¼ ë™ì•ˆ ì¸ìˆ˜ì¸ê³„ ë°›ì„ ì˜ˆì •ì¸ë° ê³¼ ì‚¬ë¬´ì‹¤ë³´ë‹¤ëŠ” ì‚¬ë‘ë°©ì²˜ëŸ¼ í•™ìƒë“¤ì´ ë§ì´ ì°¾ì•„ì˜¨ë‹¤.\n",
      "\n",
      "Text ['ê·¸ëŸ¼ ë‚¼ë¶€í„° ì¶œê·¼í•´?', 'ì•„ë‹ˆì´ë²ˆì£¼ë™ì•ˆì¸ìˆ˜ì¸ê³„ë°›ì§€ ì¸ìˆ˜ì¸ê³„ë¥¼í•˜ë£¨ë°›ê³ ì–´ì¼€ì¼í•´', 'ì•„..ã… ì œì†¡í•¨ë‹¤ ì œê°€ ë­˜ ë„ˆë¬´ ëª°ëë„¤ì—¬ í—¤', 'ì•— ë‚˜ë„ˆë¬´ì‹¸ê°€ì§€ì—†ê²Œë§í–‡ë”? ì˜ë¦¬ ê·¼ë°ì˜¤ëŠ˜í•™ìƒë“¤ì—„ì²­ì°¾ì•„ì™“ë‹¤í–‡ìë‚˜ ê·¸ë˜ì„œì¸ìˆ˜ì¸ê³„ë°›ì€ê²ƒë„ì—†ì–´^^ ê³¼ì‚¬ë¬´ì‹¤ì´ì•„ë‹ˆë¼ì‚¬ë‘ë°©ì¸ì¤„', 'ì˜¤ëŠ˜ ê°œê°• ì²«ë‚ ì´ë¼ì„œ ê·¸ëŸ°ê°€?']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_8 \n",
      "Summary before \n",
      " \n",
      "\n",
      "Summary after \n",
      " \"['ë‚˜ë„ ì¼í•œë‹¤ëŠ”ë° ì‹œê¸‰ 1.5ë°° ë§ë‚˜ìš”', ''''' ë­ì•¼ ì´ëŸ°ê±´ ìš”êµ¬í•´ì•¼ì§€ ê·¼ë¡œê³„ì•½ì„œ ì•ˆì¨ì§€ ë­ ë­ ê·¸ëŸ°ê±´ ì¤˜ì•¼í•¨', 'ì•„ì§ë„ ì•ˆì¼ëƒ ê·¸ëŸ¼ ê·¸ëŸ¼ìš”'ê±°ë„¤',' 'ì•„ë‹ˆ ê·¸ëŸ¼ ì•ˆê·¸ë˜ë„ ê³„ì•½ì„œë„ ì“°ê³  ë³´ë„ˆìŠ¤ë„ ë” ë”í• ë¼êµ¬ì—¬',', 'ì´ 'ëŸ¼ ê·¸ëŸ¼ ê·¸ ë˜˜ë˜˜ì´'  ê±”ë„¤''ì•„ì•„ì•„ ì•„ì£¼ ì•„ì£¼ ì«Œì´ê±°ë‹ˆêµ¬ë§Œ']', 'ê·¸ëŸ¼ ë­ ì   ì ¤ ë²… 'ê±° ë‚˜ ë‚˜ ì´ê±° ë„ˆ ë‚˜ìˆë‹¤êµ¬ìš”~',\n",
      "\n",
      "Target summary \n",
      " ê·¼ë¡œê³„ì•½ì„œë¥¼ ì¨ì•¼í•œë‹¤ê³  í•˜ë©° í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ë•Œ ì¼í•˜ëŠ” ê²ƒì˜ ì‹œê¸‰ì„ 1.5ë°°í•´ë‹¬ë¼ê³  í•  ê²ƒì„ ì´ì•¼ê¸°í•˜ê³  ìˆë‹¤.\n",
      "\n",
      "Text ['ë‚˜ í¬ë¦¬ìŠ¤ë§ˆìŠ¤ë–„ë„ ì¼í•œë‹¤ëŠ”ë° ì‹œê¸‰ 1.5ë°° ë§ë‚˜ìš”', 'ì–´ 1.5ë°° ìš”êµ¬í•´', 'ì–´í›„ ê·¼ë¡œê³„ì•½ì„œ ì¨ì•¼ë”©..', 'í•˜ëª¨ ê·¸ëŸ°ê±´ ìš”êµ¬í•´ì•¼ì§€ ê·¼ë¡œê³„ì•½ì„œ ì•ˆì¨ë„ ê·¸ëŸ°ê±´ ì¤˜ì•¼í•¨', 'ì•„ì§ë„ ì•ˆì¼ëƒã…ã… ê·¼ë¡œê³„ì•½ì„œ ë¹¨ë¦¬ ì¨ë¼', 'ë„¹ë„¹ ì•ˆê·¸ë˜ë„ ê³„ì•½ì„œë„ ì“°ê³  ë³´ë„ˆìŠ¤ë„ ë” ë‹¬ë¼í• ë¼êµ¬ì—¬', 'ë§‰ë‚´ ì•„ì£¼ ë˜˜ë˜˜í•˜êµ¬ë§Œ']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_9 \n",
      "Summary before \n",
      " 'ê³ ìš©ë…¸ë™ë¶€ë‘ ì „í™”í•˜ëŠ”ë°', 'á„‹á„‹á„‹', 'ì´ì¤‘ì·¨ì—… í•˜ì…¨ë‚˜\n",
      "\n",
      "Summary after \n",
      " \"['ë…¸ë™ë¶€ë‘ ì „í™”í•˜ëŠ”ë°', 'á„‹á„‹', 'ì´ì¤‘ì·¨ì—… í•˜ì…¨ë‚˜ìš”? ì´ëŸ¬ëŠ”ê±°ì•¼ ë§¨'''',',' 'ì œê°€ ì„ ìƒë‹˜ ì‹¤ì—…ê¸‰ì—¬ ê°€ëŠ¥í•˜ì‹ ì§€ ìê²© ë¨¼ì € ë¨¼ì € í™•ì¸í• ê²Œìš”', 'ì•„ë˜ì„œ ì„ ìƒë‹˜ë‹˜ ì´ì¤‘ì·¨ì—…ì´ì‹ ê°€ìš”.? ì•„ë˜ì„œ ë¬´ìŠ¨ ë§ì”€ì´ì‹œì£ ...?']'' [' 'ìš°ë¦¬' 'ì´'ë‹¤' '('(' '....''ì´ë‘ í†µí™”í•˜ëŠ”ë°' ', 'ìš°ë¦¬''ì´ê±°ë‹ˆê¹Œë‹ˆê¹Œ',  'ë‹¤'' 'ì•„ 'ì•„ì´ê³ ' ê·¸ëŸ¼', ë­'ë˜', 'ì—¬' ì´ê±° 'ì´ê±´ ë­ í•˜ì…¨ì–´ìš”', 'ê·¸ 'ì´ë¡  ë§ì´ ë§ì´ í•˜ì…¨\n",
      "\n",
      "Target summary \n",
      " ê³ ìš©ë…¸ë™ë¶€ì™€ ì „í™”í•˜ëŠ”ë° ì´ì¤‘ ì·¨ì—…ì„ í–ˆëŠ”ì§€ ë¬»ê³  ì‹¤ì—…ê¸‰ì—¬ ìê²©ì„ í™•ì¸í•˜ê² ë‹¤ê³  ë§í–ˆë‹¤.\n",
      "\n",
      "Text ['ê³ ìš©ë…¸ë™ë¶€ë‘ ì „í™”í•˜ëŠ”ë°', 'ã…‡ã…‡ã…‡', 'ì´ì¤‘ì·¨ì—… í•˜ì…¨ë‚˜ìš”? ì´ëŸ¬ëŠ”ê±°ì•¼ ë§¨ì²¨ì—', 'í—¤ì—', 'ì œê°€ ì„ ìƒë‹˜ ì‹¤ì—…ê¸‰ì—¬ ê°€ëŠ¥í•˜ì‹ ì§€ ìê²© ë¨¼ì € í™•ì¸í• ê²Œì—¬~ ì´ëŸ¬ë”ë‹ˆ ì•„ë‹ˆ ê·¸ëŸ°ë° ì„ ìƒë‹˜ ì´ì¤‘ì·¨ì—…ì´ì‹ ê°€ìš”.? ì•„ë˜ì„œ ë¬´ìŠ¨ ë§ì”€ì´ì‹œì£ ...?']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_10 \n",
      "Summary before \n",
      " .  ëˆì´ ì–¼ë§ˆë…¸.. ê·¼ë° 4ëŒ€ ë³´í—˜ í¬í•¨ì´ë€ ë§ì´ ì €ê²Œ ì„¸ì „ê¸ˆì•¡ì´ë¼ëŠ”\n",
      "\n",
      "Summary after \n",
      " \"[' \"[ 'í•™êµì—ì„œ 6ê°œì›”ì§œë¦¬ í•©ê²©í•˜ë©´ ì¡°ìº£ë‹¤.. í•©ê²© í•˜ë©´ê±°ê±°  ëŸ¼....','''',', 'ìµœ' '..'' 'ì•„ë˜.. 180 ë°›ëŠ” ë…ì„œì‹¤ ë˜ê²ë„¤,,', 'ì•„ 'ì €ê±°..ê²…ê³ ë¬¸ ë³´ë‹ˆê°€..... á„…á„‹á„‹ ìˆ˜ìš”ì¡°ì‚¬ê³ ê³  6ì›”ì— ì„œë¥˜ ë‚´ê³  ë©´ì ‘ê°€ì§€ ë³¸ëŒ€.. í•˜.. ', 'ê·¸ëŸ¼ í•„ê¸° ì—†ëŠ”ê²Œ...',' 'ê·¸ëŸ°......ì´ëŸ°ê²Œ ë­.....', 'ì´ 'ëŸ¼... ê·¸ëŸ¼...??', 'ë‚˜ 'ì ì ì„± ì—†ë„¤~~',, 'ë©´ì ‘ì´ë¼ë©´\n",
      "\n",
      "Target summary \n",
      " í•™êµì—ì„œ 4ëŒ€ ë³´í—˜ í¬í•¨ì´ê³  ì„¸ê¸ˆ ë–¼ë„ ìµœì†Œ 180ë§Œ ì›ì€ ë  ê±° ê°™ì€ 6ê°œì›”ì§œë¦¬ í•©ê²©í–ˆìœ¼ë©´ ì¢‹ê² ì§€ë§Œ ì„œë¥˜ ë‚´ê³  ë©´ì ‘ê¹Œì§€ ë³¸ë‹¤ê³  í•œë‹¤.\n",
      "\n",
      "Text ['í•™êµì—ì„œ 6ê°œì›”ì§œë¦¬ í•©ê²©í–ˆìœ¼ë©´ ì¡°ìº£ë‹¤.. í•©ê²©í•˜ë©´ ë§›ë‚œê±° ì©ë‹ˆë‹¤.. ìƒ¹ ëˆì´ ì–¼ë§ˆë…¸.. ê·¼ë° 4ëŒ€ë³´í—˜ í¬í•¨ì´ë€ ë§ì´ ì €ê²Œ ì„¸ì „ê¸ˆì•¡ì´ë¼ëŠ”ê±´ê°€? ì„¸ê¸ˆ ë–¼ë„ ì§­ì˜ í•˜ê² ëŠ..', 'ìµœì†Œ 180ì€ ë˜ê² ëˆ„.. 180 ë°›ëŠ” ë…ì„œì‹¤ ë˜ê²ë„¤,,', 'ì €ê±° ê²…ê³ ë¬¸ ë³´ë‹ˆê°€ ì´ê±´ ã„¹ã…‡ ìˆ˜ìš”ì¡°ì‚¬ê³  6ì›”ì— ì„œë¥˜ ë‚´ê³  ë©´ì ‘ê°€ì§€ ë³¸ëŒ€.. í•˜ ë©´ì ‘ìŠ¤í„°ë”” ê° ã…œ', 'ê·¸ë˜ë„ í•„ê¸° ì—†ëŠ”ê²Œ ì–´ë”” ã…', 'ì¸ì ì„± ì—†ë…¸~!', 'Ptë©´ì ‘ì´ë¼ë©´...?!']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_11 \n",
      "Summary before \n",
      " \n",
      "\n",
      "Summary after \n",
      " \"['ì•„ì¹¨ì— ì•ˆë‚˜ê°€ë©´ ì´ ìë¦¬ë¥¼ ì•ˆ ë‚˜ê°€ë©´ ë‚˜ë‘ê±°ê±°ì•¼',''á„‹á„‹á„…'' 'ì•„ë˜ë˜ì„œ ë‚˜ ì´ê±°ì•¼ ì§„ì§œ ì§„ì§œ', 'ì•„ë‹ˆ ì§„ì§œ' 'í•  ìˆ˜ ìˆì„ ë•Œ í•´ì•¼ ë¨', 'ê·¸ëŸ¼ëŸ¼ ì«Œ ë”ìˆ ë•Œì•¼  ìª„ì„œì„œ ì´ëŸ¬ê³  ì§„ì§œ ë†”ì„œ ì´ê±° ì´ê±°ì§„ê±°ì¸ë°ì¸ë° ì´ê±° ì§„ì§œë¡œì¸ë° ê»´ë†¨ì–ì•„'',' 'ë‚˜ 'ì•„ì¹¨ ì¼ì–´ë‚˜ì§€ëŸ¼ ë‚˜ ì§„ì§œ ê°‘ìê¸° ê°‘ìê¸° ì§„ì§œ ì´ê²Œ ë­ì•¼ ì´ê±°ì§€' ë‚˜ ë‚˜ë˜ ì³¤ì–ì•„', 'ë‚˜ ''ë˜ 'ë‹¤'ë‹¤'' 'ê·¸ë˜ì•¼ì— ê¹¬ê±°ë˜\n",
      "\n",
      "Target summary \n",
      " ì˜¤ëŠ˜ ì•ˆ ë‚˜ê°€ë©´ ì¢‹ì€ ìë¦¬ë¥¼ ëºê¸¸ ê²ƒ ê°™ì•˜ë‹¤ë©° í”¼ê³¤í•´ë„ ê°€ê¸°ë¥¼ ì˜ í•œ ê²ƒ ê°™ë‹¤ê³  í•œë‹¤.\n",
      "\n",
      "Text ['ì•„ì¹¨ì— ê¹¬ê±°ê±°ë“  í”¼ê³¤í•´ì„œ ê°ˆê¹Œë§ê¹Œ ê³ ë¯¼í–‡ëŠ”ë° ì§€ê¸ˆ ì´ê±° ê³„ì•½ê¸°ê°„ì´ë¼ ê°œë°”ë¹ ì„œ ë‚´ê°€ì˜¤ëŠ˜ ì•ˆë‚˜ê°€ë©´ ì´ ìë¦¬ë¥¼ ëºê¸¸ê±°ê°™ì€ê±°ì•¼', 'ã…‡ã…‡ã…‡ã…‡ ê·¸ë¦¬ê³  ì´ëŸ° ì¢‹ì€ìë¦¬ëŠ”', 'ê·¸ë˜ì„œ ê¸¸ê²Œë³´ì ì´ëŸ¬ê³  ì§„ì§œ', 'í•  ìˆ˜ ìˆì„ ë•Œ í•´ì•¼ ë¨', 'ë‚˜ ì§„ì§œ ì˜ë ¤í–‡ëŠ”ë° ì§„ì§œ ê°‘ìê¸° ë§˜ë°”ê»´ì„œ ì¼ì–´ë‚¬ì–ì•„']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_12 \n",
      "Summary before \n",
      " \n",
      "\n",
      "Summary after \n",
      " \"[' \"['''' '', 'ê±°ë´ì„œ ê·¸ê±°ê±° ë‚˜ë‘ê·¸ê±°ë‘ ë‚˜ ë‚˜ ë°”ë¡œì¶œê·¼ ê°€ëŠ¥í•˜ë‹¤í–ˆê±° ì«Œ' 'ì•„ 'ì•„'',' 'á„á„'á„  á„‹á„',', 'ì´ë¦„#' ë­? ê·¼ë° ì´ê±° ë­ë­?? ê·¸ëŸ¼ ë‚˜í•œí…Œë„ ì–˜ê¸°í–ˆì–´ì–´?', 'ë‚˜'ê·¸ëŸ¼ ê·¸ëŸ¼ ê·¸ëŸ¼ ë‚˜ ì¢€ ë­ ë­ì•¼?'ê·¸ëŸ¼', 'ê·¸ 'ëŸ¼ëŸ¼ ê·¸ëŸ¼ ë˜ ì¢€ ë‚˜ì•¼ì§€', ê·¸ëŸ¼ 'ì•¼ 'ë‹¤'', 'ì•„ ì¢€ ë†€ì•„ì•¼ì§€....', 'ì–´ 'ì–´ê±°ì§„ á…²','ì™€ 'ë‚´ê°€ ì¸ì• \n",
      "\n",
      "Target summary \n",
      " ì—…ë¬´ ì„¤ëª… ê²¸ ë¶€ë¥¸ ëŠë‚Œì´ì—ˆê³  ì†Œì¥ë‹˜ì´ ì¸ìƒ ê³„íšì„ ë¬¼ì–´ë³´ì…¨ì§€ë§Œ ëŒ€ë‹µì„ í•˜ì§€ ëª»í–ˆë‹¤.\n",
      "\n",
      "Text ['ì˜ë°›ë”#@ì´ë¦„#?', 'ë¨¸ë¥´ê°œì¨ ê·¼ë°ë­”ê°€ ì´ë¯¸ì •í•´ì ¸4ê³  ê·¸ì ¼ì— ì—…ë¬´ì„¤ëª…ê²¸ ë¶€ë¥¸ëŠë‚Œ ë‚˜ ë°”ë¡œì¶œê·¼ ê°€ëŠ¥í•˜ë‹¤í–ˆë¯„ë° ë‚´ì¼ë¶€í„° ë‚˜ì˜¤ë¼í•˜ì§„ì•Šê²ì§€ ëœëœì“° ë‚´ì¼ ì¼ì‡ëŠ”ê±°ê¹Œë¨¸ê¸ˆ', 'ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ ë­ë¬¼ì–´ë´ì¨? ì†Œì¥ë‹˜ì´ë‘ã…‡ë„ ì–˜ê¸°í–ˆì–´?', 'ì•¼ #@ì´ë¦„#ì•„ ì¢€ ë†€ì•„ì•¼ì§€ã… ', 'ì›… ì†Œì¥ë‹˜ì´ ì¸ì…ê³„íš ë¬¼ì–´ë´„ ; ëŒ€ë‹µëª»í•¨ ã… ;;;', 'ã…‹ã…‹ã…‹ã„´ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ ë­” ã…  í•˜ë£¨ì‚´ì´ë“¤ í•œí…Œ ì¸ìƒê³„íš;;']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_13 \n",
      "Summary before \n",
      " 'ë¬´ë¬´ìŠ¨ë¶€ì„œì•¼', 'í˜‘ë ¥ì„¼í„°ë° ë­ ë³‘ì›ì— í™˜ìì˜ë¢°í•˜ê³ ì´ëŸ°\n",
      "\n",
      "Summary after \n",
      " \"['''''', 'ì‘ì‘'ë° ë­ ë­ë­ë­?','  'ê±”ë„¤ë„¤ ë­ë“  ì…ì‚¬ë“ ë“ ì— ë­ë“ ì§€ ì…ì‚¬í•˜ë©´',', ì¼ë‹¨ ì¼ë‹¨ ë­ë“ ê°€ë“ ê°€ë“ 'ë‹¤'', 'ë‹¤ 'ë‹¤ì›Œì•¼í•˜ë‹ˆê¹Œ']' ['ews'...' 'ë‹¤''s'?' ë‚˜'>'ìë£Œ'..' 'ë‚˜'t'ë„¤' ìˆ'í–‡' 'ê°œ '...''ë¬´ìŠ¨ë¶€ì„œì•¼', 'ìš°ë¦¬''ì´' ë­ë„¤'ë­ ê·¸ë„¤', ë­ ê·¼ë° ë­', 'ì•„ 'ë­ ë­ì—', 'ê·¸'ê·¸ ë­ ì €ê¸° ë­ì•¼', 'ì´ëŸ°ì €ëŸ°\n",
      "\n",
      "Target summary \n",
      " ë³¸ì¸ì˜ ê¸°ì¡´ ë¶„ì•¼ì™€ ë‹¤ë¥¸ ë¶€ì„œë¡œ ì…ì‚¬í•˜ê²Œ ë˜ì—ˆë‹¤.\n",
      "\n",
      "Text ['ë¬´ìŠ¨ë¶€ì„œì•¼', 'í˜‘ë ¥ì„¼í„°ë° ë­ ë³‘ì›ì— í™˜ìì˜ë¢°í•˜ê³ ì´ëŸ°ê±°ê°™ì•„', 'ì˜¤  ì–´ë µêµ° ë„ˆë¶„ì•¼ë‘ì€ ì¢€ ë‹¤ë¥´ì§€??', 'ê¸€ì¹˜ ê·¼ë°ë­ ì–´ë””ë“  ì…ì‚¬í•˜ë©´ ìƒˆë¡œë°°ì›Œì•¼í•˜ë‹ˆê¹Œ']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_14 \n",
      "Summary before \n",
      " \n",
      "\n",
      "Summary after \n",
      " \"['#@ì´ë¦„# 3d ì´ë¯¸ì§€ í•˜ë‚˜ë§Œ ë§Œë“¤ì–´ ì¤„ìˆ˜ìˆì–´',''' ì˜¤ë¹  ì˜¤ë¹ í•œí…Œ ë¶€íƒí•˜ì§€ë§ˆ.. ì˜¤ë¹ ê°€ í•˜êµ¬ìˆìˆì • ì–´ê±°ê±°ì§€ë£¨ á„’á„’ ê·¸ë¦¼íŒìœ¼ë¡œ ë ìˆ˜ ìˆì„ê±° ê°™ìŒ ì˜¤ë¹  ì»´í„° ì˜í•´!',', 'ë¬´ìŠ¨ 3 4ì¼ì„ ì˜¤ë¹  ì•„ë²„ì§€í•œí…Œ ì‹œì¼œ',' 'ë„¤', 'ì•„''ê·¸ë ¸ë‹¤', 'ê·¸ë¦¼ì§•', ì˜¤ë¹ ëŠ” 'ë””ìì´ë„ˆ ë½‘ìœ¼ìœ¼ë¼...'' ë‚˜í•œí…Œ...', 'ì˜¤ ì˜¤ë¹ , 'ì—ë‹¤ á„…á„…ì´í‹€ ìƒµ## ì«Œ í•˜ë‚˜, í•˜ë‚˜ í•˜ë‚˜ë„ë§Œë§Œ\n",
      "\n",
      "Target summary \n",
      " ì˜¤ë¹ ì—ê²Œ ì“°ë¦¬ë””(3D) ì´ë¯¸ì§€ ì‘ì—… ì¼ì„ ë¶€íƒí•˜ê³  ìˆë‹¤.\n",
      "\n",
      "Text ['#@ì´ë¦„# 3d ì´ë¯¸ì§€ í•˜ë‚˜ë§Œ ë§Œë“¤ì–´ ì¤„ìˆ˜ìˆì—‰?', 'íšŒì‚¬ì¼ ë‚˜í•œí…Œ ë¶€íƒí•˜ì§€ë§ˆ.. ì˜¤ë¹ ê´€ë ¨ëœê±° ì•„ë‹ˆë©´', 'ì˜¤ë¹ ê°€ í•˜êµ¬ìˆì • ì–´ê±°ì§€ë£¨ ã…ã… ê·¸ë¦¼íŒìœ¼ë¡œ ë ìˆ˜ìˆì„ê±° ê°™ì—¥ ì˜¤ë¹  ì»´í„° ì˜í•´!', 'ë¬´ìŠ¨ 3dì¼ì„ ì˜¤ë¹ í•œí…Œ ì‹œì¼œ', 'ì˜ê·¸ë ¸ì§•', 'ë””ìì´ë„ˆ ë½‘ìœ¼ë¼í•´']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_15 \n",
      "Summary before \n",
      " \n",
      "\n",
      "Summary after \n",
      " \"['''''',' ë‹¤' 'ë‹¤'ë‹¤''  'ë„¤',','ë˜ 'ë˜ á„…', 'ì›ë˜ë˜'!!'~'ë‹¤']']] [' 'ì¼ë‹¹''ì¼'ì¼ë‹¹'...' '', 'ì—¬', 'ê·¸ 'ë '?''ì•„ '.... á„ƒá„ƒ', '.. 'ë¥´ë¥´ 'ë‹¤. 'ì•— ì«Œ á„‹..ë„¤'ë„¤ë‹¤' ì—¥'ê·¸ê±¸' 'ì•„ 'ì•„' ì´ê±° 'ìª„ìª„ ìª„', ì´ìƒ ë¹• 'ì— m2 'á„ƒ'á„… ', 'ì•„ ëƒ¥ '...' ìŸˆ á…¡\n",
      "\n",
      "Target summary \n",
      " ì¼ë‹¹ì€ ì›ë˜ ì‹­ë§Œ ì›ì¸ë° í—ˆë¸ŒëŠ” ì¡°ê¸ˆ ë” ì¤˜ì„œ 11ë§Œ ì›ì´ë‹¤.\n",
      "\n",
      "Text ['ì¼ë‹¹ ì–¼ë§ˆì—¬', 'ë”± ê·¸ëŸ°ë“¯ ë‚˜ ã…ã„¹', 'ì—¥', 'ì›ë˜ ì‹­ë§Œì› 11ë§Œì›ì´ë‹¤~ìƒê°í–ˆëŠ”ë”” í—ˆë¸ŒëŠ” ì«Œë”ì¤€ëŒ€']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(summaries_after_tuning)):\n",
    "    print('idx_{} '.format(i))\n",
    "    print(\"Summary before \\n\", summaries_before_tuning[i])\n",
    "    print()\n",
    "    print(\"Summary after \\n\", summaries_after_tuning[i])\n",
    "    print()\n",
    "    print(\"Target summary \\n\", test_samples[\"Summary\"][i])\n",
    "    print()\n",
    "    print('Text', test_samples[\"Text\"][i])\n",
    "    print('-'*100)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaeda34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "987e976b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ê·¸ëŸ¼ ë‚ ì§œëŠ” ê°€ê²© í° ë³€ë™ ì—†ìœ¼ë©´ 6.28-7.13ë¡œ í™•ì •í• ê¹Œ?', 'ìš°ë¦¬ ë¹„í–‰...</td>\n",
       "      <td>ë¹„í–‰ê¸° í‘œ ê°€ê²©ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ë©°, íŠ¹ê°€ ì´ë²¤íŠ¸ë¥¼ ê¸°ë‹¤ë¦¬ê³  ìˆë‹¤.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Kfë§ˆìŠ¤í¬ë§Œ 5ë¶€ì œ í•˜ëŠ”ê±°ì§€?', 'ì‘. ë©´ë§ˆìŠ¤í¬ëŠ” ì•„ë¬´ë•Œë‚˜ ì‚¬ë„ë ê»€?', 'ë©´...</td>\n",
       "      <td>ë¹„ì—¼ì´ ìˆì–´ì„œ ì‹¸ê²Œ ë‚˜ì˜¨ ì¼íšŒìš© ë¶€ì§í¬ ë§ˆìŠ¤í¬ë¥¼ ì‚¬ë‘ë ¤ê³  í•œë‹¤.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['ì•„ ê·¼ë° ì¼€ì´í¬ ì—…ì²´ë“¤ ë´¤ëŠ”ë° ì¤‘ì•™ë™ìª½ ê±°ê¸°ëŠ” ë§›ë§Œìˆê³  ë””ìì¸ì€ ê·¸ëƒ¥ê·¸ëŸ°ê²ƒê°™ì• '...</td>\n",
       "      <td>ì¼€ì´í¬ ì—…ì²´ ì¤‘ ì¤‘ì•™ë™ ìª½ì€ ë§›ë§Œ ìˆê³  ë””ìì¸ì€ ë³„ë¡œê³  ê³ ì”ë™ ì¼€ì´í¬ ì—…ì²´ëŠ” ë°°ë‹¬ë„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['ì¹«ì†”ì‚¬ì•¼í•˜ëŠ”ë° ì“±ìœ¼ë¡œ ì‚´ê¹Œ?', 'ë­˜ ì¹«ì†”ì‚¬ëŠ”ê²ƒê¹Œì§€ ë¬¼ì–´ë³´ì‹œë‚¨ã…‹ã…‹ã…‹', 'ì•„ ê·¸...</td>\n",
       "      <td>ì¹«ì†”ì„ 3ê°œì›”ì— í•˜ë‚˜ì”© ë°”ê¿”ì„œ ì™• ì¹«ì†” ì‚¬ëŸ¬ ì‹ ì„¸ê³„(ì“±) ê°€ìê³  í–ˆë‹¤.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['ì ë„ì•ˆì˜¤ë„¤ã…ì–¼ë¦‰ ê³ êµ¬ë§ˆì¸„ ë¨¹ê³ ì‹¶ë‹¨', 'ê·¸ê²Œ ê·¸ë ‡ê²Œ ë§›ìˆì—ˆì–´??? ì•„ì£¼ ì—¬ë³´ ë¹¼...</td>\n",
       "      <td>ì ë„ ì•ˆ ì™€ì„œ ê³ êµ¬ë§ˆ ë§ë­ì´ë¥¼ ì–‘ì‹¬ìƒ í•˜ë‚˜ë§Œ ë¨¹ìœ¼ë ¤ê³  í•œë‹¤.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  ['ê·¸ëŸ¼ ë‚ ì§œëŠ” ê°€ê²© í° ë³€ë™ ì—†ìœ¼ë©´ 6.28-7.13ë¡œ í™•ì •í• ê¹Œ?', 'ìš°ë¦¬ ë¹„í–‰...   \n",
       "1  ['Kfë§ˆìŠ¤í¬ë§Œ 5ë¶€ì œ í•˜ëŠ”ê±°ì§€?', 'ì‘. ë©´ë§ˆìŠ¤í¬ëŠ” ì•„ë¬´ë•Œë‚˜ ì‚¬ë„ë ê»€?', 'ë©´...   \n",
       "2  ['ì•„ ê·¼ë° ì¼€ì´í¬ ì—…ì²´ë“¤ ë´¤ëŠ”ë° ì¤‘ì•™ë™ìª½ ê±°ê¸°ëŠ” ë§›ë§Œìˆê³  ë””ìì¸ì€ ê·¸ëƒ¥ê·¸ëŸ°ê²ƒê°™ì• '...   \n",
       "3  ['ì¹«ì†”ì‚¬ì•¼í•˜ëŠ”ë° ì“±ìœ¼ë¡œ ì‚´ê¹Œ?', 'ë­˜ ì¹«ì†”ì‚¬ëŠ”ê²ƒê¹Œì§€ ë¬¼ì–´ë³´ì‹œë‚¨ã…‹ã…‹ã…‹', 'ì•„ ê·¸...   \n",
       "4  ['ì ë„ì•ˆì˜¤ë„¤ã…ì–¼ë¦‰ ê³ êµ¬ë§ˆì¸„ ë¨¹ê³ ì‹¶ë‹¨', 'ê·¸ê²Œ ê·¸ë ‡ê²Œ ë§›ìˆì—ˆì–´??? ì•„ì£¼ ì—¬ë³´ ë¹¼...   \n",
       "\n",
       "                                             Summary  \n",
       "0               ë¹„í–‰ê¸° í‘œ ê°€ê²©ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ë©°, íŠ¹ê°€ ì´ë²¤íŠ¸ë¥¼ ê¸°ë‹¤ë¦¬ê³  ìˆë‹¤.  \n",
       "1                ë¹„ì—¼ì´ ìˆì–´ì„œ ì‹¸ê²Œ ë‚˜ì˜¨ ì¼íšŒìš© ë¶€ì§í¬ ë§ˆìŠ¤í¬ë¥¼ ì‚¬ë‘ë ¤ê³  í•œë‹¤.  \n",
       "2  ì¼€ì´í¬ ì—…ì²´ ì¤‘ ì¤‘ì•™ë™ ìª½ì€ ë§›ë§Œ ìˆê³  ë””ìì¸ì€ ë³„ë¡œê³  ê³ ì”ë™ ì¼€ì´í¬ ì—…ì²´ëŠ” ë°°ë‹¬ë„...  \n",
       "3            ì¹«ì†”ì„ 3ê°œì›”ì— í•˜ë‚˜ì”© ë°”ê¿”ì„œ ì™• ì¹«ì†” ì‚¬ëŸ¬ ì‹ ì„¸ê³„(ì“±) ê°€ìê³  í–ˆë‹¤.  \n",
       "4                  ì ë„ ì•ˆ ì™€ì„œ ê³ êµ¬ë§ˆ ë§ë­ì´ë¥¼ ì–‘ì‹¬ìƒ í•˜ë‚˜ë§Œ ë¨¹ìœ¼ë ¤ê³  í•œë‹¤.  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "377fe56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ì›…', 'ì˜ì—…íŒ€ê³¼ì¥ë‹˜ì´ ë³´ë‚´ì¤¬ëŠ”ë° íŒ€ì¥ë‹˜ì´ í•´ì¤„ì§€ ëª¨ë¥´ê² ë‹¤ ì €ë²ˆì— ë¶€ì‚°ê°ˆë•Œë„ ìˆ™...</td>\n",
       "      <td>íŒ€ì¥ë‹˜ì´ ì¶œì¥ ê°€ì„œ ë¨¸ë¬¼ ìˆ™ì†Œë¥¼ ê³„ì†í•´ì„œ ë” ì‹¼ ë°ë¡œ í•˜ê²Œ í•œë‹¤ê³  ì´ì•¼ê¸°í•˜ê³  ìˆë‹¤.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['ë„ˆëŠ” ì˜ê°€ë¼....íšŒì‚¬.... ì„ íƒ ì˜í•´..', 'ì•Œê² ì–´ ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ ë§...</td>\n",
       "      <td>ì´ì œ ì´ë ¥ì„œë¥¼ ì“°ê³  ì˜ì–´ë„ í•´ì•¼ í•œë‹¤ê³  í•´ì„œ ì²« íšŒì‚¬ë¥¼ ì˜ ë“¤ì–´ê°€ë¼ê³  í–ˆë‹¤.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['ëŠë‚Œìƒ ëŒ€í†µë ¹ê¹Œì§€ëŠ” ì•„ë‹ˆê³  ì˜¤ì‹œë©´ ì—¬ì‚¬ë‹˜ì •ë„ì˜¤ì‹œì§€ì•Šì„ê¹Œ ã…‹ã…‹ã…‹', 'ê·¸ëŸ¬ë©´ì„œ',...</td>\n",
       "      <td>ëŠë‚Œìƒ ëŒ€í†µë ¹ê¹Œì§€ëŠ” ì•„ë‹ˆê³  ì˜¤ì‹œë©´ ì—¬ì‚¬ë‹˜ ì •ë„ ì˜¤ì‹œì§€ ì•Šì„ê¹Œë¼ë©° ì´ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['ìˆ¨ë§Œìˆ˜ì´ã…“ë„ ìˆ¨ë§Œì‰¬ì–´ë„ 100 ì´ë‚´', 'í•œë‹¬ì•ˆì— ì¼ ë¬´ì¡°ê±´ í•´ì•¼ëŒ€', 'ì•„ ë”±...</td>\n",
       "      <td>í•œ ë‹¬ ì•ˆì— ë¬´ì¡°ê±´ ì¼ì„ ì‹œì‘í•´ì„œ ëˆì„ ë²Œì–´ì•¼ í•œë‹¤.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['ëª©ìš”ì¼ì€ ì™¸ê·¼ì´êµ¬ ê¸ˆìš”ì¼ì€ ì¶œì¥!!!', 'ê¸ˆìš”ì¼ì´ ë‹¹ì§„ì´ì–‘?', 'ì•„ë‹ì•„ë‹ 1...</td>\n",
       "      <td>ëª©ìš”ì¼ì— ì™¸ê·¼ì´ê³  ê¸ˆìš”ì¼ì— ì¶œì¥ì¸ë° ë‹¹ì§„ì€ 10ì¼ì— ê°„ë‹¤.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  ['ì›…', 'ì˜ì—…íŒ€ê³¼ì¥ë‹˜ì´ ë³´ë‚´ì¤¬ëŠ”ë° íŒ€ì¥ë‹˜ì´ í•´ì¤„ì§€ ëª¨ë¥´ê² ë‹¤ ì €ë²ˆì— ë¶€ì‚°ê°ˆë•Œë„ ìˆ™...   \n",
       "1  ['ë„ˆëŠ” ì˜ê°€ë¼....íšŒì‚¬.... ì„ íƒ ì˜í•´..', 'ì•Œê² ì–´ ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ ë§...   \n",
       "2  ['ëŠë‚Œìƒ ëŒ€í†µë ¹ê¹Œì§€ëŠ” ì•„ë‹ˆê³  ì˜¤ì‹œë©´ ì—¬ì‚¬ë‹˜ì •ë„ì˜¤ì‹œì§€ì•Šì„ê¹Œ ã…‹ã…‹ã…‹', 'ê·¸ëŸ¬ë©´ì„œ',...   \n",
       "3  ['ìˆ¨ë§Œìˆ˜ì´ã…“ë„ ìˆ¨ë§Œì‰¬ì–´ë„ 100 ì´ë‚´', 'í•œë‹¬ì•ˆì— ì¼ ë¬´ì¡°ê±´ í•´ì•¼ëŒ€', 'ì•„ ë”±...   \n",
       "4  ['ëª©ìš”ì¼ì€ ì™¸ê·¼ì´êµ¬ ê¸ˆìš”ì¼ì€ ì¶œì¥!!!', 'ê¸ˆìš”ì¼ì´ ë‹¹ì§„ì´ì–‘?', 'ì•„ë‹ì•„ë‹ 1...   \n",
       "\n",
       "                                             Summary  \n",
       "0     íŒ€ì¥ë‹˜ì´ ì¶œì¥ ê°€ì„œ ë¨¸ë¬¼ ìˆ™ì†Œë¥¼ ê³„ì†í•´ì„œ ë” ì‹¼ ë°ë¡œ í•˜ê²Œ í•œë‹¤ê³  ì´ì•¼ê¸°í•˜ê³  ìˆë‹¤.  \n",
       "1         ì´ì œ ì´ë ¥ì„œë¥¼ ì“°ê³  ì˜ì–´ë„ í•´ì•¼ í•œë‹¤ê³  í•´ì„œ ì²« íšŒì‚¬ë¥¼ ì˜ ë“¤ì–´ê°€ë¼ê³  í–ˆë‹¤.  \n",
       "2  ëŠë‚Œìƒ ëŒ€í†µë ¹ê¹Œì§€ëŠ” ì•„ë‹ˆê³  ì˜¤ì‹œë©´ ì—¬ì‚¬ë‹˜ ì •ë„ ì˜¤ì‹œì§€ ì•Šì„ê¹Œë¼ë©° ì´ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜...  \n",
       "3                      í•œ ë‹¬ ì•ˆì— ë¬´ì¡°ê±´ ì¼ì„ ì‹œì‘í•´ì„œ ëˆì„ ë²Œì–´ì•¼ í•œë‹¤.  \n",
       "4                   ëª©ìš”ì¼ì— ì™¸ê·¼ì´ê³  ê¸ˆìš”ì¼ì— ì¶œì¥ì¸ë° ë‹¹ì§„ì€ 10ì¼ì— ê°„ë‹¤.  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bc61bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF > data Setìœ¼ë¡œ ì „í™˜\n",
    "train_len = len(train_df) // 4\n",
    "train_data = Dataset.from_pandas(train_df[:train_len]) \n",
    "val_len = len(val_df) // 2\n",
    "val_data = Dataset.from_pandas(val_df[:val_len])\n",
    "test_data=Dataset.from_pandas(val_df[val_len:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d5e1cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(features: {'Text': Value(dtype='string', id=None), 'Summary': Value(dtype='string', id=None)}, num_rows: 69998)\n",
      "Dataset(features: {'Text': Value(dtype='string', id=None), 'Summary': Value(dtype='string', id=None)}, num_rows: 17502)\n",
      "Dataset(features: {'Text': Value(dtype='string', id=None), 'Summary': Value(dtype='string', id=None)}, num_rows: 17502)\n"
     ]
    }
   ],
   "source": [
    "print(train_data)\n",
    "print(val_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b842744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input = 128\n",
    "max_target = 128\n",
    "batch_size = 4\n",
    "\n",
    "#\"digit82/kobart-summarization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7dbf744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data_to_process):\n",
    "  #get all the dialogues\n",
    "  inputs = [dialogue for dialogue in data_to_process['Text']]\n",
    "  #tokenize the dialogues\n",
    "  model_inputs = tokenizer(inputs,  max_length=max_input, padding='max_length', truncation=True)\n",
    "  #tokenize the summaries\n",
    "  with tokenizer.as_target_tokenizer():\n",
    "    targets = tokenizer(data_to_process['Summary'], max_length=max_target, padding='max_length', truncation=True)\n",
    "    \n",
    "  #set labels\n",
    "  model_inputs['labels'] = targets['input_ids']\n",
    "  #return the tokenized data\n",
    "  #input_ids, attention_mask and labels\n",
    "  return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "688b01c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3546: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d59dc792c8a4733b8cad96f9122c3ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d4ac2acc79476b909d3ed9e335ceed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_tokenize_data = train_data.map(preprocess_data, batched = True, remove_columns=['Text', 'Summary'])\n",
    "val_tokenize_data = val_data.map(preprocess_data, batched = True, remove_columns=['Text', 'Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "118acd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9825070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set special tokens\n",
    "# #from transformers import EncoderDecoderConfig\n",
    "# model.config.decoder_start_token_id = tokenizer.bos_token_id                                             \n",
    "# model.config.eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# sensible parameters for beam search\n",
    "# set decoding params                               \n",
    "model.config.max_length = 128 # 256ì€ ì¿ ë‹¤ ë©”ëª¨ë¦¬ ì˜¤ë¥˜ ìƒê¹€\n",
    "model.config.early_stopping = True\n",
    "model.config.no_repeat_ngram_size = 2\n",
    "model.config.length_penalty = 2.0\n",
    "model.config.num_beams = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0fd58ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = datasets.load_metric(\"rouge\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # all unnecessary tokens are removed\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge1\"])[\"rouge1\"].mid\n",
    "    rouge_output2 = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
    "    rouge_outputL = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rougeL\"])[\"rougeL\"].mid\n",
    "    \n",
    "\n",
    "    return {\n",
    "        \"rouge1_precision\": round(rouge_output.precision, 4),\n",
    "        \"rouge1_recall\": round(rouge_output.recall, 4),\n",
    "        \"rouge1_fmeasure\": round(rouge_output.fmeasure, 4),\n",
    "        \n",
    "        \"rouge2_precision\": round(rouge_output2.precision, 4),\n",
    "        \"rouge2_recall\": round(rouge_output2.recall, 4),\n",
    "        \"rouge2_fmeasure\": round(rouge_output2.fmeasure, 4), \n",
    "        \n",
    "        \"rougeL_precision\": round(rouge_outputL.precision, 4),\n",
    "        \"rougeL_recall\": round(rouge_outputL.recall, 4),\n",
    "        \"rougeL_fmeasure\": round(rouge_outputL.fmeasure, 4),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e86fb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"results221115\",\n",
    "    num_train_epochs=1,  # demo\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=16,  # demo\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=3e-05,\n",
    "    warmup_steps=50,\n",
    "    weight_decay=0.1,\n",
    "    label_smoothing_factor=0.1,\n",
    "    predict_with_generate=True, # ìƒì„±ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ê³  ì‹¶ë‹¤ê³  ì§€ì •í•œë‹¤.\n",
    "    logging_dir=\"logs2\",\n",
    "    logging_steps=50,\n",
    "    save_total_limit=3,\n",
    "    max_steps=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e93ce6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDataCollatorForSeq2Seq ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì œ ë°°ì¹˜ë¥¼ ìƒì„± í•˜ì‹­ì‹œì˜¤ . \\në˜í•œ ì¼ê´„ ì²˜ë¦¬ì—ì„œ ê°€ì¥ ê¸´ ìš”ì†Œì˜ ê¸¸ì´ë¡œ í…ìŠ¤íŠ¸ì™€ ë ˆì´ë¸”ì„ ë™ì ìœ¼ë¡œ ì±„ì›Œì„œ ê· ì¼í•œ ê¸¸ì´ê°€ ë˜ë„ë¡ í•©ë‹ˆë‹¤.\\ntokenizerë¥¼ ì„¤ì •í•˜ì—¬ í•¨ìˆ˜ ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì±„ìš¸ ìˆ˜ ìˆì§€ë§Œ padding=Trueë™ì  íŒ¨ë”©ì´ ë” íš¨ìœ¨ì ì…ë‹ˆë‹¤.\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model) # ë°ì´í„° ì¼ê´„ ì²˜ë¦¬?\n",
    "\"\"\"\n",
    "DataCollatorForSeq2Seq ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì œ ë°°ì¹˜ë¥¼ ìƒì„± í•˜ì‹­ì‹œì˜¤ . \n",
    "ë˜í•œ ì¼ê´„ ì²˜ë¦¬ì—ì„œ ê°€ì¥ ê¸´ ìš”ì†Œì˜ ê¸¸ì´ë¡œ í…ìŠ¤íŠ¸ì™€ ë ˆì´ë¸”ì„ ë™ì ìœ¼ë¡œ ì±„ì›Œì„œ ê· ì¼í•œ ê¸¸ì´ê°€ ë˜ë„ë¡ í•©ë‹ˆë‹¤.\n",
    "tokenizerë¥¼ ì„¤ì •í•˜ì—¬ í•¨ìˆ˜ ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì±„ìš¸ ìˆ˜ ìˆì§€ë§Œ padding=Trueë™ì  íŒ¨ë”©ì´ ë” íš¨ìœ¨ì ì…ë‹ˆë‹¤.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9dbf3f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model, \n",
    "    training_args,\n",
    "    train_dataset=train_tokenize_data,\n",
    "    eval_dataset=val_tokenize_data,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e15bc7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 69998\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 100\n",
      "  Number of trainable parameters = 123859968\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjx7789\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/aiffel/aiffel/Korean_Conversation_Summary/wandb/run-20221115_075519-3sr32gmm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jx7789/huggingface/runs/3sr32gmm\" target=\"_blank\">results221115</a></strong> to <a href=\"https://wandb.ai/jx7789/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 00:53, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>8.887000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.974600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=5.930811614990234, metrics={'train_runtime': 56.9912, 'train_samples_per_second': 28.075, 'train_steps_per_second': 1.755, 'total_flos': 121947291648000.0, 'train_loss': 5.930811614990234, 'epoch': 0.02})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7b470c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17502\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='1094' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  37/1094 01:23 < 40:39, 0.43 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_266/2732109216.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/trainer_seq2seq.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gen_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     def predict(\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2795\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2796\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   2797\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2973\u001b[0m             \u001b[0;31m# Prediction step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2974\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2975\u001b[0m             \u001b[0minputs_decode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_inputs_for_metrics\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/trainer_seq2seq.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0mgeneration_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_input_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         generated_tokens = self.model.generate(\n\u001b[0m\u001b[1;32m    199\u001b[0m             \u001b[0mgeneration_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mgen_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[1;32m   1575\u001b[0m             )\n\u001b[1;32m   1576\u001b[0m             \u001b[0;31m# 12. run beam search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m             return self.beam_search(\n\u001b[0m\u001b[1;32m   1578\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2764\u001b[0m             )  # (batch_size * num_beams, vocab_size)\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2766\u001b[0;31m             \u001b[0mnext_token_scores_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_token_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2767\u001b[0m             \u001b[0mnext_token_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_token_scores_processed\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeam_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_token_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/generation_logits_process.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_ids, scores, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/generation_logits_process.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_ids, scores)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbanned_tokens\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbanned_batch_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbanned_tokens\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b359950e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /aiffel/.cache/huggingface/hub/models--gogamza--kobart-base-v2/snapshots/d9a1f640896cef8dcfd693b1bc57510a2b09a18f/config.json\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"gogamza/kobart-base-v2\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.1,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"kobart_version\": 2.0,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 1026,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"tokenizer_class\": \"PreTrainedTokenizerFast\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /aiffel/.cache/huggingface/hub/models--gogamza--kobart-base-v2/snapshots/d9a1f640896cef8dcfd693b1bc57510a2b09a18f/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at gogamza/kobart-base-v2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 128 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def generate_summary(test_samples, model):\n",
    "    inputs = tokenizer(\n",
    "        test_samples[\"Text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_target,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    input_ids = inputs.input_ids.to(model.device)\n",
    "    \n",
    "    attention_mask = inputs.attention_mask.to(model.device)\n",
    "    outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
    "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return outputs, output_str\n",
    "\n",
    "\n",
    "model_before_tuning = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoints)# ì—¬ê¸°ì— ê¸°ë³¸ kobartê°€ì ¸ì˜¤ê¸°?\n",
    "import random\n",
    "from random import randrange\n",
    "test_samples = test_data.select(range(16))# 0, len(test_data), 200\n",
    "\n",
    "summaries_before_tuning = generate_summary(test_samples, model_before_tuning)[1]\n",
    "summaries_after_tuning = generate_summary(test_samples, model)[1] # ì—¬ê¸°ì— ì²´í¬í¬ì¸íŠ¸ ê°€ì ¸ì˜¤ê¸° \n",
    "# ì—°êµ¬í•´ë´ì•¼í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d7e3a85",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx_0 \n",
      "Summary before \n",
      " \n",
      "\n",
      "Summary after \n",
      " ì…”ì¸ ì„ì„ ì‚¬ê³  ì‹¶ë‹¤ê³  í•œë‹¤.\n",
      "\n",
      "Target summary \n",
      " ê³§ ìœ ë£Œí™”ë˜ëŠ” ì›¹íˆ°ì„ ë³´ê³  ì¬ë¯¸ìˆìœ¼ë©´ ë§í•´ì£¼ê² ë‹¤.\n",
      "\n",
      "Text ['ì›¹íˆ°ë³¼ê·¸ì•¼??ã…‹ã…‹', 'ì•ˆìë©´ë°”ì•¼ì§€ ê³§ìœ ë£Œí™”ë˜ëŠ”ê²ƒë“¤ ë¨¼ì €ë´ì•¼ì§€ ì´ëŸ°ì˜ì›…ì€ì‹«ì–´ ê´œì°®ë‹¤ë˜ë°? 17ì¼ì¸ê°€ìœ ë£Œí™”', 'ê·¸ê²Œë¨¸ì§€ ì²¨ë“¤ì–´ë³´ëŠ”ë°', 'ë‚˜ë„ëª°ëëŠ”ë° ì¸ê¸°ê¸€ì—ì„œë´¤ì–´', 'ì›…ã…‹ã…‹ã…‹', 'ë³´ê³  ì¬ë°‹ìœ¼ë©´ë§í•´ì¤€ë‹¤~~']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_1 \n",
      "Summary before \n",
      " \n",
      "\n",
      "Summary after \n",
      " ê³ ì–‘ì´ì´ ìœ„ì— ì˜¬ë ¤ë†“ê³  ë…¸ì½”ìƒ·ì„ í•˜ê³  ìˆë‹¤.\n",
      "\n",
      "Target summary \n",
      " ë²ˆê°œì¥í„°ì¸ë° í”¼íì–´ ìƒì„¸ ìƒ·ì„ ê³ ì–‘ì´ ìœ„ì— ì˜¬ë ¤ë†“ê³  ì°ì–´ì„œ ê·€ì—½ë‹¤ê³  ì¥ì‚¬ ì˜ ë˜ê² ë‹¤ê³  í•œë‹¤.\n",
      "\n",
      "Text ['#@ì‹œìŠ¤í…œ#ì‚¬ì§„# ì´ê±°ë°” ë²ˆê°œì¥í„°ì¸ë° ì´ì‚¬ëŒ í”¼ê·œì–´ìƒì„¸ìƒ· ê³ ì–‘ì´ ìœ„ì— ì˜¬ë ¤ë…¸ì½”ì°ìŒ', 'ã…‹ã…‹ã…‹ã…‹ã…‹ê¸°ì—½ë‹¼ã…‹ã…‹ã…‹ã…‹ã…‹ í„¸ë°”ë°”ã…‹ã…‹ã…‹ê³ ì–‘ì´ë§ë„¤', 'ã…£ã„±ã„±ã„±ã„±ì§±ê·€ìš¥ë‹¤', 'Zzzzzzxxxì €ê±¸ ê°€ë§Œíˆ ìˆì–´ì¤¬ë„¤', 'ì˜ë•Œ ì°ì—ˆë‚˜ë´ã…‹ã…‹', 'ì‚¬ì§„ì™„ì „ ì˜ì°ì—ˆë„¤ã…‹ã…‹ã…‹ã…‹ì¥ì‚¬ì˜ë˜ê² ë‹¤']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_2 \n",
      "Summary before \n",
      " 'ë‹¬ë ¥ ë¹¨ë¦¬ ë‚˜ì˜¤ë©´ ë‚´ì¼ ê°–ë‹¤ì£¼ê»˜', 'á„á„á„á„á„á„á„\n",
      "\n",
      "Summary after \n",
      " ë¹¨ë¦¬ ë‚˜ì˜¤ë©´ ë¹¨ë¦¬ ë¹¨ë¦¬ ë‚˜ì™€ì„œ ë¹¨ë¦¬ ë‚˜ì˜¬ ê²ƒ ê°™ë‹¤ê³  í•œë‹¤.\n",
      "\n",
      "Target summary \n",
      " ì˜¤ëŠ˜ ë‹¬ë ¥ì„ ì£¼ë¬¸í•´ì„œ ë‚´ì¼ ì œì‘ì´ ëë‚˜ë‹ˆ ë‚˜ì˜¤ë©´ ë°”ë¡œ ê°€ì ¸ë‹¤ì£¼ê¸°ë¡œ ì•½ì†í•˜ê³  ìˆë‹¤.\n",
      "\n",
      "Text ['ë‹¬ë ¥ ë¹¨ë¦¬ ë‚˜ì˜¤ë©´ ë‚´ì¼ ê°–ë‹¤ì£¼ê»˜', 'ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ì˜¤ì˜¤', 'ì–¸ì œ ì¤„ì§€ ëª¨ë¥´ê² ìŒ ì˜¤ëŠ˜ ì£¼ë¬¸í•´ì„œ ì œì‘ì€ ë‚´ì¼ëë‚ ê±´ë””', 'ê¸ˆìš”ì¼ì•„ì§ ì´í‹€ë‚¨ìŒ', 'ë°”ë¡œ ì£¼ì‹œë ¤ë‚˜ ì•„ ì˜¤ëŠ˜ ìˆ˜ìšœì´ë„¤', 'ã„²ã…‹ã…‹ã…‹ã…‹ ìˆ˜ìš”ì¼ë°–ì— ì•ˆë˜ë‹¤ë‹ˆã…œã…œã…œ', 'êµ¬ë‹ˆê¹Œã…œã…œ']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_3 \n",
      "Summary before \n",
      " \n",
      "\n",
      "Summary after \n",
      " ì ¤íŠ¸ë¡¯ì´ë‹¤ë³´ë‹ˆ ë‚˜ì˜¤ëŠ” ì• ë“¤ ì£„ë‹¤ ë°•í˜„ë¹ˆstë¡œ ë¼ì›Œì„œ ë¼ë–¨ì–´ ëŠ¬ì—„ì„ íŠ•ê²¨ì„œ ì¤ë‹¤.\n",
      "\n",
      "Target summary \n",
      " íŠ¸ë¡¯ì´ë‹¤ì— ë‚˜ì˜¤ëŠ” ì• ë“¤ì´ ëŠë¼í•˜ë‹¤ê³  í•˜ë©´ì„œ ì–´ë¦°ì•„ì´ë“¤ì´ ì œì¼ ë‚«ë‹¤ê³  í•˜ê³  ìˆë‹¤.\n",
      "\n",
      "Text ['íŠ¸ë¡¯ì´ë‹¤ë³´ë‹ˆ ë‚˜ì˜¤ëŠ” ì• ë“¤ ì£„ë‹¤ ë°•í˜„ë¹ˆstë¡œ ë¼ë–¨ì–´ ëŠ¬ë¼í•˜ê²Œã… ã… ã… ', 'ì°¨ë¼ë¦¬', 'ë³´ê¸°ì‹œëŸ¬ã…œê·¸ëŸ°ê±°', 'ì´ˆë”© ë…¸ë˜ì˜í•˜ëŠ” ì• ê°€ ì ¤ë‚˜ìŒ', 'ë‚˜ëˆ„êµ°ì§€ì•Œê±°ê°™ì•„ ê±” ì•Œê±°ê°™ì• ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹', 'ì–´ë¦°ì• ë“¤ì´ ì ¤ ë‚˜ìŒ ã…¡ã…¡']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_4 \n",
      "Summary before \n",
      " \n",
      "\n",
      "Summary after \n",
      " ë‚´ ë°©ì— ë°©ì— í–¥ìˆ˜ë¡œ ë„ë°°ëœê±° ê°™ë‹¤ê³  í•´ì„œ ì§€ê¸ˆ í•œì°¨ë¡€ ë¶“ê³  ì™”ì–´ ëª°ë“œë¼ê³  í•œë‹¤.\n",
      "\n",
      "Target summary \n",
      " ìº”ë“¤ì„ ë§ì´ ë§Œë“¤ê³  ìˆì–´ì„œ ë°©ì´ í–¥ìˆ˜ë¡œ ë„ë°°ëœ ê³µë°©ì´ ëœ ê²ƒ ê°™ë‹¤.\n",
      "\n",
      "Text ['ì´ê²Œë­ì•¼~ ì´ê²Œ ë¨¼ì €ì•¼ ë‚´ ë°©ì— í–¥ìˆ˜ë¡œ ë„ë°°ëœê±°ê°™ì•„ ì§„ì§œ ë”ì° ìº”ë“¤ë„ˆë¬´ë§ì•„ ì§€ê¸ˆ ê³µë°©ëì–´ ì§€ê¸ˆ í•œì°¨ë¡€ ë¶“ê³ ì™”ì–´ ëª°ë“œì—..', 'ì•„ë‹ˆ ë¬´ìŠ¨ ìº”ë“¤ì„ ê·¸ë ‡ê²Œ ë˜ ì •ë„ê°€ ì—†ì´ ë§Œë“¤ê³  ìˆì–´', 'ëª°ë¼ ì§€ê¸ˆ ê°œì›ƒê²¨ ì§€ê¸ˆ í•œ', 'ì•„ì´ë””ì–´ìŠ¤ëƒêµ¬ìš”~', 'ìº”ë“¤ë§Œë“œëŠ”ê±°ë§Œ 3ì¼ë„˜ê²Œ í•˜ê³ ìˆëŠ”ê±°ê°™ì•„']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_5 \n",
      "Summary before \n",
      " \n",
      "\n",
      "Summary after \n",
      " í•œë³µì„ì€ ì±„ í•œ ë°”í€´ë¥¼ ê±¸ì„ ìˆ˜ ìˆë‹¤.\"\"\n",
      "\n",
      "\n",
      "Target summary \n",
      " ì˜¤ëŠ˜ ë§ˆì„ì„ í•œ ë°”í€´ ëŒë©° ê±·ëŠ” ê²ƒì— ëŒ€í•´ ì´ì•¼ê¸°í•œë‹¤.\n",
      "\n",
      "Text ['ê³¼ì—°ì˜¤ëŠ˜ ì–¼ë§ˆë‚˜ê±¸ì„ì§€..', 'ì•„ì§ë„ ê±·ëŠ”ì¤‘~', 'í•œì°¸ë‚¨ì•˜ëˆ™..', 'ã…ã… ê·¸ë ‡ê²Œ ë¨¸ë£¨~', 'ê¸´ì½”ìŠ¤.. ê°•ë‚¨ìí•œë°”í€´', 'ë§ˆì„í•œë°”í€´ì—¬~', 'ã…ã… ë§ˆì„ì´ ë„˜ì»¤..']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_6 \n",
      "Summary before \n",
      " \n",
      "\n",
      "Summary after \n",
      " í‚¬ë§íƒ€ì„ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆë‹¤.\n",
      "\n",
      "Target summary \n",
      " ë„·í”Œë¦­ìŠ¤ ì˜í™”ë¥¼ ì‹œê°„ ë•Œìš°ê¸°(í‚¬ë§íƒ€ì„) ìš©ìœ¼ë¡œ ì¶”ì²œí•œë‹¤.\n",
      "\n",
      "Text ['#@ì‹œìŠ¤í…œ#ì‚¬ì§„# ë„·í”Œã…‹ã…‹ã…‹ã…‹ã…‹ì¶”ì²œì´ìš”ã…‹ã…‹ã…‹ã…‹ ê·¸ëƒ¥ í‚¬ë§íƒ€ì„ìš©ìœ¼ë¡œ ë³¼ë§Œí•œë“¯ã…‹ã…‹ã…‹ã…‹ ëª…ëŒ€ì‚¬ë¼ ìº¡ì³í•´ë´„ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ í—¤ì–´ì§ˆë•Œ ì €ë§í•˜ë©´ ê°œì›ƒê¸¸ë“¯ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹#@ê¸°íƒ€#ã…‹ã…‹ã…‹ã…‹', 'í™©ê¸ˆê°™ì€ ê°€ì„ê¸° ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹', 'ì €ëŸ°ë§ì€ ì–´ë–»ê²Œ ìƒê°í•˜ëŠ”ê±°ì—¬ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹', 'ê·¸ë‹ˆê¹Œ ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹', 'ë°©ê¸ˆ ëŒ€ì‚¬ ë‚˜ì˜¤ëŠ”ë° ì € ì£¼ì¸ê³µì´ ë‚¨ìë“¤ì€ ê°•í•œ ì—¬ìë¥¼ ì¢‹ì•„í•œë‹¤ê³  í•˜ì§€ë§Œ ë§‰ìƒ ì›í•˜ëŠ”ê±´ ì¹˜ì–´ë¦¬ë”ì•¼ ë¼ëŠ”ë°']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_7 \n",
      "Summary before \n",
      " ['ë³¸ë°©ì‚¬ìˆ˜í•œë‹¤...', '#@ì‹œìŠ¤í…œ#ì‚¬ì§„# ê°™ì´ ë‹¬ë¦¬\n",
      "\n",
      "Summary after \n",
      " ë³¸ë°©ì‚¬ìˆ˜í•œë‹¤...\n",
      "\n",
      "Target summary \n",
      " ìˆ¨ì„ ì°¸ê³  ë³¼ ë§Œí¼ ì•…ê·€ê°€ ë„ˆë¬´ ë¬´ì„­ê³  ëª°ì…ë„ê°€ êµ‰ì¥íˆ ë†’ë‹¤.\n",
      "\n",
      "Text ['ë³¸ë°©ì‚¬ìˆ˜í•œë‹¤...', '#@ì‹œìŠ¤í…œ#ì‚¬ì§„# ê°™ì´ ë‹¬ë¦¬ì~~~', 'ì™€ ë°©ê¸ˆ ìˆ¨ ì°¸ê³  ë´¤ë„¤', 'ã…‹ã…‹ã…‹ã…‹ì•…ê·€ ì§„ì§œ ë¬´ì„­ì œã… ã… ã… ', 'ã…‹ã…‹ã…‹ã…‹ì–´...ì§„ì§œ ëª©ì†Œë¦¬ ë°”ë€”ë•Œ ì™„ì „ ë¬´ì„œì›Œ', 'í•˜ ì¬ë°Œì—‰ ã… ã… ', 'ëª°ì…ë„ ì¥ë‚œì•„ë‹ˆë‹¤ã… ']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_8 \n",
      "Summary before \n",
      " ìƒê°ì´ ììœ ë¡œì›Œì§€ê³  ì˜ìš•ì´ ìƒê¸´ëŒ€ ëŒ€ì‹  ì¼ ë§ì´ í•´ì„œ ëª¸ì´ í”¼ê³¤í•œê°€\n",
      "\n",
      "Summary after \n",
      " ìƒê°ì´ ììœ ë¡œì›Œì§€ê³  ì˜ìš•ì´ ìƒê¸´ë‹¤ê³  í•˜ì§€ë§Œ ì¼ ë§ì´ í•´ì„œ ëª¸ì´ í”¼ê³¤í•œê°€ë³´ë‹¤ë³´ë‹¤ê°€ ì¼ ë•Œë¬¸ì— ì˜¤ ë¯¸ë£¨ë˜ ì¼ì„ í•˜ê³  ì‹¶ë‹¤ê³  í•˜ë‹ˆ ì¼ ì‹œì‘í•˜ë‚˜ë³´ë‹¤ ë” ë¹¨ë¦¬ í•´ì•¼ê² ë‹¤ê³  ìƒê°í•˜ê³  ìˆë‹¤.\n",
      "\n",
      "Target summary \n",
      " ì¼ì„ ë§ì´ í•´ì„œ ëª¸ì´ í”¼ê³¤í•œ ëŒ€ì‹  ìƒê°ì´ ììœ ë¡œì›Œì§€ê³  ì˜ìš•ì´ ìƒê¸´ë‹¤ê³  í•˜ì, ì¢‹ì€ ì¹´ë“œë¼ê³  í•œë‹¤.\n",
      "\n",
      "Text ['ìƒê°ì´ ììœ ë¡œì›Œì§€ê³  ì˜ìš•ì´ ìƒê¸´ëŒ€ ëŒ€ì‹  ì¼ ë§ì´ í•´ì„œ ëª¸ì´ í”¼ê³¤í•œê°€ë³´ë‹¤', 'ê·¸ëŸ°ê°€ë³´ë‹¤ ì˜¤ ë¯¸ë£¨ë˜ ì¼ì„ ë“œë””ì–´ í•˜ëŠ”êµ¬ë‚˜', 'ì˜¤ ì¢‹ì€ ì¹´ë“œë„¤ ì´ì œ ì¼ ì‹œì‘í•˜ë‚˜ë³´ë‹¤ ë‚´ë…„ì— ë³¸ê²©ì ìœ¼ë¡œ', 'í˜¼ì ì—´ì‹¬íˆ í•´ì•¼ì§€']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_9 \n",
      "Summary before \n",
      " \n",
      "\n",
      "Summary after \n",
      " ì¥ì‹¤ ê°€ì•¼ì§€ ì‰¬ê³  ìˆë‹¤.ê°œê°€ ì›ƒê¸°ë‹¤ ë­í•˜ê³¡ ë†€ê³  ìˆëŠ”ë° ìµìˆ™í•œ íœ˜ë°”ëŒì´ ë“¤ë¦¬ëŠ” ê²ƒ ê°™ë‹¤ê³  í•´ì„œ êµ¿ì„ í•˜ê³  ìˆë‹¤.\n",
      "\n",
      "Target summary \n",
      " ì—‘ì†Œì˜ ë…¸ë˜ë¥¼ ë“£ë‹¤ê°€ ìµìˆ™í•œ íœ˜íŒŒëŒ ì†Œë¦¬ê°€ ë“¤ë ¤ ì´ì–´í°ì„ ë¹¼ê³  ë“¤ì—ˆë‹¤.\n",
      "\n",
      "Text ['ë†€ì•˜ìŒ í—ˆã…ì¥ì‹¤ ê°€ì•¼ì§€ ì‰¬ë£¨', 'ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ ê°œì›ƒê¸°ë‹¤ ë­í•˜ê³¡ ë†€ê²Œ ìˆë‹ˆ??', 'ì—‘ì†Œë…¸ë˜ í•˜ë‚˜ ë‚˜ì™€ì„œ ë…¸ë˜ë“£ëŠ”ë° ìµìˆ™í•œ íœ˜ë°”ëŒì´ ë“¤ë¦¬ëŠ”ê±°ì•¼ ê·¸ë˜ì„œ ë°”ë¡œì´ì–´í° ë¹¼ê³  ë“¤ë„œì§€ ë…¸ë˜ë“¤ì–´ì„œ êµ¿', 'ì¢‹ê² ë‹¹ã…‹ã…‹ã…‹ã…‹ë‚˜ìˆì„ë–ˆ ì•ˆë‚˜ì˜¤ë˜ë…']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_10 \n",
      "Summary before \n",
      " \n",
      "\n",
      "Summary after \n",
      " ê³ ê¸°ë¥¼ë¹„ëŠ” í˜„ì‹¤ì´ ì•„ë‹ˆë‹ˆê¹Œ ê´œì°®ì„ ê±°ë¼ í•œë‹¤.\n",
      "\n",
      "Target summary \n",
      " ì˜ìƒì„ ë³´ë©° ì¢‹ì•„í•˜ëŠ” ìºë¦­í„°ì— ëŒ€í•˜ì—¬ ì´ì•¼ê¸°í•œë‹¤.\n",
      "\n",
      "Text ['ì¢€ë¹„ëŠ” í˜„ì‹¤ì´ ì•„ë‹ˆë‹ˆê¹Œ ê´œì°®ì„ê±°ì•¼^___^', 'ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ ì „í•˜ê°€ ì‚¬ë¼ì ¸... ì£½ê³ ì‹¶ì§€ì•Šìœ¼ë©´ ì–´ì„œ ì°¾ì•„ë‚´ê²Œ!', 'ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ ë‚´ê°€ ê±°ê¸°ì„œ ê°€ì¥ ì¢‹ì•„í•˜ëŠ” ìºë¦­í„°ëŠ” ë²”íŒ”ì´ì•¼ ë²”ë©°ë“¤ì—ˆì—Œã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹', 'ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ë‚´ê°€ ë¹¨ë¦¬ ë³´ë©´ì„œ ë‚´ ìµœì• ë„ ì°¾ì•„ë³¼ê²Œ ì‹¬ì¥ì´ ë‘ê·¼ë‘ê·¼ #@ì´ë¦„#ì•¼ ë§Œì•½ ì˜¤ëŠ˜ ì´ê±° ê°™ì´ ë´¤ì–ì•„? ë‚˜ ì°ìœ¼ë£¨ ì˜¤ëŠ˜ ìŒë£Œ ë‘ë²ˆ ìŸì•˜ë‹¤.....']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_11 \n",
      "Summary before \n",
      " [ [ [ [ [ [''ë‚˜ë¬´ íŠ¹ì„±ìƒ ë³µë¶ˆë³µì´ë¼ ìƒê°í–‡ì§€ë§Œ #\n",
      "\n",
      "Summary after \n",
      " ë‚˜ë¬´ íŠ¹ì„±ìƒ íŠ¹ì„±ìƒ ë³µë¶ˆë³µì´ë¼ ìƒê°í–‡ì§€ë§Œ ê·¸ë ‡ë‹¤ê³  í•˜ë©´ ë˜ ë‹¤ë¥´ê²Œ ë³´ë©´ ë˜ ê´œì°®ì€ê±° ê°™ê¸°ë„ í•˜ê³ , ë˜ ê·¸ë ‡ê²Œ ë³´ë©´ ë” ì§„í•œê±° ê°™ì€ë° ì´ë ‡ê²Œ ë³´ë©´ ì§„í•˜ê³  ì§„í•´ì„œ ì§„í•  ê²ƒ ê°™ë‹¤ê³  í•œë‹¤.\n",
      "\n",
      "Target summary \n",
      " ë‚˜ë¬´ íŠ¹ì„±ìƒ ë³µë¶ˆë³µì´ë¼ê³  ìƒê°í–ˆì§€ë§Œ ì´ëŸ° ì‚¬ì§„ê³¼ëŠ” ë˜ ë¹„ìŠ·í•´ì„œ ê´œì°®ì€ ê²ƒ ê°™ìœ¼ë©´ì„œë„ ì§„í•œ ê²ƒ ê°™ê¸°ë„ í•˜ë‹¤.\n",
      "\n",
      "Text ['ë‚˜ë¬´ íŠ¹ì„±ìƒ ë³µë¶ˆë³µì´ë¼ ìƒê°í–‡ì§€ë§Œ #@ì‹œìŠ¤í…œ#ì‚¬ì§„# ì´ëŸ°ê±°ë‘ì€ ë˜ ë¹„ìŠ·í•˜ê±°ë“  ã…', 'í ..ì €ë ‡ê²Œ ë³´ë©´ ë˜ ê´œì°®ì€ë°', 'ê·¸ë ‡ê¸´í•œë°', 'ìƒê°ë³´ë‹¤ ì§„í•œê±° ê°™ê¸°ë„í•˜ê³ ']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_12 \n",
      "Summary before \n",
      " \n",
      "\n",
      "Summary after \n",
      " ì£ ë¥´ë”” ì†Œí™˜í–ˆìœ¼ë‹ˆê¹Œ ë‹¹ì¼ë‚  í™•ì¸í•´ë³´ì\"ê³  í•˜ì\"ê³  í•˜ë‹ˆ ë‹¹ì¼ ë‚  í™•ì¸í•˜ë¼ê³  í•œë‹¤.\n",
      "\n",
      "Target summary \n",
      " ì˜¤ëŠ˜ì€ ì•ˆ ëˆŒëŸ¬ì§„ë‹¤ê³  ê·¸ë‚  ê°€ì„œ ë´ì•¼ í• ë“¯í•˜ë‹¤ê³  ì´ì•¼ê¸°í•˜ê³  ìˆë‹¤.\n",
      "\n",
      "Text ['#@ì‹œìŠ¤í…œ#ê¸°íƒ€#', 'ì˜¤ ë­˜ê¹Œ', 'ì•ˆëˆŒë¦¬ë”ë¼ ë‹¤ë¥¸ê±´ ëˆŒë¦¬ëŠ”ë°', 'ì•„ ì˜¤ëŠ˜', 'ê¶ê¸ˆ ã…œã…œ', 'ê·¸ë‚  ê°€ì„œ ë´ì•¼í• ë“¯ ã…‹ã…‹ ì£ ë¥´ë”” ì†Œí™˜í–ˆìœ¼ë‹ˆê¹Œ ë‹¹ì¼ë‚  í™•ì¸í•´ë³´ì', 'ì•„ã…‹ã…‹ã…‹ã…‹ ì˜¤ëŠ˜ì¸ì¤„ ìˆœê°„']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_13 \n",
      "Summary before \n",
      " ''í•˜ê³  ì‹¶ìë„ˆ á„', 'ë™ìˆ²ìœ¼ë¡œ ìŠµë“í•œ ìŠ¤í‚¬ë¡œ \n",
      "\n",
      "Summary after \n",
      " ì‚°ìœ¼ë¡œ ë“¤ì–´ê°€ì„œ ì‰¬ëŠ” ê±´ë°..', 'ìêµ­ ë•Œë¬¸ì— ê·€ë†í•˜ê³  ì‹¶ë‹¤ê³  í•œë‹¤.\n",
      "\n",
      "Target summary \n",
      " ì´ëŸ° ì‹œê¸°ì— ì‚°ìœ¼ë¡œ ë“¤ì–´ê°€ì„œ ê·€ë†ì„ í•˜ê³  ì‹¶ë‹¤.\n",
      "\n",
      "Text ['ì´ëŸ´ ë•Œ ì‚°ìœ¼ë¡œ ë“¤ì–´ê°€ì„œ ì‰¬ëŠ” ê±´ë°..', 'ë§ˆì €... ë‚˜ ìš”ì¦˜ ê·€ë†í•˜ê³  ì‹¶ìë„ˆ ã…‹', 'ë™ìˆ²ìœ¼ë¡œ ìŠµë“í•œ ìŠ¤í‚¬ë¡œ ë‹˜ ë­”ê°€ ì˜í•  ë“¯', 'ã…‡ã…ˆ ã…ã… ë™ìˆ²ìŠ¤í‚¬ ë¬´ì‹œ ëª»í•˜ì§€ ã…‹']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_14 \n",
      "Summary before \n",
      " \n",
      "\n",
      "Summary after \n",
      " ìœ ë°°ì˜¤ë©´ ìš°ë¦¬ê°™ì´ í—¹ìŠ¤ ë‹¤ë¯¸ì ìš´ë™, í—¬ìŠ¤ë„ í•˜ê³ ì‹¶ì–´í•˜ì§€ ì•Šì•„ ê³ ë¯¼ì´ë‹¤.\n",
      "\n",
      "Target summary \n",
      " í—¬ìŠ¤ì— ë‹¤ë‹ˆìê³  í–ˆëŠ”ë° ê²€ë„ë¥¼ ë°°ìš°ê³  ì‹¶ë‹¤ê³  í•œë‹¤.\n",
      "\n",
      "Text ['#@ì´ë¦„# ìœ ë°°ì˜¤ë©´ ìš°ë¦¬ê°™ì´ í—¹ìŠ¤ ë‹¤ë¯¸ì ìš´ë™', 'í—¬ìŠ¤ìš”...? ë‚˜ í•©ê¸°ë“€ í•˜ê³ ì‹¶ì–´ ì•„ë‹ˆì•„ë‹ˆ ê²€ë„ ì´ì•¼', '#@ì´ë¦„#ì´í•œí…Œ ë°°ì›Œ', 'ë¨¸ë¦¬~', 'ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…Œã…‹ã…‹ã…‹', 'ì•„ë§ë‹¤ì´ ê°€ì´ ê²€ë„ì¸ê°€ í›„ëœëœ']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_15 \n",
      "Summary before \n",
      " \n",
      "\n",
      "Summary after \n",
      " í•˜ë£¨ì¢…ì¼ ë–¼ì°½ ì˜ìƒ ë´£ë‹¤.\n",
      "\n",
      "Target summary \n",
      " ë‚´í•œê³µì—° ì˜¤ëŠ” ê°€ìˆ˜ë“¤ ê³µì—°ì—ì„œ ë–¼ë¥¼ ì§€ì–´ ë…¸ë˜(ë–¼ì°½)í•˜ëŠ” ì˜ìƒì„ ë§¨ë‚  ë³¸ ê±° ë˜ ë³´ê³  ìˆëŠ”ë° ê±°ê¸°ì— ìˆëŠ” ê±° ë§ˆëƒ¥ ë²…ì°¨ì˜¤ë¥´ê³  ê°€ìŠ´ì´ ì›…ì¥í•´ì§„ë‹¤.\n",
      "\n",
      "Text ['ì–´ì œ í•˜ë£¨ì¢…ì¼ ë–¼ì°½ ì˜ìƒ ë´£ìŒã…‹ã…‹', 'ì„¤ë§ˆ ë‚´í•œê³µì—° ì˜¤ëŠ” ê°€ìˆ˜ë“¤ ê³µì—°?ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹', 'ë‹¹ì—°ã…‹ã…‹ã…‹ã…‹ë³¸ ê±° ë˜ë³´ê³  ë˜ë´ë„ ë§¨ë‚  ì¬ë°‹ìŒã…‹ã…‹ã…‹', 'ë‚˜ë„ ì¢‹ì•„í•´ã…‹ã…‹ã…‹ã…‹ã…‹ ê°€ìŠ´ì´ ì›…ì¥í•´ì§ìš”', 'ë‚´ê°€ ê±°ê¸°ì— ìˆëŠ”ê±°ë§ˆëƒ¥ã…‹ã…‹ã…‹ã…‹ ë²…ì°¨ì˜¤ë¦„', 'ì¸ì •']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(summaries_after_tuning)):\n",
    "    print('idx_{} '.format(i))\n",
    "    print(\"Summary before \\n\", summaries_before_tuning[i])\n",
    "    print()\n",
    "    print(\"Summary after \\n\", summaries_after_tuning[i])\n",
    "    print()\n",
    "    print(\"Target summary \\n\", test_samples[\"Summary\"][i])\n",
    "    print()\n",
    "    print('Text', test_samples[\"Text\"][i])\n",
    "    print('-'*100)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c052e1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
