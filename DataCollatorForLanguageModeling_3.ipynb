{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44b337fa",
   "metadata": {},
   "source": [
    "# DataCollatorForLanguageModeling_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89503e3",
   "metadata": {},
   "source": [
    "## 1. Import 및 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b9ab59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "856b928b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge_score in /opt/conda/lib/python3.9/site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.9/site-packages (from rouge_score) (0.12.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.9/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from rouge_score) (1.21.4)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.9/site-packages (from rouge_score) (3.6.5)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (4.62.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (1.1.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (8.0.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (2021.11.10)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: datasets==1.0.2 in /opt/conda/lib/python3.9/site-packages (1.0.2)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (0.3.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (3.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (4.62.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (2.0.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (2.26.0)\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (6.0.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (1.21.4)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (1.3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.0.2) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.0.2) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.0.2) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.0.2) (2.0.8)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets==1.0.2) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets==1.0.2) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->datasets==1.0.2) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: transformers==4.24.0 in /opt/conda/lib/python3.9/site-packages (4.24.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (2021.11.10)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (6.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (3.4.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (2.26.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (1.21.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (4.62.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (0.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.24.0) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->transformers==4.24.0) (3.0.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.24.0) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.24.0) (2.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.24.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.24.0) (1.26.12)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: transformer-utils in /opt/conda/lib/python3.9/site-packages (0.1.1)\n",
      "Requirement already satisfied: colorcet in /opt/conda/lib/python3.9/site-packages (from transformer-utils) (3.0.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from transformer-utils) (4.62.3)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.9/site-packages (from transformer-utils) (4.24.0)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.9/site-packages (from transformer-utils) (0.11.2)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.9/site-packages (from transformer-utils) (1.9.1+cu111)\n",
      "Requirement already satisfied: pyct>=0.4.4 in /opt/conda/lib/python3.9/site-packages (from colorcet->transformer-utils) (0.4.8)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.9/site-packages (from seaborn->transformer-utils) (1.21.4)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /opt/conda/lib/python3.9/site-packages (from seaborn->transformer-utils) (3.4.3)\n",
      "Requirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.9/site-packages (from seaborn->transformer-utils) (1.3.3)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.9/site-packages (from seaborn->transformer-utils) (1.7.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch->transformer-utils) (4.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (2021.11.10)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (0.13.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (0.11.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (2.26.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (3.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (3.0.6)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (8.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.23->seaborn->transformer-utils) (2021.3)\n",
      "Requirement already satisfied: param>=1.7.0 in /opt/conda/lib/python3.9/site-packages (from pyct>=0.4.4->colorcet->transformer-utils) (1.12.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers->transformer-utils) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers->transformer-utils) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->transformers->transformer-utils) (2.0.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers->transformer-utils) (1.26.12)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn->transformer-utils) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging) (3.0.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.9/site-packages (0.13.5)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (3.19.1)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.9/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (1.0.11)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (3.1.29)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.9/site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.9/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from wandb) (59.4.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (1.11.1)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (2.26.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (8.0.3)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.9/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score\n",
    "!pip install datasets==1.0.2\n",
    "!pip install transformers==4.24.0\n",
    "!pip install transformer-utils\n",
    "!pip install packaging\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d3222cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-23 07:24:42--  https://www.dropbox.com/s/9xls0tgtf3edgns/mecab-0.996-ko-0.9.2.tar.gz?dl=1\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /s/dl/9xls0tgtf3edgns/mecab-0.996-ko-0.9.2.tar.gz [following]\n",
      "--2022-11-23 07:24:42--  https://www.dropbox.com/s/dl/9xls0tgtf3edgns/mecab-0.996-ko-0.9.2.tar.gz\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://ucd24f69c1fd627631e07687cd1b.dl.dropboxusercontent.com/cd/0/get/BxS4xO_9hI-oURNedsG7t5ycqisNzT_8sNhkJkiBF6S49XHAHIGr4zcSYI89BuJVg0GoRXr-6_WyScGgQvJDbnalJK_nQ_jb_61F2KB2WdizSlgdke4pXgwGLQf3dHKn7zPOuGa7OZqzgv55FWHuzac0aBRxVFLa9u2mY5mzukbhCz1nfv1Avc--x9zTc0pm0oo/file?dl=1# [following]\n",
      "--2022-11-23 07:24:43--  https://ucd24f69c1fd627631e07687cd1b.dl.dropboxusercontent.com/cd/0/get/BxS4xO_9hI-oURNedsG7t5ycqisNzT_8sNhkJkiBF6S49XHAHIGr4zcSYI89BuJVg0GoRXr-6_WyScGgQvJDbnalJK_nQ_jb_61F2KB2WdizSlgdke4pXgwGLQf3dHKn7zPOuGa7OZqzgv55FWHuzac0aBRxVFLa9u2mY5mzukbhCz1nfv1Avc--x9zTc0pm0oo/file?dl=1\n",
      "Resolving ucd24f69c1fd627631e07687cd1b.dl.dropboxusercontent.com (ucd24f69c1fd627631e07687cd1b.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
      "Connecting to ucd24f69c1fd627631e07687cd1b.dl.dropboxusercontent.com (ucd24f69c1fd627631e07687cd1b.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1414979 (1.3M) [application/binary]\n",
      "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz?dl=1.7’\n",
      "\n",
      "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  --.-KB/s    in 0.07s   \n",
      "\n",
      "2022-11-23 07:24:43 (20.0 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz?dl=1.7’ saved [1414979/1414979]\n",
      "\n",
      "mecab-0.996-ko-0.9.2/\n",
      "mecab-0.996-ko-0.9.2/example/\n",
      "mecab-0.996-ko-0.9.2/example/example.cpp\n",
      "mecab-0.996-ko-0.9.2/example/example_lattice.cpp\n",
      "mecab-0.996-ko-0.9.2/example/example_lattice.c\n",
      "mecab-0.996-ko-0.9.2/example/example.c\n",
      "mecab-0.996-ko-0.9.2/example/thread_test.cpp\n",
      "mecab-0.996-ko-0.9.2/mecab-config.in\n",
      "mecab-0.996-ko-0.9.2/man/\n",
      "mecab-0.996-ko-0.9.2/man/Makefile.am\n",
      "mecab-0.996-ko-0.9.2/man/mecab.1\n",
      "mecab-0.996-ko-0.9.2/man/Makefile.in\n",
      "mecab-0.996-ko-0.9.2/mecab.iss.in\n",
      "mecab-0.996-ko-0.9.2/config.guess\n",
      "mecab-0.996-ko-0.9.2/README\n",
      "mecab-0.996-ko-0.9.2/COPYING\n",
      "mecab-0.996-ko-0.9.2/CHANGES.md\n",
      "mecab-0.996-ko-0.9.2/README.md\n",
      "mecab-0.996-ko-0.9.2/INSTALL\n",
      "mecab-0.996-ko-0.9.2/config.sub\n",
      "mecab-0.996-ko-0.9.2/configure.in\n",
      "mecab-0.996-ko-0.9.2/swig/\n",
      "mecab-0.996-ko-0.9.2/swig/Makefile\n",
      "mecab-0.996-ko-0.9.2/swig/version.h.in\n",
      "mecab-0.996-ko-0.9.2/swig/version.h\n",
      "mecab-0.996-ko-0.9.2/swig/MeCab.i\n",
      "mecab-0.996-ko-0.9.2/aclocal.m4\n",
      "mecab-0.996-ko-0.9.2/LGPL\n",
      "mecab-0.996-ko-0.9.2/Makefile.am\n",
      "mecab-0.996-ko-0.9.2/configure\n",
      "mecab-0.996-ko-0.9.2/tests/\n",
      "mecab-0.996-ko-0.9.2/tests/autolink/\n",
      "mecab-0.996-ko-0.9.2/tests/autolink/unk.def\n",
      "mecab-0.996-ko-0.9.2/tests/autolink/dicrc\n",
      "mecab-0.996-ko-0.9.2/tests/autolink/dic.csv\n",
      "mecab-0.996-ko-0.9.2/tests/autolink/test\n",
      "mecab-0.996-ko-0.9.2/tests/autolink/char.def\n",
      "mecab-0.996-ko-0.9.2/tests/autolink/matrix.def\n",
      "mecab-0.996-ko-0.9.2/tests/autolink/test.gld\n",
      "mecab-0.996-ko-0.9.2/tests/t9/\n",
      "mecab-0.996-ko-0.9.2/tests/t9/unk.def\n",
      "mecab-0.996-ko-0.9.2/tests/t9/ipadic.pl\n",
      "mecab-0.996-ko-0.9.2/tests/t9/dicrc\n",
      "mecab-0.996-ko-0.9.2/tests/t9/dic.csv\n",
      "mecab-0.996-ko-0.9.2/tests/t9/test\n",
      "mecab-0.996-ko-0.9.2/tests/t9/char.def\n",
      "mecab-0.996-ko-0.9.2/tests/t9/matrix.def\n",
      "mecab-0.996-ko-0.9.2/tests/t9/mkdic.pl\n",
      "mecab-0.996-ko-0.9.2/tests/t9/test.gld\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/ipa.train\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/ipa.test\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/seed/\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/seed/rewrite.def\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/seed/feature.def\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/seed/unk.def\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/seed/dicrc\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/seed/dic.csv\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/seed/char.def\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/seed/matrix.def\n",
      "mecab-0.996-ko-0.9.2/tests/run-eval.sh\n",
      "mecab-0.996-ko-0.9.2/tests/run-cost-train.sh\n",
      "mecab-0.996-ko-0.9.2/tests/Makefile.am\n",
      "mecab-0.996-ko-0.9.2/tests/katakana/\n",
      "mecab-0.996-ko-0.9.2/tests/katakana/unk.def\n",
      "mecab-0.996-ko-0.9.2/tests/katakana/dicrc\n",
      "mecab-0.996-ko-0.9.2/tests/katakana/dic.csv\n",
      "mecab-0.996-ko-0.9.2/tests/katakana/test\n",
      "mecab-0.996-ko-0.9.2/tests/katakana/char.def\n",
      "mecab-0.996-ko-0.9.2/tests/katakana/matrix.def\n",
      "mecab-0.996-ko-0.9.2/tests/katakana/test.gld\n",
      "mecab-0.996-ko-0.9.2/tests/eval/\n",
      "mecab-0.996-ko-0.9.2/tests/eval/answer\n",
      "mecab-0.996-ko-0.9.2/tests/eval/system\n",
      "mecab-0.996-ko-0.9.2/tests/eval/test.gld\n",
      "mecab-0.996-ko-0.9.2/tests/shiin/\n",
      "mecab-0.996-ko-0.9.2/tests/shiin/unk.def\n",
      "mecab-0.996-ko-0.9.2/tests/shiin/dicrc\n",
      "mecab-0.996-ko-0.9.2/tests/shiin/dic.csv\n",
      "mecab-0.996-ko-0.9.2/tests/shiin/test\n",
      "mecab-0.996-ko-0.9.2/tests/shiin/char.def\n",
      "mecab-0.996-ko-0.9.2/tests/shiin/matrix.def\n",
      "mecab-0.996-ko-0.9.2/tests/shiin/mkdic.pl\n",
      "mecab-0.996-ko-0.9.2/tests/shiin/test.gld\n",
      "mecab-0.996-ko-0.9.2/tests/latin/\n",
      "mecab-0.996-ko-0.9.2/tests/latin/unk.def\n",
      "mecab-0.996-ko-0.9.2/tests/latin/dicrc\n",
      "mecab-0.996-ko-0.9.2/tests/latin/dic.csv\n",
      "mecab-0.996-ko-0.9.2/tests/latin/test\n",
      "mecab-0.996-ko-0.9.2/tests/latin/char.def\n",
      "mecab-0.996-ko-0.9.2/tests/latin/matrix.def\n",
      "mecab-0.996-ko-0.9.2/tests/latin/test.gld\n",
      "mecab-0.996-ko-0.9.2/tests/chartype/\n",
      "mecab-0.996-ko-0.9.2/tests/chartype/unk.def\n",
      "mecab-0.996-ko-0.9.2/tests/chartype/dicrc\n",
      "mecab-0.996-ko-0.9.2/tests/chartype/dic.csv\n",
      "mecab-0.996-ko-0.9.2/tests/chartype/test\n",
      "mecab-0.996-ko-0.9.2/tests/chartype/char.def\n",
      "mecab-0.996-ko-0.9.2/tests/chartype/matrix.def\n",
      "mecab-0.996-ko-0.9.2/tests/chartype/test.gld\n",
      "mecab-0.996-ko-0.9.2/tests/run-dics.sh\n",
      "mecab-0.996-ko-0.9.2/tests/ngram/\n",
      "mecab-0.996-ko-0.9.2/tests/ngram/unk.def\n",
      "mecab-0.996-ko-0.9.2/tests/ngram/dicrc\n",
      "mecab-0.996-ko-0.9.2/tests/ngram/dic.csv\n",
      "mecab-0.996-ko-0.9.2/tests/ngram/test\n",
      "mecab-0.996-ko-0.9.2/tests/ngram/char.def\n",
      "mecab-0.996-ko-0.9.2/tests/ngram/matrix.def\n",
      "mecab-0.996-ko-0.9.2/tests/ngram/test.gld\n",
      "mecab-0.996-ko-0.9.2/tests/Makefile.in\n",
      "mecab-0.996-ko-0.9.2/ltmain.sh\n",
      "mecab-0.996-ko-0.9.2/config.rpath\n",
      "mecab-0.996-ko-0.9.2/config.h.in\n",
      "mecab-0.996-ko-0.9.2/mecabrc.in\n",
      "mecab-0.996-ko-0.9.2/GPL\n",
      "mecab-0.996-ko-0.9.2/Makefile.train\n",
      "mecab-0.996-ko-0.9.2/ChangeLog\n",
      "mecab-0.996-ko-0.9.2/install-sh\n",
      "mecab-0.996-ko-0.9.2/AUTHORS\n",
      "mecab-0.996-ko-0.9.2/doc/\n",
      "mecab-0.996-ko-0.9.2/doc/bindings.html\n",
      "mecab-0.996-ko-0.9.2/doc/posid.html\n",
      "mecab-0.996-ko-0.9.2/doc/unk.html\n",
      "mecab-0.996-ko-0.9.2/doc/learn.html\n",
      "mecab-0.996-ko-0.9.2/doc/format.html\n",
      "mecab-0.996-ko-0.9.2/doc/libmecab.html\n",
      "mecab-0.996-ko-0.9.2/doc/mecab.css\n",
      "mecab-0.996-ko-0.9.2/doc/feature.html\n",
      "mecab-0.996-ko-0.9.2/doc/Makefile.am\n",
      "mecab-0.996-ko-0.9.2/doc/soft.html\n",
      "mecab-0.996-ko-0.9.2/doc/en/\n",
      "mecab-0.996-ko-0.9.2/doc/en/bindings.html\n",
      "mecab-0.996-ko-0.9.2/doc/dic-detail.html\n",
      "mecab-0.996-ko-0.9.2/doc/flow.png\n",
      "mecab-0.996-ko-0.9.2/doc/mecab.html\n",
      "mecab-0.996-ko-0.9.2/doc/index.html\n",
      "mecab-0.996-ko-0.9.2/doc/result.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/tab_a.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/globals_eval.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Tagger-members.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/functions_vars.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/doxygen.css\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/tab_r.gif\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Lattice.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/functions.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Tagger.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h_source.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/tabs.css\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/nav_f.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/tab_b.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/globals.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/nav_h.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/tab_h.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Model.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/globals_func.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/closed.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/tab_l.gif\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__path__t-members.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/functions_func.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/globals_type.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Lattice-members.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__node__t.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers_func.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/tab_s.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__dictionary__info__t-members.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers_type.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Model-members.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__dictionary__info__t.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/namespaces.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/namespaceMeCab.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__path__t.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/files.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__node__t-members.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/index.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/annotated.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/globals_defs.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/classes.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h-source.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/doxygen.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/tab_b.gif\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/bc_s.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/open.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h.html\n",
      "mecab-0.996-ko-0.9.2/doc/dic.html\n",
      "mecab-0.996-ko-0.9.2/doc/partial.html\n",
      "mecab-0.996-ko-0.9.2/doc/feature.png\n",
      "mecab-0.996-ko-0.9.2/doc/Makefile.in\n",
      "mecab-0.996-ko-0.9.2/missing\n",
      "mecab-0.996-ko-0.9.2/BSD\n",
      "mecab-0.996-ko-0.9.2/NEWS\n",
      "mecab-0.996-ko-0.9.2/mkinstalldirs\n",
      "mecab-0.996-ko-0.9.2/src/\n",
      "mecab-0.996-ko-0.9.2/src/dictionary.h\n",
      "mecab-0.996-ko-0.9.2/src/writer.h\n",
      "mecab-0.996-ko-0.9.2/src/utils.h\n",
      "mecab-0.996-ko-0.9.2/src/string_buffer.cpp\n",
      "mecab-0.996-ko-0.9.2/src/tokenizer.cpp\n",
      "mecab-0.996-ko-0.9.2/src/make.bat\n",
      "mecab-0.996-ko-0.9.2/src/mecab.h\n",
      "mecab-0.996-ko-0.9.2/src/freelist.h\n",
      "mecab-0.996-ko-0.9.2/src/string_buffer.h\n",
      "mecab-0.996-ko-0.9.2/src/learner_tagger.h\n",
      "mecab-0.996-ko-0.9.2/src/dictionary_compiler.cpp\n",
      "mecab-0.996-ko-0.9.2/src/eval.cpp\n",
      "mecab-0.996-ko-0.9.2/src/mecab-system-eval.cpp\n",
      "mecab-0.996-ko-0.9.2/src/darts.h\n",
      "mecab-0.996-ko-0.9.2/src/param.h\n",
      "mecab-0.996-ko-0.9.2/src/char_property.h\n",
      "mecab-0.996-ko-0.9.2/src/learner_node.h\n",
      "mecab-0.996-ko-0.9.2/src/mecab-dict-gen.cpp\n",
      "mecab-0.996-ko-0.9.2/src/mecab-dict-index.cpp\n",
      "mecab-0.996-ko-0.9.2/src/winmain.h\n",
      "mecab-0.996-ko-0.9.2/src/thread.h\n",
      "mecab-0.996-ko-0.9.2/src/context_id.cpp\n",
      "mecab-0.996-ko-0.9.2/src/Makefile.am\n",
      "mecab-0.996-ko-0.9.2/src/connector.h\n",
      "mecab-0.996-ko-0.9.2/src/common.h\n",
      "mecab-0.996-ko-0.9.2/src/dictionary_rewriter.cpp\n",
      "mecab-0.996-ko-0.9.2/src/Makefile.msvc.in\n",
      "mecab-0.996-ko-0.9.2/src/dictionary_rewriter.h\n",
      "mecab-0.996-ko-0.9.2/src/feature_index.h\n",
      "mecab-0.996-ko-0.9.2/src/iconv_utils.cpp\n",
      "mecab-0.996-ko-0.9.2/src/char_property.cpp\n",
      "mecab-0.996-ko-0.9.2/src/mecab-test-gen.cpp\n",
      "mecab-0.996-ko-0.9.2/src/tagger.cpp\n",
      "mecab-0.996-ko-0.9.2/src/mecab-cost-train.cpp\n",
      "mecab-0.996-ko-0.9.2/src/learner.cpp\n",
      "mecab-0.996-ko-0.9.2/src/dictionary.cpp\n",
      "mecab-0.996-ko-0.9.2/src/lbfgs.cpp\n",
      "mecab-0.996-ko-0.9.2/src/ucs.h\n",
      "mecab-0.996-ko-0.9.2/src/writer.cpp\n",
      "mecab-0.996-ko-0.9.2/src/learner_tagger.cpp\n",
      "mecab-0.996-ko-0.9.2/src/lbfgs.h\n",
      "mecab-0.996-ko-0.9.2/src/libmecab.cpp\n",
      "mecab-0.996-ko-0.9.2/src/tokenizer.h\n",
      "mecab-0.996-ko-0.9.2/src/mecab.cpp\n",
      "mecab-0.996-ko-0.9.2/src/utils.cpp\n",
      "mecab-0.996-ko-0.9.2/src/dictionary_generator.cpp\n",
      "mecab-0.996-ko-0.9.2/src/param.cpp\n",
      "mecab-0.996-ko-0.9.2/src/context_id.h\n",
      "mecab-0.996-ko-0.9.2/src/mmap.h\n",
      "mecab-0.996-ko-0.9.2/src/viterbi.h\n",
      "mecab-0.996-ko-0.9.2/src/viterbi.cpp\n",
      "mecab-0.996-ko-0.9.2/src/stream_wrapper.h\n",
      "mecab-0.996-ko-0.9.2/src/feature_index.cpp\n",
      "mecab-0.996-ko-0.9.2/src/nbest_generator.h\n",
      "mecab-0.996-ko-0.9.2/src/ucstable.h\n",
      "mecab-0.996-ko-0.9.2/src/nbest_generator.cpp\n",
      "mecab-0.996-ko-0.9.2/src/iconv_utils.h\n",
      "mecab-0.996-ko-0.9.2/src/connector.cpp\n",
      "mecab-0.996-ko-0.9.2/src/Makefile.in\n",
      "mecab-0.996-ko-0.9.2/src/scoped_ptr.h\n",
      "mecab-0.996-ko-0.9.2/Makefile.in\n",
      "checking for a BSD-compatible install... /usr/bin/install -c\n",
      "checking whether build environment is sane... yes\n",
      "checking for a thread-safe mkdir -p... /usr/bin/mkdir -p\n",
      "checking for gawk... no\n",
      "checking for mawk... mawk\n",
      "checking whether make sets $(MAKE)... yes\n",
      "checking for gcc... gcc\n",
      "checking whether the C compiler works... yes\n",
      "checking for C compiler default output file name... a.out\n",
      "checking for suffix of executables... \n",
      "checking whether we are cross compiling... no\n",
      "checking for suffix of object files... o\n",
      "checking whether we are using the GNU C compiler... yes\n",
      "checking whether gcc accepts -g... yes\n",
      "checking for gcc option to accept ISO C89... none needed\n",
      "checking for style of include used by make... GNU\n",
      "checking dependency style of gcc... none\n",
      "checking for g++... g++\n",
      "checking whether we are using the GNU C++ compiler... yes\n",
      "checking whether g++ accepts -g... yes\n",
      "checking dependency style of g++... none\n",
      "checking how to run the C preprocessor... gcc -E\n",
      "checking for grep that handles long lines and -e... /usr/bin/grep\n",
      "checking for egrep... /usr/bin/grep -E\n",
      "checking whether gcc needs -traditional... no\n",
      "checking whether make sets $(MAKE)... (cached) yes\n",
      "checking build system type... x86_64-unknown-linux-gnu\n",
      "checking host system type... x86_64-unknown-linux-gnu\n",
      "checking how to print strings... printf\n",
      "checking for a sed that does not truncate output... /usr/bin/sed\n",
      "checking for fgrep... /usr/bin/grep -F\n",
      "checking for ld used by gcc... /usr/bin/ld\n",
      "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
      "checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B\n",
      "checking the name lister (/usr/bin/nm -B) interface... BSD nm\n",
      "checking whether ln -s works... yes\n",
      "checking the maximum length of command line arguments... 1572864\n",
      "checking whether the shell understands some XSI constructs... yes\n",
      "checking whether the shell understands \"+=\"... yes\n",
      "checking how to convert x86_64-unknown-linux-gnu file names to x86_64-unknown-linux-gnu format... func_convert_file_noop\n",
      "checking how to convert x86_64-unknown-linux-gnu file names to toolchain format... func_convert_file_noop\n",
      "checking for /usr/bin/ld option to reload object files... -r\n",
      "checking for objdump... objdump\n",
      "checking how to recognize dependent libraries... pass_all\n",
      "checking for dlltool... dlltool\n",
      "checking how to associate runtime and link libraries... printf %s\\n\n",
      "checking for ar... ar\n",
      "checking for archiver @FILE support... @\n",
      "checking for strip... strip\n",
      "checking for ranlib... ranlib\n",
      "checking command to parse /usr/bin/nm -B output from gcc object... ok\n",
      "checking for sysroot... no\n",
      "checking for mt... no\n",
      "checking if : is a manifest tool... no\n",
      "checking for ANSI C header files... yes\n",
      "checking for sys/types.h... yes\n",
      "checking for sys/stat.h... yes\n",
      "checking for stdlib.h... yes\n",
      "checking for string.h... yes\n",
      "checking for memory.h... yes\n",
      "checking for strings.h... yes\n",
      "checking for inttypes.h... yes\n",
      "checking for stdint.h... yes\n",
      "checking for unistd.h... yes\n",
      "checking for dlfcn.h... yes\n",
      "checking for objdir... .libs\n",
      "checking if gcc supports -fno-rtti -fno-exceptions... no\n",
      "checking for gcc option to produce PIC... -fPIC -DPIC\n",
      "checking if gcc PIC flag -fPIC -DPIC works... yes\n",
      "checking if gcc static flag -static works... yes\n",
      "checking if gcc supports -c -o file.o... yes\n",
      "checking if gcc supports -c -o file.o... (cached) yes\n",
      "checking whether the gcc linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\n",
      "checking whether -lc should be explicitly linked in... no\n",
      "checking dynamic linker characteristics... GNU/Linux ld.so\n",
      "checking how to hardcode library paths into programs... immediate\n",
      "checking whether stripping libraries is possible... yes\n",
      "checking if libtool supports shared libraries... yes\n",
      "checking whether to build shared libraries... yes\n",
      "checking whether to build static libraries... yes\n",
      "checking how to run the C++ preprocessor... g++ -E\n",
      "checking for ld used by g++... /usr/bin/ld -m elf_x86_64\n",
      "checking if the linker (/usr/bin/ld -m elf_x86_64) is GNU ld... yes\n",
      "checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\n",
      "checking for g++ option to produce PIC... -fPIC -DPIC\n",
      "checking if g++ PIC flag -fPIC -DPIC works... yes\n",
      "checking if g++ static flag -static works... yes\n",
      "checking if g++ supports -c -o file.o... yes\n",
      "checking if g++ supports -c -o file.o... (cached) yes\n",
      "checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\n",
      "checking dynamic linker characteristics... (cached) GNU/Linux ld.so\n",
      "checking how to hardcode library paths into programs... immediate\n",
      "checking for library containing strerror... none required\n",
      "checking whether byte ordering is bigendian... no\n",
      "checking for ld used by GCC... /usr/bin/ld -m elf_x86_64\n",
      "checking if the linker (/usr/bin/ld -m elf_x86_64) is GNU ld... yes\n",
      "checking for shared library run path origin... done\n",
      "checking for iconv... yes\n",
      "checking for working iconv... yes\n",
      "checking for iconv declaration... \n",
      "         extern size_t iconv (iconv_t cd, char * *inbuf, size_t *inbytesleft, char * *outbuf, size_t *outbytesleft);\n",
      "checking for ANSI C header files... (cached) yes\n",
      "checking for an ANSI C-conforming const... yes\n",
      "checking whether byte ordering is bigendian... (cached) no\n",
      "checking for string.h... (cached) yes\n",
      "checking for stdlib.h... (cached) yes\n",
      "checking for unistd.h... (cached) yes\n",
      "checking fcntl.h usability... yes\n",
      "checking fcntl.h presence... yes\n",
      "checking for fcntl.h... yes\n",
      "checking for stdint.h... (cached) yes\n",
      "checking for sys/stat.h... (cached) yes\n",
      "checking sys/mman.h usability... yes\n",
      "checking sys/mman.h presence... yes\n",
      "checking for sys/mman.h... yes\n",
      "checking sys/times.h usability... yes\n",
      "checking sys/times.h presence... yes\n",
      "checking for sys/times.h... yes\n",
      "checking for sys/types.h... (cached) yes\n",
      "checking dirent.h usability... yes\n",
      "checking dirent.h presence... yes\n",
      "checking for dirent.h... yes\n",
      "checking ctype.h usability... yes\n",
      "checking ctype.h presence... yes\n",
      "checking for ctype.h... yes\n",
      "checking for sys/types.h... (cached) yes\n",
      "checking io.h usability... no\n",
      "checking io.h presence... no\n",
      "checking for io.h... no\n",
      "checking windows.h usability... no\n",
      "checking windows.h presence... no\n",
      "checking for windows.h... no\n",
      "checking pthread.h usability... yes\n",
      "checking pthread.h presence... yes\n",
      "checking for pthread.h... yes\n",
      "checking for off_t... yes\n",
      "checking for size_t... yes\n",
      "checking size of char... 1\n",
      "checking size of short... 2\n",
      "checking size of int... 4\n",
      "checking size of long... 8\n",
      "checking size of long long... 8\n",
      "checking size of size_t... 8\n",
      "checking for size_t... (cached) yes\n",
      "checking for unsigned long long int... yes\n",
      "checking for stdlib.h... (cached) yes\n",
      "checking for unistd.h... (cached) yes\n",
      "checking for sys/param.h... yes\n",
      "checking for getpagesize... yes\n",
      "checking for working mmap... yes\n",
      "checking for main in -lstdc++... yes\n",
      "checking for pthread_create in -lpthread... yes\n",
      "checking for pthread_join in -lpthread... yes\n",
      "checking for getenv... yes\n",
      "checking for opendir... yes\n",
      "checking whether make is GNU Make... yes\n",
      "checking if g++ supports stl <vector> (required)... yes\n",
      "checking if g++ supports stl <list> (required)... yes\n",
      "checking if g++ supports stl <map> (required)... yes\n",
      "checking if g++ supports stl <set> (required)... yes\n",
      "checking if g++ supports stl <queue> (required)... yes\n",
      "checking if g++ supports stl <functional> (required)... yes\n",
      "checking if g++ supports stl <algorithm> (required)... yes\n",
      "checking if g++ supports stl <string> (required)... yes\n",
      "checking if g++ supports stl <iostream> (required)... yes\n",
      "checking if g++ supports stl <sstream> (required)... yes\n",
      "checking if g++ supports stl <fstream> (required)... yes\n",
      "checking if g++ supports template <class T> (required)... yes\n",
      "checking if g++ supports const_cast<> (required)... yes\n",
      "checking if g++ supports static_cast<> (required)... yes\n",
      "checking if g++ supports reinterpret_cast<> (required)... yes\n",
      "checking if g++ supports namespaces (required) ... yes\n",
      "checking if g++ supports __thread (optional)... yes\n",
      "checking if g++ supports template <class T> (required)... yes\n",
      "checking if g++ supports GCC native atomic operations (optional)... yes\n",
      "checking if g++ supports OSX native atomic operations (optional)... no\n",
      "checking if g++ environment provides all required features... yes\n",
      "configure: creating ./config.status\n",
      "config.status: creating Makefile\n",
      "config.status: creating src/Makefile\n",
      "config.status: creating src/Makefile.msvc\n",
      "config.status: creating man/Makefile\n",
      "config.status: creating doc/Makefile\n",
      "config.status: creating tests/Makefile\n",
      "config.status: creating swig/version.h\n",
      "config.status: creating mecab.iss\n",
      "config.status: creating mecab-config\n",
      "config.status: creating mecabrc\n",
      "config.status: creating config.h\n",
      "config.status: config.h is unchanged\n",
      "config.status: executing depfiles commands\n",
      "config.status: executing libtool commands\n",
      "config.status: executing default commands\n",
      "make  all-recursive\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "Making all in src\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
      "make[2]: Nothing to be done for 'all'.\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
      "Making all in man\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
      "make[2]: Nothing to be done for 'all'.\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
      "Making all in doc\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
      "make[2]: Nothing to be done for 'all'.\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
      "Making all in tests\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "make[2]: Nothing to be done for 'all'.\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "Making check in src\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
      "make[1]: Nothing to be done for 'check'.\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
      "Making check in man\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
      "make[1]: Nothing to be done for 'check'.\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
      "Making check in doc\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
      "make[1]: Nothing to be done for 'check'.\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
      "Making check in tests\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "make  check-TESTS\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./unk.def ... 2\n",
      "emitting double-array: 100% |###########################################| \n",
      "./model.def is not found. skipped.\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./dic.csv ... 177\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading ./matrix.def ... 178x178\n",
      "emitting matrix      : 100% |###########################################| \n",
      "\n",
      "done!\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./unk.def ... 2\n",
      "emitting double-array: 100% |###########################################| \n",
      "./model.def is not found. skipped.\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./dic.csv ... 83\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading ./matrix.def ... 84x84\n",
      "emitting matrix      : 100% |###########################################| \n",
      "\n",
      "done!\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./unk.def ... 2\n",
      "emitting double-array: 100% |###########################################| \n",
      "./model.def is not found. skipped.\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./dic.csv ... 450\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading ./matrix.def ... 1x1\n",
      "\n",
      "done!\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./unk.def ... 2\n",
      "emitting double-array: 100% |###########################################| \n",
      "./model.def is not found. skipped.\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./dic.csv ... 162\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading ./matrix.def ... 3x3\n",
      "emitting matrix      : 100% |###########################################| \n",
      "\n",
      "done!\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./unk.def ... 2\n",
      "emitting double-array: 100% |###########################################| \n",
      "./model.def is not found. skipped.\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./dic.csv ... 4\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading ./matrix.def ... 1x1\n",
      "\n",
      "done!\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./unk.def ... 11\n",
      "emitting double-array: 100% |###########################################| \n",
      "./model.def is not found. skipped.\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./dic.csv ... 1\n",
      "reading ./matrix.def ... 1x1\n",
      "\n",
      "done!\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./unk.def ... 2\n",
      "emitting double-array: 100% |###########################################| \n",
      "./model.def is not found. skipped.\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./dic.csv ... 1\n",
      "reading ./matrix.def ... 1x1\n",
      "\n",
      "done!\n",
      "PASS: run-dics.sh\n",
      "PASS: run-eval.sh\n",
      "seed/pos-id.def is not found. minimum setting is used\n",
      "reading seed/unk.def ... 40\n",
      "emitting double-array: 100% |###########################################| \n",
      "seed/model.def is not found. skipped.\n",
      "seed/pos-id.def is not found. minimum setting is used\n",
      "reading seed/dic.csv ... 4335\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading seed/matrix.def ... 1x1\n",
      "\n",
      "done!\n",
      "reading corpus ...\n",
      "Number of sentences: 34\n",
      "Number of features:  64108\n",
      "eta:                 0.00005\n",
      "freq:                1\n",
      "eval-size:           6\n",
      "unk-eval-size:       4\n",
      "threads:             1\n",
      "charset:             EUC-JP\n",
      "C(sigma^2):          1.00000\n",
      "\n",
      "iter=0 err=1.00000 F=0.35771 target=2406.28355 diff=1.00000\n",
      "iter=1 err=0.97059 F=0.65652 target=1484.25231 diff=0.38318\n",
      "iter=2 err=0.91176 F=0.79331 target=863.32765 diff=0.41834\n",
      "iter=3 err=0.85294 F=0.89213 target=596.72480 diff=0.30881\n",
      "iter=4 err=0.61765 F=0.95467 target=336.30744 diff=0.43641\n",
      "iter=5 err=0.50000 F=0.96702 target=246.53039 diff=0.26695\n",
      "iter=6 err=0.35294 F=0.95472 target=188.93963 diff=0.23361\n",
      "iter=7 err=0.20588 F=0.99106 target=168.62665 diff=0.10751\n",
      "iter=8 err=0.05882 F=0.99777 target=158.64865 diff=0.05917\n",
      "iter=9 err=0.08824 F=0.99665 target=154.14530 diff=0.02839\n",
      "iter=10 err=0.08824 F=0.99665 target=151.94257 diff=0.01429\n",
      "iter=11 err=0.02941 F=0.99888 target=147.20825 diff=0.03116\n",
      "iter=12 err=0.00000 F=1.00000 target=147.34956 diff=0.00096\n",
      "iter=13 err=0.02941 F=0.99888 target=146.32592 diff=0.00695\n",
      "iter=14 err=0.00000 F=1.00000 target=145.77299 diff=0.00378\n",
      "iter=15 err=0.02941 F=0.99888 target=145.24641 diff=0.00361\n",
      "iter=16 err=0.00000 F=1.00000 target=144.96490 diff=0.00194\n",
      "iter=17 err=0.02941 F=0.99888 target=144.90246 diff=0.00043\n",
      "iter=18 err=0.00000 F=1.00000 target=144.75959 diff=0.00099\n",
      "iter=19 err=0.00000 F=1.00000 target=144.71727 diff=0.00029\n",
      "iter=20 err=0.00000 F=1.00000 target=144.66337 diff=0.00037\n",
      "iter=21 err=0.00000 F=1.00000 target=144.61349 diff=0.00034\n",
      "iter=22 err=0.00000 F=1.00000 target=144.62987 diff=0.00011\n",
      "iter=23 err=0.00000 F=1.00000 target=144.60060 diff=0.00020\n",
      "iter=24 err=0.00000 F=1.00000 target=144.59125 diff=0.00006\n",
      "iter=25 err=0.00000 F=1.00000 target=144.58619 diff=0.00004\n",
      "iter=26 err=0.00000 F=1.00000 target=144.58219 diff=0.00003\n",
      "iter=27 err=0.00000 F=1.00000 target=144.58059 diff=0.00001\n",
      "\n",
      "Done! writing model file ... \n",
      "model-ipadic.c1.0.f1.model is not a binary model. reopen it as text mode...\n",
      "reading seed/unk.def ... 40\n",
      "reading seed/dic.csv ... 4335\n",
      "emitting model-ipadic.c1.0.f1.dic/left-id.def/ model-ipadic.c1.0.f1.dic/right-id.def\n",
      "emitting model-ipadic.c1.0.f1.dic/unk.def ... 40\n",
      "emitting model-ipadic.c1.0.f1.dic/dic.csv ... 4335\n",
      "emitting matrix      : 100% |###########################################| \n",
      "copying seed/char.def to model-ipadic.c1.0.f1.dic/char.def\n",
      "copying seed/rewrite.def to model-ipadic.c1.0.f1.dic/rewrite.def\n",
      "copying seed/dicrc to model-ipadic.c1.0.f1.dic/dicrc\n",
      "copying seed/feature.def to model-ipadic.c1.0.f1.dic/feature.def\n",
      "copying model-ipadic.c1.0.f1.model to model-ipadic.c1.0.f1.dic/model.def\n",
      "\n",
      "done!\n",
      "model-ipadic.c1.0.f1.dic/pos-id.def is not found. minimum setting is used\n",
      "reading model-ipadic.c1.0.f1.dic/unk.def ... 40\n",
      "emitting double-array: 100% |###########################################| \n",
      "model-ipadic.c1.0.f1.dic/pos-id.def is not found. minimum setting is used\r\n",
      "reading model-ipadic.c1.0.f1.dic/dic.csv ... 4335\r\n",
      "emitting double-array: 100% |###########################################| \r\n",
      "reading model-ipadic.c1.0.f1.dic/matrix.def ... 346x346\r\n",
      "emitting matrix      : 100% |###########################################| \r\n",
      "\r\n",
      "done!\r\n",
      "              precision          recall         F\n",
      "LEVEL 0:    12.8959(57/442) 11.8998(57/479) 12.3779\n",
      "LEVEL 1:    12.2172(54/442) 11.2735(54/479) 11.7264\n",
      "LEVEL 2:    11.7647(52/442) 10.8559(52/479) 11.2921\n",
      "LEVEL 4:    11.7647(52/442) 10.8559(52/479) 11.2921\n",
      "PASS: run-cost-train.sh\n",
      "==================\n",
      "All 3 tests passed\n",
      "==================\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "Making install in src\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
      "test -z \"/usr/local/lib\" || /usr/bin/mkdir -p \"/usr/local/lib\"\n",
      " /bin/bash ../libtool   --mode=install /usr/bin/install -c   libmecab.la '/usr/local/lib'\n",
      "libtool: install: /usr/bin/install -c .libs/libmecab.so.2.0.0 /usr/local/lib/libmecab.so.2.0.0\n",
      "libtool: install: (cd /usr/local/lib && { ln -s -f libmecab.so.2.0.0 libmecab.so.2 || { rm -f libmecab.so.2 && ln -s libmecab.so.2.0.0 libmecab.so.2; }; })\n",
      "libtool: install: (cd /usr/local/lib && { ln -s -f libmecab.so.2.0.0 libmecab.so || { rm -f libmecab.so && ln -s libmecab.so.2.0.0 libmecab.so; }; })\n",
      "libtool: install: /usr/bin/install -c .libs/libmecab.lai /usr/local/lib/libmecab.la\n",
      "libtool: install: /usr/bin/install -c .libs/libmecab.a /usr/local/lib/libmecab.a\n",
      "libtool: install: chmod 644 /usr/local/lib/libmecab.a\n",
      "libtool: install: ranlib /usr/local/lib/libmecab.a\n",
      "libtool: finish: PATH=\"/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/sbin\" ldconfig -n /usr/local/lib\n",
      "----------------------------------------------------------------------\n",
      "Libraries have been installed in:\n",
      "   /usr/local/lib\n",
      "\n",
      "If you ever happen to want to link against installed libraries\n",
      "in a given directory, LIBDIR, you must either use libtool, and\n",
      "specify the full pathname of the library, or use the `-LLIBDIR'\n",
      "flag during linking and do at least one of the following:\n",
      "   - add LIBDIR to the `LD_LIBRARY_PATH' environment variable\n",
      "     during execution\n",
      "   - add LIBDIR to the `LD_RUN_PATH' environment variable\n",
      "     during linking\n",
      "   - use the `-Wl,-rpath -Wl,LIBDIR' linker flag\n",
      "   - have your system administrator add LIBDIR to `/etc/ld.so.conf'\n",
      "\n",
      "See any operating system documentation about shared libraries for\n",
      "more information, such as the ld(1) and ld.so(8) manual pages.\n",
      "----------------------------------------------------------------------\n",
      "test -z \"/usr/local/bin\" || /usr/bin/mkdir -p \"/usr/local/bin\"\n",
      "  /bin/bash ../libtool   --mode=install /usr/bin/install -c mecab '/usr/local/bin'\n",
      "libtool: install: /usr/bin/install -c .libs/mecab /usr/local/bin/mecab\n",
      "test -z \"/usr/local/libexec/mecab\" || /usr/bin/mkdir -p \"/usr/local/libexec/mecab\"\n",
      "  /bin/bash ../libtool   --mode=install /usr/bin/install -c mecab-dict-index mecab-dict-gen mecab-cost-train mecab-system-eval mecab-test-gen '/usr/local/libexec/mecab'\n",
      "libtool: install: /usr/bin/install -c .libs/mecab-dict-index /usr/local/libexec/mecab/mecab-dict-index\n",
      "libtool: install: /usr/bin/install -c .libs/mecab-dict-gen /usr/local/libexec/mecab/mecab-dict-gen\n",
      "libtool: install: /usr/bin/install -c .libs/mecab-cost-train /usr/local/libexec/mecab/mecab-cost-train\n",
      "libtool: install: /usr/bin/install -c .libs/mecab-system-eval /usr/local/libexec/mecab/mecab-system-eval\n",
      "libtool: install: /usr/bin/install -c .libs/mecab-test-gen /usr/local/libexec/mecab/mecab-test-gen\n",
      "test -z \"/usr/local/include\" || /usr/bin/mkdir -p \"/usr/local/include\"\n",
      " /usr/bin/install -c -m 644 mecab.h '/usr/local/include'\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
      "Making install in man\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
      "make[2]: Nothing to be done for 'install-exec-am'.\n",
      "test -z \"/usr/local/share/man/man1\" || /usr/bin/mkdir -p \"/usr/local/share/man/man1\"\n",
      " /usr/bin/install -c -m 644 mecab.1 '/usr/local/share/man/man1'\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
      "Making install in doc\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
      "make[2]: Nothing to be done for 'install-exec-am'.\n",
      "make[2]: Nothing to be done for 'install-data-am'.\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
      "Making install in tests\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "make[2]: Nothing to be done for 'install-exec-am'.\n",
      "make[2]: Nothing to be done for 'install-data-am'.\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "test -z \"/usr/local/bin\" || /usr/bin/mkdir -p \"/usr/local/bin\"\n",
      " /usr/bin/install -c mecab-config '/usr/local/bin'\n",
      "test -z \"/usr/local/etc\" || /usr/bin/mkdir -p \"/usr/local/etc\"\n",
      " /usr/bin/install -c -m 644 mecabrc '/usr/local/etc'\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "--2022-11-23 07:25:00--  https://www.dropbox.com/s/i8girnk5p80076c/mecab-ko-dic-2.1.1-20180720.tar.gz?dl=1\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.2.18, 2620:100:6016:18::a27d:112\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.2.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /s/dl/i8girnk5p80076c/mecab-ko-dic-2.1.1-20180720.tar.gz [following]\n",
      "--2022-11-23 07:25:00--  https://www.dropbox.com/s/dl/i8girnk5p80076c/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc9c21d33411d300ccb92aaf35d6.dl.dropboxusercontent.com/cd/0/get/BxQlCgUmeZFM27eAbGeYJlmCqdJzxzTevLs0Z0brJUSCR3dJgculUj7-o461hCs3Jf-7D5i1wXZS-m_nzr8UG9CXRNqNwUPvERUSAdbTmMJWDmxn9tkS4nfSr3JF27dWIRCcToUBTCe_YZqE6EMnHahr6_H7azXty3Mnw40vmaG0xX8uD3mZecZ0whUDbCpShmI/file?dl=1# [following]\n",
      "--2022-11-23 07:25:01--  https://uc9c21d33411d300ccb92aaf35d6.dl.dropboxusercontent.com/cd/0/get/BxQlCgUmeZFM27eAbGeYJlmCqdJzxzTevLs0Z0brJUSCR3dJgculUj7-o461hCs3Jf-7D5i1wXZS-m_nzr8UG9CXRNqNwUPvERUSAdbTmMJWDmxn9tkS4nfSr3JF27dWIRCcToUBTCe_YZqE6EMnHahr6_H7azXty3Mnw40vmaG0xX8uD3mZecZ0whUDbCpShmI/file?dl=1\n",
      "Resolving uc9c21d33411d300ccb92aaf35d6.dl.dropboxusercontent.com (uc9c21d33411d300ccb92aaf35d6.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
      "Connecting to uc9c21d33411d300ccb92aaf35d6.dl.dropboxusercontent.com (uc9c21d33411d300ccb92aaf35d6.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 49775061 (47M) [application/binary]\n",
      "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz?dl=1.7’\n",
      "\n",
      "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  40.8MB/s    in 1.2s    \n",
      "\n",
      "2022-11-23 07:25:02 (40.8 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz?dl=1.7’ saved [49775061/49775061]\n",
      "\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "autoconf is already the newest version (2.69-11.1).\n",
      "The following packages were automatically installed and are no longer required:\n",
      "  accountsservice-ubuntu-schemas bc bluez-obexd cups cups-browsed cups-client\n",
      "  cups-common cups-core-drivers cups-daemon cups-filters\n",
      "  cups-filters-core-drivers cups-ipp-utils cups-ppdc cups-server-common\n",
      "  fonts-droid-fallback fonts-noto-mono fonts-urw-base35 ghostscript\n",
      "  gir1.2-dbusmenu-glib-0.4 gnome-bluetooth gnome-power-manager\n",
      "  gnome-screensaver gsettings-ubuntu-schemas gvfs-backends indicator-applet\n",
      "  indicator-application indicator-appmenu indicator-bluetooth indicator-common\n",
      "  indicator-datetime indicator-keyboard indicator-messages indicator-power\n",
      "  indicator-printers indicator-session indicator-sound jayatana\n",
      "  libaccounts-glib0 libbamf3-2 libcdio-cdda2 libcdio-paranoia2 libcdio18\n",
      "  libcupsfilters1 libfcitx-config4 libfcitx-gclient1 libfcitx-utils0\n",
      "  libfontembed1 libgnome-panel0 libgs9 libgs9-common libido3-0.1-0 libijs-0.35\n",
      "  libindicator3-7 libjbig2dec0 liblightdm-gobject-1-0 liblouis-data liblouis20\n",
      "  liblouisutdml-bin liblouisutdml-data liblouisutdml9 libmessaging-menu0\n",
      "  libmtp-common libmtp-runtime libmtp9 libnfs13 libpaper-utils libpaper1\n",
      "  libpoppler-cpp0v5 libqpdf26 libunity-gtk2-parser0 libunity-gtk3-parser0\n",
      "  libunity-settings-daemon1 liburl-dispatcher1 lightdm nautilus-data\n",
      "  poppler-utils python3-psutil python3-xdg ssl-cert ubuntu-touch-sounds\n",
      "  unity-greeter unity-gtk-module-common unity-gtk2-module unity-gtk3-module\n",
      "  unity-settings-daemon unity-settings-daemon-schemas\n",
      "Use 'apt autoremove' to remove them.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n",
      "mecab-ko-dic-2.1.1-20180720/\n",
      "mecab-ko-dic-2.1.1-20180720/configure\n",
      "mecab-ko-dic-2.1.1-20180720/COPYING\n",
      "mecab-ko-dic-2.1.1-20180720/autogen.sh\n",
      "mecab-ko-dic-2.1.1-20180720/Place-station.csv\n",
      "mecab-ko-dic-2.1.1-20180720/NNG.csv\n",
      "mecab-ko-dic-2.1.1-20180720/README\n",
      "mecab-ko-dic-2.1.1-20180720/EF.csv\n",
      "mecab-ko-dic-2.1.1-20180720/MAG.csv\n",
      "mecab-ko-dic-2.1.1-20180720/Preanalysis.csv\n",
      "mecab-ko-dic-2.1.1-20180720/NNB.csv\n",
      "mecab-ko-dic-2.1.1-20180720/Person-actor.csv\n",
      "mecab-ko-dic-2.1.1-20180720/VV.csv\n",
      "mecab-ko-dic-2.1.1-20180720/Makefile.in\n",
      "mecab-ko-dic-2.1.1-20180720/matrix.def\n",
      "mecab-ko-dic-2.1.1-20180720/EC.csv\n",
      "mecab-ko-dic-2.1.1-20180720/NNBC.csv\n",
      "mecab-ko-dic-2.1.1-20180720/clean\n",
      "mecab-ko-dic-2.1.1-20180720/ChangeLog\n",
      "mecab-ko-dic-2.1.1-20180720/J.csv\n",
      "mecab-ko-dic-2.1.1-20180720/.keep\n",
      "mecab-ko-dic-2.1.1-20180720/feature.def\n",
      "mecab-ko-dic-2.1.1-20180720/Foreign.csv\n",
      "mecab-ko-dic-2.1.1-20180720/XPN.csv\n",
      "mecab-ko-dic-2.1.1-20180720/EP.csv\n",
      "mecab-ko-dic-2.1.1-20180720/NR.csv\n",
      "mecab-ko-dic-2.1.1-20180720/left-id.def\n",
      "mecab-ko-dic-2.1.1-20180720/Place.csv\n",
      "mecab-ko-dic-2.1.1-20180720/Symbol.csv\n",
      "mecab-ko-dic-2.1.1-20180720/dicrc\n",
      "mecab-ko-dic-2.1.1-20180720/NP.csv\n",
      "mecab-ko-dic-2.1.1-20180720/ETM.csv\n",
      "mecab-ko-dic-2.1.1-20180720/IC.csv\n",
      "mecab-ko-dic-2.1.1-20180720/Place-address.csv\n",
      "mecab-ko-dic-2.1.1-20180720/Group.csv\n",
      "mecab-ko-dic-2.1.1-20180720/model.def\n",
      "mecab-ko-dic-2.1.1-20180720/XSN.csv\n",
      "mecab-ko-dic-2.1.1-20180720/INSTALL\n",
      "mecab-ko-dic-2.1.1-20180720/rewrite.def\n",
      "mecab-ko-dic-2.1.1-20180720/Inflect.csv\n",
      "mecab-ko-dic-2.1.1-20180720/configure.ac\n",
      "mecab-ko-dic-2.1.1-20180720/NNP.csv\n",
      "mecab-ko-dic-2.1.1-20180720/CoinedWord.csv\n",
      "mecab-ko-dic-2.1.1-20180720/XSV.csv\n",
      "mecab-ko-dic-2.1.1-20180720/pos-id.def\n",
      "mecab-ko-dic-2.1.1-20180720/Makefile.am\n",
      "mecab-ko-dic-2.1.1-20180720/unk.def\n",
      "mecab-ko-dic-2.1.1-20180720/missing\n",
      "mecab-ko-dic-2.1.1-20180720/VCP.csv\n",
      "mecab-ko-dic-2.1.1-20180720/install-sh\n",
      "mecab-ko-dic-2.1.1-20180720/Hanja.csv\n",
      "mecab-ko-dic-2.1.1-20180720/MAJ.csv\n",
      "mecab-ko-dic-2.1.1-20180720/XSA.csv\n",
      "mecab-ko-dic-2.1.1-20180720/Wikipedia.csv\n",
      "mecab-ko-dic-2.1.1-20180720/tools/\n",
      "mecab-ko-dic-2.1.1-20180720/tools/add-userdic.sh\n",
      "mecab-ko-dic-2.1.1-20180720/tools/mecab-bestn.sh\n",
      "mecab-ko-dic-2.1.1-20180720/tools/convert_for_using_store.sh\n",
      "mecab-ko-dic-2.1.1-20180720/user-dic/\n",
      "mecab-ko-dic-2.1.1-20180720/user-dic/nnp.csv\n",
      "mecab-ko-dic-2.1.1-20180720/user-dic/place.csv\n",
      "mecab-ko-dic-2.1.1-20180720/user-dic/person.csv\n",
      "mecab-ko-dic-2.1.1-20180720/user-dic/README.md\n",
      "mecab-ko-dic-2.1.1-20180720/NorthKorea.csv\n",
      "mecab-ko-dic-2.1.1-20180720/VX.csv\n",
      "mecab-ko-dic-2.1.1-20180720/right-id.def\n",
      "mecab-ko-dic-2.1.1-20180720/VA.csv\n",
      "mecab-ko-dic-2.1.1-20180720/char.def\n",
      "mecab-ko-dic-2.1.1-20180720/NEWS\n",
      "mecab-ko-dic-2.1.1-20180720/MM.csv\n",
      "mecab-ko-dic-2.1.1-20180720/ETN.csv\n",
      "mecab-ko-dic-2.1.1-20180720/AUTHORS\n",
      "mecab-ko-dic-2.1.1-20180720/Person.csv\n",
      "mecab-ko-dic-2.1.1-20180720/XR.csv\n",
      "mecab-ko-dic-2.1.1-20180720/VCN.csv\n",
      "Looking in current directory for macros.\n",
      "configure.ac:2: warning: AM_INIT_AUTOMAKE: two- and three-arguments forms are deprecated.  For more info, see:\n",
      "configure.ac:2: https://www.gnu.org/software/automake/manual/automake.html#Modernize-AM_005fINIT_005fAUTOMAKE-invocation\n",
      "checking for a BSD-compatible install... /usr/bin/install -c\n",
      "checking whether build environment is sane... yes\n",
      "/tmp/mecab-ko-dic-2.1.1-20180720/missing: Unknown `--is-lightweight' option\n",
      "Try `/tmp/mecab-ko-dic-2.1.1-20180720/missing --help' for more information\n",
      "configure: WARNING: 'missing' script is too old or missing\n",
      "checking for a thread-safe mkdir -p... /usr/bin/mkdir -p\n",
      "checking for gawk... no\n",
      "checking for mawk... mawk\n",
      "checking whether make sets $(MAKE)... yes\n",
      "checking whether make supports nested variables... yes\n",
      "checking for mecab-config... /usr/local/bin/mecab-config\n",
      "checking that generated files are newer than configure... done\n",
      "configure: creating ./config.status\n",
      "config.status: creating Makefile\n",
      "make: Nothing to be done for 'all'.\n",
      "make[1]: Entering directory '/tmp/mecab-ko-dic-2.1.1-20180720'\n",
      "make[1]: Nothing to be done for 'install-exec-am'.\n",
      " /usr/bin/mkdir -p '/usr/local/lib/mecab/dic/mecab-ko-dic'\n",
      " /usr/bin/install -c -m 644 model.bin matrix.bin char.bin sys.dic unk.dic left-id.def right-id.def rewrite.def pos-id.def dicrc '/usr/local/lib/mecab/dic/mecab-ko-dic'\n",
      "make[1]: Leaving directory '/tmp/mecab-ko-dic-2.1.1-20180720'\n",
      "fatal: destination path 'mecab-python-0.996' already exists and is not an empty directory.\n",
      "Requirement already satisfied: konlpy in /opt/conda/lib/python3.9/site-packages (0.5.2)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from konlpy) (1.3.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /opt/conda/lib/python3.9/site-packages (from konlpy) (4.6.3)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.9/site-packages (from konlpy) (0.4.4)\n",
      "Requirement already satisfied: beautifulsoup4==4.6.0 in /opt/conda/lib/python3.9/site-packages (from konlpy) (4.6.0)\n",
      "Requirement already satisfied: tweepy>=3.7.0 in /opt/conda/lib/python3.9/site-packages (from konlpy) (3.10.0)\n",
      "Requirement already satisfied: numpy>=1.6 in /opt/conda/lib/python3.9/site-packages (from konlpy) (1.21.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.9/site-packages (from tweepy>=3.7.0->konlpy) (1.16.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /opt/conda/lib/python3.9/site-packages (from tweepy>=3.7.0->konlpy) (2.26.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.0.8)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# mecab 설치\n",
    "!curl -s https://raw.githubusercontent.com/teddylee777/machine-learning/master/99-Misc/01-Colab/mecab-colab.sh | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7864993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "import datasets\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    LineByLineTextDataset,\n",
    "    EarlyStoppingCallback\n",
    "\n",
    ")\n",
    "\n",
    "from transformers import RobertaTokenizerFast\n",
    "from transformers import EncoderDecoderModel\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate\n",
    "from konlpy.tag import Mecab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f9a1f7",
   "metadata": {},
   "source": [
    "## 2. 모델 및 데이터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2ed1b5",
   "metadata": {},
   "source": [
    "### 1) 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ac7c2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoints = \"gogamza/kobart-base-v2\" #/MLM_pretrain_3ep_221121/checkpoint-33000\"#\"gogamza/kobart-base-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoints)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0874605",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count = 0\n",
    "for i in model.parameters():\n",
    "    total_count += 1\n",
    "count= 0\n",
    "for i in model.parameters():\n",
    "    count += 1\n",
    "    i.requires_grad = False\n",
    "    if count == total_count-3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af93706a",
   "metadata": {},
   "source": [
    "### 2) 데이터 불러오기 및 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4c59ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_textfile_path = \"data/train_text.csv\"\n",
    "val_textfile_path = \"data/val_text.csv\"\n",
    "\n",
    "with open(train_textfile_path, encoding=\"utf-8\") as f:\n",
    "            train_textlines = [line for line in f.read().splitlines() if (len(line) > 0 and not line.isspace())]     \n",
    "\n",
    "with open(val_textfile_path, encoding=\"utf-8\") as f:\n",
    "            val_textlines = [line for line in f.read().splitlines() if (len(line) > 0 and not line.isspace())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb8431b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_textlines[0]\n",
    "del val_textlines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dc1d43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(zip(train_textlines), columns=['Text'])\n",
    "val_df = pd.DataFrame(zip(val_textlines), columns=['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c15257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.reset_index(inplace=True, drop=True)\n",
    "val_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "445737db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>그럼 날짜는 가격 큰 변동 없으면 6 28-7 13로 확정할까 우리 비행포함 15일...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kf마스크만 5부제 하는거지 응 면마스크는 아무때나 사도될껀 면마스크말고 부직포 마...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>아 근데 케이크 업체들 봤는데 중앙동쪽 거기는 맛만있고 디자인은 그냥그런것같애 그러...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>칫솔사야하는데 쓱으로 살까 뭘 칫솔사는것까지 물어보시남 아 그 왕칫솔 또 사려나 싶...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>잠도안오네 얼릉 고구마츄 먹고싶단 그게 그렇게 맛있었어 아주 여보 빼이보릿 되버렸네...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  그럼 날짜는 가격 큰 변동 없으면 6 28-7 13로 확정할까 우리 비행포함 15일...\n",
       "1  kf마스크만 5부제 하는거지 응 면마스크는 아무때나 사도될껀 면마스크말고 부직포 마...\n",
       "2  아 근데 케이크 업체들 봤는데 중앙동쪽 거기는 맛만있고 디자인은 그냥그런것같애 그러...\n",
       "3  칫솔사야하는데 쓱으로 살까 뭘 칫솔사는것까지 물어보시남 아 그 왕칫솔 또 사려나 싶...\n",
       "4  잠도안오네 얼릉 고구마츄 먹고싶단 그게 그렇게 맛있었어 아주 여보 빼이보릿 되버렸네..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3a4f8b",
   "metadata": {},
   "source": [
    "## 3. 데이터 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aec5ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab()\n",
    "\n",
    "def sentence_len_total(data):\n",
    "    text_split_text = []\n",
    "    # 반복문으로 Mecab 적용\n",
    "    for text_sen in tqdm(data['Text'].iloc[range(0, len(data))]):\n",
    "        text_split_text.append(mecab.morphs(text_sen))\n",
    "    \n",
    "    temp = pd.DataFrame(zip(text_split_text), columns=['Text'])\n",
    "    \n",
    "    # Mecab 적용 후 길이 출력\n",
    "    text_len = temp.Text.map(len)\n",
    "    \n",
    "    # text_len 사분위수 구하기    \n",
    "    text_Q1 = text_len.quantile(.25)\n",
    "    text_Q3 = text_len.quantile(.75)\n",
    "    text_IQR = text_Q3 - text_Q1\n",
    "    text_Q2 = text_len.quantile(.5)\n",
    "    text_Q4 = text_len.quantile(1)\n",
    "    text_threshold_len_left = text_Q1 - (1.5 * text_IQR)\n",
    "    text_threshold_len_right = text_Q3 + (1.5 * text_IQR)\n",
    "\n",
    "    \n",
    "    print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "    print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "    print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "    print('텍스트의 왼쪽 울타리 범위 : {}'. format(text_threshold_len_left),\n",
    "         '텍스트의 오른쪽 울타리 범위 : {}'. format(text_threshold_len_right))\n",
    "    print('text_Q1 = {}'.format(text_Q1), 'headlines_Q1 = {}'.format(text_Q1))\n",
    "    print('text_Q3 = {}'.format(text_Q3), 'headlines_Q3 = {}'.format(text_Q3))\n",
    "    print('text_IQR = {}'.format(text_IQR), 'headlines_IQR = {}'.format(text_IQR))\n",
    "    print('text_Q2 = {}'.format(text_Q2), 'headlines_Q2 = {}'.format(text_Q2))\n",
    "    print('text_Q4 = {}'.format(text_Q4), 'headlines_Q4 = {}'.format(text_Q4))\n",
    "\n",
    "    \n",
    "    plt.subplot(1,1,1)\n",
    "    plt.boxplot(text_len)\n",
    "    plt.title('text')\n",
    "    plt.show()\n",
    "\n",
    "    plt.title('text')\n",
    "    plt.hist(text_len, bins = 40)\n",
    "    plt.xlabel('length of samples')\n",
    "    plt.ylabel('number of samples')\n",
    "    plt.show()\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dae1bb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279992/279992 [01:11<00:00, 3908.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 7\n",
      "텍스트의 최대 길이 : 923\n",
      "텍스트의 평균 길이 : 55.99256050172862\n",
      "텍스트의 왼쪽 울타리 범위 : -3.0 텍스트의 오른쪽 울타리 범위 : 109.0\n",
      "text_Q1 = 39.0 headlines_Q1 = 39.0\n",
      "text_Q3 = 67.0 headlines_Q3 = 67.0\n",
      "text_IQR = 28.0 headlines_IQR = 28.0\n",
      "text_Q2 = 51.0 headlines_Q2 = 51.0\n",
      "text_Q4 = 923.0 headlines_Q4 = 923.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>그럼 날짜는 가격 큰 변동 없으면 6 28-7 13로 확정할까 우리 비행포함 15일...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kf마스크만 5부제 하는거지 응 면마스크는 아무때나 사도될껀 면마스크말고 부직포 마...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>아 근데 케이크 업체들 봤는데 중앙동쪽 거기는 맛만있고 디자인은 그냥그런것같애 그러...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>칫솔사야하는데 쓱으로 살까 뭘 칫솔사는것까지 물어보시남 아 그 왕칫솔 또 사려나 싶...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>잠도안오네 얼릉 고구마츄 먹고싶단 그게 그렇게 맛있었어 아주 여보 빼이보릿 되버렸네...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279987</th>\n",
       "      <td>도착하샸나염 자리잡고 알려주이소 아아 나 다이소좀 구경하느랔 웅 이제 할리스 지나쳐...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279988</th>\n",
       "      <td>시간잘봐라 겁나 여러가지다 예약내역 올려바바 그러게 호텔은 언제해여 표사고 오늘밤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279989</th>\n",
       "      <td>언제 도착요정이십니까 15분뒤 도착이룝 옥희여 이제 나오묜 될듯 나나홨오 나와 오 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279990</th>\n",
       "      <td>근데 현인가요제 가면 최소20시간은 줄서서 기다려야하는거아님 그정도는아니고 한 열두...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279991</th>\n",
       "      <td>아 그렇구나 어떄 대전 괜찮아 오 대전도 좋은거 같아요 그리고 겨울이니까 겨울바다보...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>279992 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text\n",
       "0       그럼 날짜는 가격 큰 변동 없으면 6 28-7 13로 확정할까 우리 비행포함 15일...\n",
       "1       kf마스크만 5부제 하는거지 응 면마스크는 아무때나 사도될껀 면마스크말고 부직포 마...\n",
       "2       아 근데 케이크 업체들 봤는데 중앙동쪽 거기는 맛만있고 디자인은 그냥그런것같애 그러...\n",
       "3       칫솔사야하는데 쓱으로 살까 뭘 칫솔사는것까지 물어보시남 아 그 왕칫솔 또 사려나 싶...\n",
       "4       잠도안오네 얼릉 고구마츄 먹고싶단 그게 그렇게 맛있었어 아주 여보 빼이보릿 되버렸네...\n",
       "...                                                   ...\n",
       "279987  도착하샸나염 자리잡고 알려주이소 아아 나 다이소좀 구경하느랔 웅 이제 할리스 지나쳐...\n",
       "279988      시간잘봐라 겁나 여러가지다 예약내역 올려바바 그러게 호텔은 언제해여 표사고 오늘밤\n",
       "279989  언제 도착요정이십니까 15분뒤 도착이룝 옥희여 이제 나오묜 될듯 나나홨오 나와 오 ...\n",
       "279990  근데 현인가요제 가면 최소20시간은 줄서서 기다려야하는거아님 그정도는아니고 한 열두...\n",
       "279991  아 그렇구나 어떄 대전 괜찮아 오 대전도 좋은거 같아요 그리고 겨울이니까 겨울바다보...\n",
       "\n",
       "[279992 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_len_total(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e43d741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35004/35004 [00:09<00:00, 3814.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 9\n",
      "텍스트의 최대 길이 : 547\n",
      "텍스트의 평균 길이 : 56.268940692492286\n",
      "텍스트의 왼쪽 울타리 범위 : -3.0 텍스트의 오른쪽 울타리 범위 : 109.0\n",
      "text_Q1 = 39.0 headlines_Q1 = 39.0\n",
      "text_Q3 = 67.0 headlines_Q3 = 67.0\n",
      "text_IQR = 28.0 headlines_IQR = 28.0\n",
      "text_Q2 = 51.0 headlines_Q2 = 51.0\n",
      "text_Q4 = 547.0 headlines_Q4 = 547.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAATbUlEQVR4nO3df2xd513H8fe3TtLQNFnj1lRpnTRDVMTIYmOYUaBIS0thLT9apLIuBVKSyyLEMEMB0lKDtgql4EqAsjKta0m2DJiTqcBaUPlRmitN1tgPF7aS1aAZuqxOuzZp0nbNlMyxv/yRk8i+tePr2M71PXm/pKtzznPOPfd7peSTk+c857mRmUiSyuWiRhcgSZp7hrsklZDhLkklZLhLUgkZ7pJUQoa7JJWQ4S5JJWS464IUEV+PiJ9cKOeR5prhLkklZLjrghMRfwWsAf4hIt6IiG0RcV1EfC4iXo2Ir0TEu4pjfywiDkfE6mL7bRFxNCLWTXaeRn0nqVY4/YAuRBHxdeDXMvPfIuJq4BngV4B/Bm4E9gDrMvNQRGwHfhT4GeCLwMcy8y9qz3P+v4U0Na/cJfhl4InMfCIzxzLzSWAAuKXY/yHgLZwK9oPARxpSpTQDhrsE1wC/WHTJvBoRrwLXA6sAMnME+ATQCfxp+t9dNYFFjS5AapDxAf088FeZ+b7JDiy6bT4IfBz404j44cw8Mcl5pAXDK3ddqF4CvqdY/2vg5yLipyOiJSKWRsS7IqI9IoJTV+07gQrwIvBHU5xHWjAMd12o/hj4g6IL5g7gVuBe4BCnruR/j1N/P34L+G7gD4vumE3Apoj4idrzRMTvnt+vIE3N0TKSVEJeuUtSCRnuklRChrsklZDhLkkltCDGuV9xxRW5du3aRpchSU3l6aefPpyZbZPtWxDhvnbtWgYGBhpdhiQ1lYg4MNU+u2UkqYQMd0kqIcNdkkrIcJekEjLcJamEDHdpEn19fXR2dtLS0kJnZyd9fX2NLkmakQUxFFJaSPr6+ujp6WHnzp1cf/319Pf3U6lUANiwYUODq5PqsyBmhezq6krHuWuh6Ozs5MEHH2T9+vVn2qrVKt3d3ezfv7+BlUkTRcTTmdk16T7DXZqopaWF48ePs3jx4jNtIyMjLF26lNHR0QZWJk10tnC3z12q0dHRQX9//4S2/v5+Ojo6GlSRNHOGu1Sjp6eHSqVCtVplZGSEarVKpVKhp6en0aVJdfOGqlTj9E3T7u5uBgcH6ejoYPv27d5MVVOxz12SmpR97pJ0gTHcJamEDHdJKiHDXZJKyHCXpBIy3CWphAx3SSohw12SSshwl6QSqivcI+LrEfFfEfHliBgo2loj4smI+FqxXFm0R0R8OCKGIuKZiHjHfH4BSdKbzeTKfX1mvn3co673AE9l5rXAU8U2wM3AtcVrC/DRuSpWklSf2XTL3ArsLtZ3A7eNa/9knvJ54LKIWDWLz5EkzVC94Z7Av0bE0xGxpWi7MjNfLNa/CVxZrF8NPD/uvcNFmyTpPKl3yt/rM/NgRHw38GRE/Pf4nZmZETGj6SWLfyS2AKxZs2Ymb5UkTaOuK/fMPFgsXwb+Hngn8NLp7pZi+XJx+EFg9bi3txdtted8ODO7MrOrra3t3L+BJOlNpg33iFgWEctPrwM/BewHHgfuKg67C3isWH8c2FiMmrkOeG1c940k6Tyop1vmSuDvI+L08Z/KzH+OiC8Bn46ICnAAeE9x/BPALcAQ8G1g05xXLUk6q2nDPTP/D3jbJO2vADdO0p7A++ekOknSOfEJVUkqIcNdkkrIcJekEjLcJamEDHdJKiHDXZJKyHCXpBIy3CWphAx3SSohw12SSshwl6QSMtwlqYQMd0kqIcNdkkrIcJcm0dfXR2dnJy0tLXR2dtLX19fokqQZqfc3VKULRl9fHz09PezcuZPrr7+e/v5+KpUKABs2bGhwdVJ94tRvazRWV1dXDgwMNLoMCYDOzk4efPBB1q9ff6atWq3S3d3N/v37G1iZNFFEPJ2ZXZPuM9yliVpaWjh+/DiLFy8+0zYyMsLSpUsZHR1tYGXSRGcLd/vcpRodHR309/dPaOvv76ejo6NBFUkzZ7hLNXp6eqhUKlSrVUZGRqhWq1QqFXp6ehpdmlQ3b6hKNU7fNO3u7mZwcJCOjg62b9/uzVQ1FfvcJalJ2ecuSRcYw12SSshwlybhE6pqdt5QlWr4hKrKwBuqUg2fUFWz8AlVaQZ8QlXNYk5Gy0RES0T8Z0T8Y7H91oj4QkQMRcTeiFhStF9cbA8V+9fOybeQzpOOjg7uu+++CX3u9913n0+oqqnM5IbqB4DBcdu9wJ9n5vcCR4FK0V4Bjhbtf14cJzWN9evX09vby+bNm/nWt77F5s2b6e3tndBNIy10dYV7RLQDPwP8ZbEdwA3Ao8Uhu4HbivVbi22K/TcWx0tNoVqtcvfdd7Nr1y6WL1/Orl27uPvuu6lWq40uTapbXX3uEfEo8MfAcuB3gV8FPl9cnRMRq4F/yszOiNgPvDszh4t9/wv8SGYerjnnFmALwJo1a37owIEDc/alpNmwz13NYlZ97hHxs8DLmfn0XBaVmQ9nZldmdrW1tc3lqaVZcVZIlUE949x/HPj5iLgFWAqsAHYAl0XEosw8CbQDB4vjDwKrgeGIWAS8BXhlziuX5klPTw933HEHy5Yt48CBA1xzzTUcO3aMHTt2NLo0qW7TXrln5u9nZntmrgXeC+zLzF8CqsDtxWF3AY8V648X2xT79+VCGG8pnQNvF6lZzWb6gbuBrRExBFwO7CzadwKXF+1bgXtmV6J0fm3fvp29e/fy3HPPMTo6ynPPPcfevXvZvn17o0uT6uZDTFINb6iqWTjlrzQD3lBVGThxmFRj/A3Vb3zjG6xZs8Ybqmo6XrlLZ7EQui2lc2G4SzXG31AdGxvzhqqakuEu1RgcHGR4eHjCxGHDw8MMDg5O/2ZpgbDPXapx1VVXsW3bNj71qU+d+bGOO++8k6uuuqrRpUl188pdmkTtw0s+zKRmY7hLNV544QV6e3vp7u5m6dKldHd309vbywsvvNDo0qS62S0j1ejo6KC9vX3CT+pVq1XHuaupeOUu1ejp6aFSqVCtVhkZGaFarVKpVOjp6Wl0aVLdvHKXamzYsIHPfe5z3HzzzZw4cYKLL76Y973vfWzYsKHRpUl188pdqtHX18fevXtZtWoVF110EatWrWLv3r309fU1ujSpboa7VGPbtm0sWrSIXbt2cfz4cXbt2sWiRYvYtm1bo0uT6ma4SzWGh4fZvXs369evZ/Hixaxfv57du3czPDzc6NKkuhnuklRChrtUo729nY0bN04YLbNx40ba29sbXZpUN8NdqvHAAw8wOjrK5s2bufjii9m8eTOjo6M88MADjS5NqpvhLtXYsGEDO3bsYNmyZUQEy5YtY8eOHQ6FVFPxZ/YkqUn5M3vSDPX19U2Y8tcx7mo2PqEq1ejr66Onp4edO3eemfK3UqkA2DWjpmG3jFSjs7OT2267jc985jMMDg7S0dFxZnv8ZGJSo52tW8Yrd6nGs88+y0svvcSll14KwLFjx/jYxz7GK6+80uDKpPrZ5y7VaGlpYWxsbML0A2NjY7S0tDS6NKluhrtU4+TJkyxZsmRC25IlSzh58mSDKpJmznCXJrFp06YJv8S0adOmRpckzYh97lKN9vZ2Pv7xj7/pB7KdfkDNxCt3qYbTD6gMpg33iFgaEV+MiK9ExFcj4r6i/a0R8YWIGIqIvRGxpGi/uNgeKvavnefvIM0ppx9QGUw7zj0iAliWmW9ExGKgH/gAsBX4u8zcExEPAV/JzI9GxG8AP5CZvx4R7wV+ITPvONtnOM5dkmZuVtMP5ClvFJuLi1cCNwCPFu27gduK9VuLbYr9Nxb/QEiSzpO6+twjoiUivgy8DDwJ/C/wamaeHhs2DFxdrF8NPA9Q7H8NuHySc26JiIGIGDh06NCsvoQkaaK6wj0zRzPz7UA78E5g3Ww/ODMfzsyuzOxqa2ub7emkOXV6GGREnBkOKTWTGY2WycxXgSrwo8BlEXF6KGU7cLBYPwisBij2vwXwuW01je7ubh566CHuv/9+jh07xv33389DDz1kwKup1DNapi0iLivWvwu4CRjkVMjfXhx2F/BYsf54sU2xf18uhNnJpDo98sgj9Pb2snXrVi655BK2bt1Kb28vjzzySKNLk+pWz5X7KqAaEc8AXwKezMx/BO4GtkbEEKf61HcWx+8ELi/atwL3zH3Z0vw5ceIEra2tE+Zzb21t5cSJE40uTaqbU/5KNRYvXsyKFSt49NFHzzyhevvtt/P6668zMjLS6PKkM5zyV5qBFStWcOTIEW666SZGR0dpaWlhdHSU1tbWRpcm1c3pB6QaR48eBWB0dHTC8nS71AwMd6lGZrJ8+XL27dvHd77zHfbt28fy5ctZCF2YUr0Md2kSl1xyyVm3pYXOcJcmccMNN0yYz/2GG25odEnSjBjuUo3W1lb27NnD4cOHGRsb4/Dhw+zZs8cbqmoqhrtU48477wTg8OHDE5an26VmYLhLNarVKvfeey/r1q3joosuYt26ddx7771Uq9VGlybVzXCXagwODnLkyBGGhoYYGxtjaGiII0eOMDg42OjSpLr5hKpU4/LLL+fIkSNvam9tbeWVV5wDTwvHrH6sQ7rQnA72Sy+9dMJyssCXFirDXZrCG2+8MWEpNRPDXZrCypUrJyylZmK4S1N47bXXJiylZmK4S1MYGxubsJSaieEuSSVkuEtTWLp06YSl1EwMd2kKx48fn7CUmonhLkklZLhLUgkZ7pJUQoa7JJWQ4S5JJWS4S1IJGe6SVEKGuySVkOEuSSVkuEtSCU0b7hGxOiKqEfFsRHw1Ij5QtLdGxJMR8bViubJoj4j4cEQMRcQzEfGO+f4SkqSJ6rlyPwn8TmZ+P3Ad8P6I+H7gHuCpzLwWeKrYBrgZuLZ4bQE+OudVS5LOatpwz8wXM/M/ivVvAYPA1cCtwO7isN3AbcX6rcAn85TPA5dFxKq5LlySNLUZ9blHxFrgB4EvAFdm5ovFrm8CVxbrVwPPj3vbcNFWe64tETEQEQOHDh2aad2SpLOoO9wj4lLgb4HfzszXx+/LzARyJh+cmQ9nZldmdrW1tc3krZKkadQV7hGxmFPB/jeZ+XdF80unu1uK5ctF+0Fg9bi3txdtkqTzpJ7RMgHsBAYz88/G7XocuKtYvwt4bFz7xmLUzHXAa+O6byRJ58GiOo75ceBXgP+KiC8XbfcCfwJ8OiIqwAHgPcW+J4BbgCHg28CmuSxYkjS9acM9M/uBmGL3jZMcn8D7Z1mXJGkWfEJVkkrIcJekEjLcJamEDHdJKiHDXZJKyHCXpBIy3CWphAx3SSohw12SSshwl6QSMtwlqYQMd0kqIcNdkkrIcJekEjLcJamEDHdJKiHDXZJKyHCXpBIy3CWphAx3SSohw12SSshwl6QSMtwlqYQMd0kqIcNdkkrIcJekEjLcJamEpg33iNgVES9HxP5xba0R8WREfK1YrizaIyI+HBFDEfFMRLxjPouXZioipn3N9v3TnUM6H+q5cv8E8O6atnuApzLzWuCpYhvgZuDa4rUF+OjclCnNjcyc9jXb9093Dul8mDbcM/OzwJGa5luB3cX6buC2ce2fzFM+D1wWEavmqFZJUp3Otc/9ysx8sVj/JnBlsX418Py444aLtjeJiC0RMRARA4cOHTrHMqS5N9WVt1fkaiazvqGap/7Ez/hPfWY+nJldmdnV1tY22zKkOTW+e8WuFjWjcw33l053txTLl4v2g8Dqcce1F22SpPPoXMP9ceCuYv0u4LFx7RuLUTPXAa+N676RJJ0ni6Y7ICL6gHcBV0TEMPBB4E+AT0dEBTgAvKc4/AngFmAI+DawaR5qliRNY9pwz8wNU+y6cZJjE3j/bIuSJM2OT6hKUgkZ7pJUQoa7JJWQ4S5JJWS4S1IJGe6SVEKGuySV0LTj3KWFqrW1laNHj87755yP+dlXrlzJkSO1k69K585wV9M6evRoaSb08gc+NNfslpGkEjLcJamEDHdJKiH73NW08oMr4ENvaXQZcyI/uKLRJahkDHc1rbjv9VLdUM0PNboKlYndMpJUQoa7JJWQ4S5JJWSfu5paWR7+WblyZaNLUMkY7mpa5+NmakSU5qatLix2y0hSCRnuklRChrsklZDhLkklZLhLUgkZ7pJUQoa7JJWQ4S5JJWS4S1IJzUu4R8S7I+J/ImIoIu6Zj8+QzkVEzOh1Lu8py5QIam5zPv1ARLQAHwFuAoaBL0XE45n57Fx/ljRTTiWgC8V8XLm/ExjKzP/LzO8Ae4Bb5+FzJElTmI9wvxp4ftz2cNE2QURsiYiBiBg4dOjQPJQhSReuht1QzcyHM7MrM7va2toaVYYkldJ8hPtBYPW47faiTZJ0nsxHuH8JuDYi3hoRS4D3Ao/Pw+dIkqYw56NlMvNkRPwm8C9AC7ArM786158jSZravPwSU2Y+ATwxH+eWJE3PJ1QlqYRiITzUERGHgAONrkOaxBXA4UYXIU3hmsycdLjhggh3aaGKiIHM7Gp0HdJM2S0jSSVkuEtSCRnu0tk93OgCpHNhn7sklZBX7pJUQoa7JJWQ4S5NIiJ2RcTLEbG/0bVI58Jwlyb3CeDdjS5COleGuzSJzPwscKTRdUjnynCXpBIy3CWphAx3SSohw12SSshwlyYREX3AvwPfFxHDEVFpdE3STDj9gCSVkFfuklRChrsklZDhLkklZLhLUgkZ7pJUQoa7JJWQ4S5JJfT/WtpjR+y91YEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbDklEQVR4nO3df7hmZV3v8fdHUFBDAZm4cEAHj5yMTBFHwCMVSgGCBZ2jiGUQkVwVJ6j8EZQJaVzCZfkDLRQFQTKJ/BEkHGlEyDwqMAjyUw4TDMGEMspvTXLge/5Y99aH7Z6ZZ9ae59nz7P1+Xde6nrXutZ61vjez9/5y3+te90pVIUlSH0+Y6wAkSZPLJCJJ6s0kIknqzSQiSerNJCJJ6s0kIknqzSQiSerNJCKNUJKVSX5xUzmPtLGZRCRJvZlEpBFJci7wLOCfkjyc5C1J9kry5ST3J/l6kn3asf8jybeT7NS2X5jkviTPm+k8c1Unabo47Yk0OklWAr9dVZ9Pshi4DvgN4HPAvsB5wPOqanWSk4GXAgcBVwIfqqoPTD/P+GshrZ0tEWl8Xg9cXFUXV9VjVbUMWA4c2PafBDydLoGsAv56TqKUNoBJRBqfZwOvaV1Z9ye5H9gb2AGgqn4AnA08H/irsptAE2DzuQ5AmucGE8GdwLlV9YaZDmzdXScCHwX+KslLquqRGc4jbTJsiUij9S3gOW39b4FfTrJ/ks2SbJlknyQ7JgldK+RM4CjgbuAdazmPtMkwiUij9U7gra3r6rXAwcCfAKvpWiZvpvs9PBb4SeDPWjfWkcCRSX5u+nmSvGm8VZDWztFZkqTebIlIknoziUiSejOJSJJ6M4lIknpbcM+JbLfddrVkyZK5DkOSJsbVV1/97apaNNO+BZdElixZwvLly+c6DEmaGEnuWNs+u7MkSb2ZRCRJvZlEJEm9mUQkSb2ZRCRJvZlEJEm9mUQkSb2ZRCRJvZlEJEm9Lbgn1ufKkuMvWuf+laccNKZIJGnjsSUiSeptZEkkyVlJ7klyw0DZtkmWJbm1fW7TypPktCQrklyXZPeB7xzRjr81yRED5S9Ocn37zmntHdWSpDEaZUvkbOCAaWXHA5dW1S7ApW0b4JXALm05GjgduqQDnAjsCewBnDiVeNoxbxj43vRrSZJGbGRJpKq+CNw7rfhg4Jy2fg5wyED5x6rzVWDrJDsA+wPLqureqroPWAYc0PY9raq+Wt1L4j82cC5J0piM+57I9lV1d1v/JrB9W18M3Dlw3F2tbF3ld81QPqMkRydZnmT56tWrZ1cDSdIPzdmN9daCqDFd64yqWlpVSxctmvG9KpKkHsadRL7VuqJon/e08lXATgPH7djK1lW+4wzlkqQxGncSuRCYGmF1BHDBQPnhbZTWXsADrdvrEmC/JNu0G+r7AZe0fQ8m2auNyjp84FySpDEZ2cOGST4B7ANsl+QuulFWpwDnJzkKuAM4tB1+MXAgsAL4HnAkQFXdm+QdwFXtuLdX1dTN+t+jGwH2ZOD/tEWSNEYjSyJV9bq17Np3hmMLOGYt5zkLOGuG8uXA82cToyRpdnxiXZLUm0lEktSbSUSS1JtJRJLUm0lEktSbSUSS1JtJRJLUm0lEktSbSUSS1JtJRJLUm0lEktSbSUSS1JtJRJLUm0lEktSbSUSS1JtJRJLUm0lEktSbSUSS1JtJRJLUm0lEktSbSUSS1JtJRJLUm0lEktSbSUSS1JtJRJLUm0lEktSbSUSS1JtJRJLUm0lEktSbSUSS1JtJRJLU25wkkSR/mOTGJDck+USSLZPsnOSKJCuS/H2SJ7Vjt2jbK9r+JQPnOaGV35Jk/7moiyQtZGNPIkkWA8cCS6vq+cBmwGHAqcB7quq5wH3AUe0rRwH3tfL3tONIsmv73s8ABwB/k2SzcdZFkha6uerO2hx4cpLNgacAdwOvAD7Z9p8DHNLWD27btP37JkkrP6+qHqmq24EVwB7jCV+SBHOQRKpqFfCXwL/TJY8HgKuB+6tqTTvsLmBxW18M3Nm+u6Yd/4zB8hm+8zhJjk6yPMny1atXb9wKSdICNhfdWdvQtSJ2Bp4JPJWuO2pkquqMqlpaVUsXLVo0yktJ0oIyF91ZvwjcXlWrq+oHwKeBlwFbt+4tgB2BVW19FbATQNv/dOA7g+UzfEeSNAZzkUT+HdgryVPavY19gZuAy4BXt2OOAC5o6xe2bdr+L1RVtfLD2uitnYFdgCvHVAdJEt0N7rGqqiuSfBL4GrAGuAY4A7gIOC/JX7SyM9tXzgTOTbICuJduRBZVdWOS8+kS0BrgmKp6dKyVkaQFbuxJBKCqTgROnFZ8GzOMrqqq7wOvWct5TgZO3ugBSpKG4hPrkqTe1ptEkrwmyVZt/a1JPp1k99GHJkna1A3TnfVnVfUPSfamG1n1LuB0YM+RRrbALDn+orXuW3nKQWOMRJKGN0x31tTN6oOAM6rqIuBJowtJkjQphkkiq5J8CHgtcHGSLYb8niRpnhsmGRwKXALsX1X3A9sCbx5lUJKkybDeJFJV3wPuAfZuRWuAW0cZlCRpMgwzOutE4I+BE1rRE4G/HWVQkqTJMEx31q8CvwJ8F6Cq/gPYapRBSZImwzBJ5L/aXFUFkOSpow1JkjQphkki57fRWVsneQPweeDDow1LkjQJ1vuwYVX9ZZJfAh4Efgp4W1UtG3lkkqRN3lATMLakYeKQJD3OWpNIkodo90Gm7wKqqp42sqgkSRNhrUmkqhyBJUlap6G6s9qsvXvTtUy+VFXXjDQqSdJEGOZhw7cB5wDPALYDzk7y1lEHJkna9A3TEvl14IXtDYMkOQW4FviLEcYlSZoAwzwn8h/AlgPbWwCrRhOOJGmSDNMSeQC4MckyunsivwRcmeQ0gKo6doTxSZI2YcMkkc+0ZcrlowlFkjRphnli/ZxxBCJJmjzDjM56VZJrktyb5MEkDyV5cBzBSZI2bcN0Z70X+J/A9W02X0mSgOFGZ90J3GACkSRNN0xL5C3AxUn+BXhkqrCq3j2yqCRJE2GYJHIy8DDdsyJPGm04kqRJMkwSeWZVPX/kkUiSJs4w90QuTrLfyCORJE2cYZLI7wKfS/KfDvGVJA0a5mFD3ysiSZrRsO8T2QbYhYGJGKvqi6MKSpI0GYZ5Yv23gS8ClwB/3j5Pms1Fk2yd5JNJvpHk5iQvTbJtkmVJbm2f27Rjk+S0JCuSXNdekDV1niPa8bcmOWI2MUmSNtww90SOA14C3FFVLwdeBNw/y+u+D/hcVT0PeCFwM3A8cGlV7QJc2rYBXknXCtoFOBo4HSDJtsCJwJ7AHsCJU4lHkjQewySR7w+8kGqLqvoG8FN9L5jk6cDPA2cCVNV/VdX9wMF0b1CkfR7S1g8GPladrwJbJ9kB2B9YVlX3VtV9wDLggL5xSZI23DBJ5K4kWwP/CCxLcgFwxyyuuTOwGvhom9jxI0meCmxfVXe3Y74JbN/WF9NNvfLDeFrZ2sp/TJKjkyxPsnz16tWzCF2SNGi9SaSqfrWq7q+qk4A/o2tBHDKLa24O7A6cXlUvAr7Lj7qupq5ZdC/A2iiq6oyqWlpVSxctWrSxTitJC94wN9b/W5ItpjaBJcBTZnHNu4C7quqKtv1JuqTyrdZNRfu8p+1fBew08P0dW9nayiVJYzJMd9angEeTPBc4g+4P99/1vWBVfRO4M8nUfZV9gZuAC4GpEVZHABe09QuBw9sorb2AB1q31yXAfkm2aTfU92tlkqQxGeY5kceqak2SXwXeX1XvT3LNLK/7+8DHkzwJuA04ki6hnZ/kKLp7Loe2Yy8GDgRWAN9rx1JV9yZ5B3BVO+7tVXXvLOOSJG2AYZLID5K8jq518Mut7ImzuWhVXQssnWHXvjMcW8AxaznPWcBZs4lFktTfMN1ZRwIvBU6uqtuT7AycO9qwJEmTYJi5s24Cjh3Yvh04dZRBSZImwzAtEUmSZjTUBIxavyXHXzTXIUjS2K21JZLk3PZ53PjCkSRNknV1Z704yTOB32rPYmw7uIwrQEnSpmtd3VkfpJtN9znA1XRPq0+pVi5JWsDW2hKpqtOq6qeBs6rqOVW188BiApEkDTXE93eTvBD4uVb0xaq6brRhSZImwTATMB4LfBz4ybZ8PMnvjzowSdKmb5ghvr8N7FlV3wVIcirwFeD9owxMP7K+4cMrTzloTJFI0uMN87BhgEcHth/l8TfZJUkL1DAtkY8CVyT5TNs+hPZqW0nSwjbMjfV3J7kc2LsVHVlVs50KXpI0Dww17UlVfQ342ohjkSRNGCdglCT1ZhKRJPW2ziSSZLMkl40rGEnSZFlnEqmqR4HHkjx9TPFIkibIMDfWHwauT7IM+O5UYVUdu/avSJIWgmGSyKfbIknS4wzznMg5SZ4MPKuqbhlDTJKkCTHMBIy/DFwLfK5t75bkwhHHJUmaAMMM8T0J2AO4H6CqrsUXUkmSGC6J/KCqHphW9tgogpEkTZZhbqzfmOTXgM2S7AIcC3x5tGFJkibBMC2R3wd+BngE+ATwIPAHI4xJkjQhhhmd9T3gT9vLqKqqHhp9WJKkSTDM6KyXJLkeuI7uocOvJ3nx6EOTJG3qhrkncibwe1X1rwBJ9qZ7UdULRhmYJGnTN8w9kUenEghAVX0JWDO6kCRJk2KtSSTJ7kl2B/4lyYeS7JPkF5L8DXD5bC/cZgi+Jsln2/bOSa5IsiLJ3yd5Uivfom2vaPuXDJzjhFZ+S5L9ZxuTJGnDrKs766+mbZ84sF4b4drHATcDT2vbpwLvqarzknwQOAo4vX3eV1XPTXJYO+61SXYFDqMbOfZM4PNJ/nubeViSNAZrTSJV9fJRXTTJjsBBwMnAHyUJ8Arg19oh59A9KX86cHBbB/gk8IF2/MHAeVX1CHB7khV0T9Z/ZVRxS5Ieb7031pNsDRwOLBk8fpZTwb8XeAuwVdt+BnB/VU3da7kLWNzWFwN3tmuuSfJAO34x8NWBcw5+Z3odjgaOBnjWs541i7AlSYOGubF+MV0CuR64emDpJcmrgHuqqvc5NlRVnVFVS6tq6aJFi8Z1WUma94YZ4rtlVf3RRrzmy4BfSXIgsCXdPZH3AVsn2by1RnYEVrXjVwE7AXcl2Rx4OvCdgfIpg9+RJI3BMC2Rc5O8IckOSbadWvpesKpOqKodq2oJ3Y3xL1TVrwOXAa9uhx0BXNDWL2zbtP1fqKpq5Ye10Vs7A7sAV/aNS5K04YZpifwX8C7gT/nRqKxi408H/8fAeUn+AriG7iFH2ue57cb5vXSJh6q6Mcn5wE10z60c48gsSRqvYZLIG4HnVtW3N/bFq+py2jMnVXUb3eiq6cd8H3jNWr5/Mt0IL0nSHBimO2sF8L1RByJJmjzDtES+C1yb5DK66eCBWQ/xlSTNA8MkkX9siyRJjzPM+0TOGUcgkqTJM8wT67czw1xZVbWxR2dJkibMMN1ZSwfWt6QbKdX7ORFJ0vyx3tFZVfWdgWVVVb2XbvJESdICN0x31u4Dm0+ga5kM04KRJM1zwySDwfeKrAFWAoeOJBpJ0kQZZnTWyN4rIkmabMN0Z20B/C9+/H0ibx9dWJKkSTBMd9YFwAN07xB5ZD3HSpIWkGGSyI5VdcDII5EkTZxhJmD8cpKfHXkkkqSJM0xLZG/gN9uT648AAaqqXjDSyCRJm7xhksgrRx6FJGkiDTPE945xBCJJmjzD3BORJGlGJhFJUm8mEUlSbyYRSVJvJhFJUm8mEUlSb74XZB5YcvxFa9238hTfHyZpdGyJSJJ6M4lIknoziUiSejOJSJJ6M4lIknoziUiSejOJSJJ6G3sSSbJTksuS3JTkxiTHtfJtkyxLcmv73KaVJ8lpSVYkuS7J7gPnOqIdf2uSI8ZdF0la6OaiJbIGeGNV7QrsBRyTZFfgeODSqtoFuLRtQ/dSrF3acjRwOnRJBzgR2BPYAzhxKvFIksZj7Emkqu6uqq+19YeAm4HFwMHAOe2wc4BD2vrBwMeq81Vg6yQ7APsDy6rq3qq6D1gGHDC+mkiS5vSeSJIlwIuAK4Dtq+rutuubwPZtfTFw58DX7mplayuf6TpHJ1meZPnq1as3XgUkaYGbsySS5CeATwF/UFUPDu6rqgJqY12rqs6oqqVVtXTRokUb67SStODNSRJJ8kS6BPLxqvp0K/5W66aifd7TylcBOw18fcdWtrZySdKYzMXorABnAjdX1bsHdl0ITI2wOgK4YKD88DZKay/ggdbtdQmwX5Jt2g31/VqZJGlM5mIq+JcBvwFcn+TaVvYnwCnA+UmOAu4ADm37LgYOBFYA3wOOBKiqe5O8A7iqHff2qrp3LDWQJAFzkESq6ktA1rJ73xmOL+CYtZzrLOCsjRedJGlD+MS6JKk3k4gkqTeTiCSpN5OIJKk3k4gkqTeTiCSpN5OIJKm3uXjYUGO05PiL1rl/5SkHjSkSSfORLRFJUm8mEUlSbyYRSVJvJhFJUm8mEUlSbyYRSVJvJhFJUm8mEUlSbyYRSVJvJhFJUm8mEUlSbyYRSVJvTsC4AdY3maEkLTS2RCRJvdkSWeCcKl7SbNgSkST1ZhKRJPVmEpEk9WYSkST15o11rdO6brx7012SLRFJUm8mEUlSbyYRSVJv3hNRbz6oKGnik0iSA4D3AZsBH6mqU+Y4JDXelJfmv4lOIkk2A/4a+CXgLuCqJBdW1U1zG5nWx1aMND9MdBIB9gBWVNVtAEnOAw4GTCITbi5nTDaBScOb9CSyGLhzYPsuYM/pByU5Gji6bT6c5JYhzr0d8O1ZR7jpmu/1g551zKkjiGQ0/DecHyahjs9e245JTyJDqaozgDM25DtJllfV0hGFNOfme/1g/tdxvtcPrOMkmPQhvquAnQa2d2xlkqQxmPQkchWwS5KdkzwJOAy4cI5jkqQFY6K7s6pqTZL/DVxCN8T3rKq6cSOdfoO6vybQfK8fzP86zvf6gXXc5KWq5joGSdKEmvTuLEnSHDKJSJJ6M4lMk+SAJLckWZHk+LmOp68kZyW5J8kNA2XbJlmW5Nb2uU0rT5LTWp2vS7L73EU+nCQ7JbksyU1JbkxyXCufT3XcMsmVSb7e6vjnrXznJFe0uvx9G1RCki3a9oq2f8mcVmBISTZLck2Sz7bt+Va/lUmuT3JtkuWtbN78nJpEBgxMo/JKYFfgdUl2nduoejsbOGBa2fHApVW1C3Bp24auvru05Wjg9DHFOBtrgDdW1a7AXsAx7d9qPtXxEeAVVfVCYDfggCR7AacC76mq5wL3AUe1448C7mvl72nHTYLjgJsHtudb/QBeXlW7DTwPMn9+TqvKpS3AS4FLBrZPAE6Y67hmUZ8lwA0D27cAO7T1HYBb2vqHgNfNdNykLMAFdHOozcs6Ak8BvkY3I8O3gc1b+Q9/ZulGKb60rW/ejstcx76eeu1I90f0FcBngcyn+rVYVwLbTSubNz+ntkQeb6ZpVBbPUSyjsH1V3d3Wvwls39Ynut6tW+NFwBXMszq2rp5rgXuAZcC/AfdX1Zp2yGA9fljHtv8B4BljDXjDvRd4C/BY234G86t+AAX8c5Kr2xRMMI9+Tif6ORH1V1WVZOLHdyf5CeBTwB9U1YNJfrhvPtSxqh4FdkuyNfAZ4HlzG9HGk+RVwD1VdXWSfeY4nFHau6pWJflJYFmSbwzunPSfU1sijzffp1H5VpIdANrnPa18Iuud5Il0CeTjVfXpVjyv6jilqu4HLqPr3tk6ydT/AA7W44d1bPufDnxnvJFukJcBv5JkJXAeXZfW+5g/9QOgqla1z3vo/kdgD+bRz6lJ5PHm+zQqFwJHtPUj6O4jTJUf3kaG7AU8MNDU3iSla3KcCdxcVe8e2DWf6riotUBI8mS6ez430yWTV7fDptdxqu6vBr5QrWN9U1RVJ1TVjlW1hO537QtV9evMk/oBJHlqkq2m1oH9gBuYRz+nc35TZlNbgAOB/0fX9/yncx3PLOrxCeBu4Ad0/apH0fUfXwrcCnwe2LYdG7pRaf8GXA8snev4h6jf3nR9zdcB17blwHlWxxcA17Q63gC8rZU/B7gSWAH8A7BFK9+yba9o+58z13XYgLruA3x2vtWv1eXrbblx6m/KfPo5ddoTSVJvdmdJknoziUiSejOJSJJ6M4lIknoziUiSejOJaN5K8vAIzrlbkgMHtk9K8qZZnO81SW5OctnGibB3HCuTbDeXMWgymUSkDbMb3fMoG8tRwBuq6uUb8ZzS2JhEtCAkeXOSq9o7Gqbey7GktQI+3N7X8c/tyXCSvKQde22SdyW5oc1i8Hbgta38te30uya5PMltSY5dy/Vf194pcUOSU1vZ2+gemjwzybumHb9Dki+269yQ5Oda+elJlmfg/SKtfGWSd069syLJ7kkuSfJvSX6nHbNPO+dF6d6Z88EkP/Y3IMnr073H5NokH2qTQG6W5OwWy/VJ/nCW/ySaL+b6aUcXl1EtwMPtcz/gDLqngZ9AN+X4z9NNlb8G2K0ddz7w+rZ+Az+advwU2pT6wG8CHxi4xknAl4EtgO3o5nJ64rQ4ngn8O7CIbtLTLwCHtH2XM8NTycAb+dHTzZsBW7X1bQfKLgde0LZXAr/b1t9D95T7Vu2a32rl+wDfp3uKejO6WYFfPfD97YCfBv5pqg7A3wCHAy8Glg3Et/Vc//u6bBqLLREtBPu15Rq6d3I8j+6lPwC3V9W1bf1qYEmbr2qrqvpKK/+79Zz/oqp6pKq+TTeR3vbT9r8EuLyqVlc3hfnH6ZLYulwFHJnkJOBnq+qhVn5okq+1uvwM3cvTpkzN83Y9cEVVPVRVq4FHpubgAq6sqtuqmx34E3QtoUH70iWMq9oU9PvSJZ3bgOckeX+SA4AH1xO/FgingtdCEOCdVfWhxxV27yF5ZKDoUeDJPc4//Ryz/r2qqi8m+XngIODsJO8G/hV4E/CSqrovydl080lNj+OxaTE9NhDT9HmOpm8HOKeqTpgeU5IXAvsDvwMcCvzWhtZL848tES0ElwC/le7dIyRZ3N7tMKPqpl1/KMmereiwgd0P0XUTbYgrgV9Isl26VzC/DviXdX0hybPpuqE+DHwE2B14GvBd4IEk29O9SnVD7dFmqX4C8FrgS9P2Xwq8euq/T7p3gT+7jdx6QlV9Cnhri0eyJaL5r6r+OclPA1/pZpDnYeD1dK2GtTkK+HCSx+j+4D/Qyi8Djm9dPe8c8vp3Jzm+fTd03V8XrOdr+wBvTvKDFu/hVXV7kmuAb9C9/e7/DnP9aa4CPgA8t8XzmWmx3pTkrXRv4nsC3SzQxwD/CXx04Eb8j7VUtDA5i680gyQ/UVUPt/Xj6d5zfdwchzUr6d4e+KaqetUch6J5xJaINLODkpxA9ztyB92oLEnT2BKRJPXmjXVJUm8mEUlSbyYRSVJvJhFJUm8mEUlSb/8fYPm5zmSVykYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>웅 영업팀과장님이 보내줬는데 팀장님이 해줄지 모르겠다 저번에 부산갈때도 숙소로 엄청...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>너는 잘가라 회사 선택 잘해 알겠어 많이 힘들구나 나도 이제 이력서쓰고 영어도 해야...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>느낌상 대통령까지는 아니고 오시면 여사님정도오시지않을까 그러면서 샘 여기있었구낭 종...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>숨만수이 도 숨만쉬어도 100 이내 한달안에 일 무조건 해야대 아 딱한달 그냥 아무...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>목요일은 외근이구 금요일은 출장 금요일이 당진이양 아닝아닝 10일이 당진이야 그럼 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34999</th>\n",
       "      <td>방금 샐러드 정기배송 주문한 거 먹었눈데 왜 먹어도 배고푸야 샐러드 정기배송도 시켜...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35000</th>\n",
       "      <td>닭갈비 맛있었다 맛나맛나 그티웅 아깐 먹기 싫다더니 역시 너의 선택 최고엿어 요즘 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35001</th>\n",
       "      <td>나 핫바 먹어야지 먹을래 아니 난 안 무거 그럼 나만 먹는다잉 핫바 찍어먹을 소스 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35002</th>\n",
       "      <td>아 본죽에 신메뉴 나온 거 알아 오 신메뉴 나온 걸 왜 못봤지 언니는 오늘 갔었는데...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35003</th>\n",
       "      <td>혹시 커피 시식하는거 남으면 그대 것을 아주 챙겨봅 아주감사합니다 엄마가 카누보다 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35004 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text\n",
       "0      웅 영업팀과장님이 보내줬는데 팀장님이 해줄지 모르겠다 저번에 부산갈때도 숙소로 엄청...\n",
       "1      너는 잘가라 회사 선택 잘해 알겠어 많이 힘들구나 나도 이제 이력서쓰고 영어도 해야...\n",
       "2      느낌상 대통령까지는 아니고 오시면 여사님정도오시지않을까 그러면서 샘 여기있었구낭 종...\n",
       "3      숨만수이 도 숨만쉬어도 100 이내 한달안에 일 무조건 해야대 아 딱한달 그냥 아무...\n",
       "4      목요일은 외근이구 금요일은 출장 금요일이 당진이양 아닝아닝 10일이 당진이야 그럼 ...\n",
       "...                                                  ...\n",
       "34999  방금 샐러드 정기배송 주문한 거 먹었눈데 왜 먹어도 배고푸야 샐러드 정기배송도 시켜...\n",
       "35000  닭갈비 맛있었다 맛나맛나 그티웅 아깐 먹기 싫다더니 역시 너의 선택 최고엿어 요즘 ...\n",
       "35001  나 핫바 먹어야지 먹을래 아니 난 안 무거 그럼 나만 먹는다잉 핫바 찍어먹을 소스 ...\n",
       "35002  아 본죽에 신메뉴 나온 거 알아 오 신메뉴 나온 걸 왜 못봤지 언니는 오늘 갔었는데...\n",
       "35003  혹시 커피 시식하는거 남으면 그대 것을 아주 챙겨봅 아주감사합니다 엄마가 카누보다 ...\n",
       "\n",
       "[35004 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_len_total(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2fe3e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text\n",
      "0  그럼 날짜는 가격 큰 변동 없으면 6 28-7 13로 확정할까 우리 비행포함 15일...\n",
      "1  kf마스크만 5부제 하는거지 응 면마스크는 아무때나 사도될껀 면마스크말고 부직포 마...\n",
      "2  아 근데 케이크 업체들 봤는데 중앙동쪽 거기는 맛만있고 디자인은 그냥그런것같애 그러...\n",
      "3  칫솔사야하는데 쓱으로 살까 뭘 칫솔사는것까지 물어보시남 아 그 왕칫솔 또 사려나 싶...\n",
      "4  잠도안오네 얼릉 고구마츄 먹고싶단 그게 그렇게 맛있었어 아주 여보 빼이보릿 되버렸네...\n",
      "                                                Text\n",
      "0  웅 영업팀과장님이 보내줬는데 팀장님이 해줄지 모르겠다 저번에 부산갈때도 숙소로 엄청...\n",
      "1  너는 잘가라 회사 선택 잘해 알겠어 많이 힘들구나 나도 이제 이력서쓰고 영어도 해야...\n",
      "2  느낌상 대통령까지는 아니고 오시면 여사님정도오시지않을까 그러면서 샘 여기있었구낭 종...\n",
      "3  숨만수이 도 숨만쉬어도 100 이내 한달안에 일 무조건 해야대 아 딱한달 그냥 아무...\n",
      "4  목요일은 외근이구 금요일은 출장 금요일이 당진이양 아닝아닝 10일이 당진이야 그럼 ...\n"
     ]
    }
   ],
   "source": [
    "print(train_df.head())\n",
    "print(val_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521cead2",
   "metadata": {},
   "source": [
    "## 4. 데이터 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8355278",
   "metadata": {},
   "source": [
    "### 1) dataset으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1af8d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset.from_pandas(train_df)\n",
    "val_data = Dataset.from_pandas(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70524776",
   "metadata": {},
   "source": [
    "### 2) EDA 바탕으로 길이 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40d36ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input = 70# 5e128\n",
    "max_target = 70 # 5e 128\n",
    "batch_size = 4\n",
    "ignore_index = -100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999f69ef",
   "metadata": {},
   "source": [
    "### 3) 토큰화 함수 구현 및 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07493c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ignored_data(inputs, max_len, ignore_index):\n",
    "    if len(inputs) < max_len:\n",
    "        pad = [ignore_index] *(max_len - len(inputs)) # ignore_index즉 -100으로 패딩을 만들 것인데 max_len - lne(inpu)\n",
    "        inputs = np.concatenate([inputs, pad])\n",
    "    else:\n",
    "        inputs = inputs[:max_len]\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c7310c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data_to_process):\n",
    "    label_id= []\n",
    "    label_ids = []\n",
    "\n",
    "    inputs = [dialogue for dialogue in data_to_process['Text']]\n",
    "    model_inputs = tokenizer(inputs,  max_length=max_input, padding='max_length', truncation=True)\n",
    "\n",
    "    for i in range(len(data_to_process['Text'])):\n",
    "        label_id.append(tokenizer.encode(data_to_process['Text'][i]))  \n",
    "    for i in range(len(data_to_process['Text'])):\n",
    "        label_id[i].append(tokenizer.eos_token_id)\n",
    "        label_ids.append(add_ignored_data(label_id[i], max_target, ignore_index))\n",
    "\n",
    "    model_inputs['labels'] = label_ids\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3df3aaa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4992cca808b4741afd24b2388de7180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/280 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8daab800da0449cbf391cff81578925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_tokenize_data = train_data.map(preprocess_data, batched = True, remove_columns=['Text'])\n",
    "val_tokenize_data = val_data.map(preprocess_data, batched = True, remove_columns=['Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94671c2c",
   "metadata": {},
   "source": [
    "## 5. 학습을 진행하기 위한 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7f49a2",
   "metadata": {},
   "source": [
    "### 1) config 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9f85de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.config.decoder_start_token_id = tokenizer.bos_token_id                                             \n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# sensible parameters for beam search\n",
    "# set decoding params                               \n",
    "model.config.max_length = 70#128\n",
    "model.config.early_stopping = True\n",
    "model.config.no_repeat_ngram_size = 2\n",
    "model.config.length_penalty = 2.0\n",
    "model.config.num_beams = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c18633",
   "metadata": {},
   "source": [
    "### 2) rounge 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfd8b847",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = datasets.load_metric(\"rouge\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # all unnecessary tokens are removed\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "#     print(\"labels_ids\",labels_ids)\n",
    "#     print(\"labels_ids[labels_ids == -100]\",labels_ids[labels_ids == -100])\n",
    "#     print(\"tokenizer.pad_token_id\",tokenizer.pad_token_id)\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge1\"])[\"rouge1\"].mid\n",
    "    rouge_output2 = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
    "    rouge_outputL = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rougeL\"])[\"rougeL\"].mid\n",
    "    \n",
    "\n",
    "    return {\n",
    "        \"rouge1_precision\": round(rouge_output.precision, 4),\n",
    "        \"rouge1_recall\": round(rouge_output.recall, 4),\n",
    "        \"rouge1_fmeasure\": round(rouge_output.fmeasure, 4),\n",
    "        \n",
    "        \"rouge2_precision\": round(rouge_output2.precision, 4),\n",
    "        \"rouge2_recall\": round(rouge_output2.recall, 4),\n",
    "        \"rouge2_fmeasure\": round(rouge_output2.fmeasure, 4), \n",
    "        \n",
    "        \"rougeL_precision\": round(rouge_outputL.precision, 4),\n",
    "        \"rougeL_recall\": round(rouge_outputL.recall, 4),\n",
    "        \"rougeL_fmeasure\": round(rouge_outputL.fmeasure, 4),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62127d6a",
   "metadata": {},
   "source": [
    "### 3) arguments 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59b0d5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"MLM_pretrain_basev2_freezing\",\n",
    "    num_train_epochs=1,  # demo\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=16,  # demo\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=3e-05,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.1,\n",
    "    label_smoothing_factor=0.1,\n",
    "    predict_with_generate=True, # 생성기능을 사용하고 싶다고 지정한다.\n",
    "    logging_dir=\"logs2\",\n",
    "    logging_steps=500,\n",
    "    save_total_limit=3,\n",
    "    #evaluation_strategy = \"steps\",# step별로 2버 loss가 오르는거 아니면 계속 반복하는듯\n",
    "   # load_best_model_at_end = True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1a9700",
   "metadata": {},
   "source": [
    "### 4) data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e3e1cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674d60a2",
   "metadata": {},
   "source": [
    "### 5) train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45d129d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model, \n",
    "    training_args,\n",
    "    train_dataset=train_tokenize_data,\n",
    "    eval_dataset=val_tokenize_data,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    #callbacks = [EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1b47a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 279992\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 17500\n",
      "  Number of trainable parameters = 2304\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjx7789\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/aiffel/aiffel/Korean_Conversation_Summary/wandb/run-20221123_072911-2aplyz5u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jx7789/huggingface/runs/2aplyz5u\" target=\"_blank\">MLM_pretrain_basev2_freezing</a></strong> to <a href=\"https://wandb.ai/jx7789/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17500' max='17500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17500/17500 50:22, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>7.579400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>7.514900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>7.512100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>7.499600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>7.469900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>7.455800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>7.401900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>7.451600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>7.418500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>7.415200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>7.397900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>7.397200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>7.352000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>7.374200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>7.325200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>7.344600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>7.367300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>7.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>7.335900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>7.337300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>7.322500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>7.304400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>7.309100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>7.306000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>7.281500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>7.301800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>7.305100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>7.288600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>7.326400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>7.303100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>7.300300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>7.302200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>7.288200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>7.310700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>7.282700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-500\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-500/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-500/special_tokens_map.json\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-1000\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-1000/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-1500\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-1500/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-1500/special_tokens_map.json\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-2000\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-2000/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-2500\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-2500/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-2500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-3000\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-3000/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-3000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-1500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-3500\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-3500/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-3500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-4000\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-4000/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-4000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-2500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-4500\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-4500/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-4500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-3000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-5000\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-5000/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-5000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-3500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-5500\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-5500/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-5500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-4000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-6000\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-6000/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-6000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-4500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-6500\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-6500/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-6500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-5000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-7000\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-7000/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-7000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-5500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-7500\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-7500/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-7500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-6000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-8500\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-8500/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-8500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-7000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-9000\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-9000/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-9000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-7500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-9500\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-9500/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-9500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-8000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-10000\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-10000/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-10000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-8500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-10500\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-10500/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-10500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-10500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-10500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-9000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-11000\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-11000/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-11000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-11000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-9500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-11500\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-11500/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-11500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-11500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-11500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-10000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-12000\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-12000/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-12000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-10500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-12500\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-12500/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-12500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-12500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-12500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-11000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-13000\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-13000/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-13000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-13000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-13000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-11500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-13500\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-13500/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-13500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-13500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-13500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-12000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-14000\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-14000/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-14000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-14000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-12500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-14500\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-14500/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-14500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-14500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-14500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-13000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-15000\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-15000/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-13500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-15500\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-15500/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-15500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-15500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-15500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-14000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-16000\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-16000/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-16000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-16000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-14500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-16500\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-16500/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-16500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-16500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-16500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-15000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-17000\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-17000/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-17000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-17000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-17000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-15500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_pretrain_basev2_freezing/checkpoint-17500\n",
      "Configuration saved in MLM_pretrain_basev2_freezing/checkpoint-17500/config.json\n",
      "Model weights saved in MLM_pretrain_basev2_freezing/checkpoint-17500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_pretrain_basev2_freezing/checkpoint-17500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_pretrain_basev2_freezing/checkpoint-17500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_pretrain_basev2_freezing/checkpoint-16000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=17500, training_loss=7.366375948660714, metrics={'train_runtime': 3030.2069, 'train_samples_per_second': 92.4, 'train_steps_per_second': 5.775, 'total_flos': 1.16704034463744e+16, 'train_loss': 7.366375948660714, 'epoch': 1.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805d3c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='774' max='2188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 774/2188 15:24 < 28:10, 0.84 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fd9c2f",
   "metadata": {},
   "source": [
    "## 6. 학습 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a50dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(val_textfile_path, encoding=\"utf-8\") as f:\n",
    "            val_textlines = [line for line in f.read().splitlines() if (len(line) > 0 and not line.isspace())]\n",
    "        \n",
    "val_df = pd.DataFrame(zip(val_textlines), columns=['Text'])\n",
    "val_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12218f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(test_samples, model):\n",
    "    inputs = tokenizer(\n",
    "        test_samples[\"Text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_target,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    input_ids = inputs.input_ids.to(model.device)\n",
    "    \n",
    "    attention_mask = inputs.attention_mask.to(model.device)\n",
    "    outputs = model.generate(input_ids, num_beams=2,no_repeat_ngram_size=2, max_length=128,\n",
    "                            suppress_tokens= [234,23782,14338,240,199,198,161,116, 14338, 239], \n",
    "                             attention_mask=attention_mask, top_p=0.92)\n",
    "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return outputs, output_str\n",
    "\n",
    "\n",
    "model_before_tuning = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoints)# 여기에 기본 kobart가져오기?\n",
    "import random\n",
    "from random import randrange\n",
    "ck_num = len(val_data)\n",
    "test_samples = val_data.select(range(0, ck_num, 1000))# 0, len(test_data), 200\n",
    "\n",
    "summaries_before_tuning = generate_summary(test_samples, model_before_tuning)[1]\n",
    "summaries_after_tuning = generate_summary(test_samples, model)[1] # 여기에 체크포인트 가져오기 \n",
    "# 연구해봐야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffdb622",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(summaries_after_tuning)):\n",
    "    print('idx_{} '.format(i))\n",
    "    print(\"Summary before \\n\", summaries_before_tuning[i])\n",
    "    print()\n",
    "    print(\"Summary after \\n\", summaries_after_tuning[i])\n",
    "    print()\n",
    "    print(\"Target summary \\n\", test_samples[\"Summary\"][i])\n",
    "    print()\n",
    "    print('Text', test_samples[\"Text\"][i])\n",
    "    print('-'*100)\n",
    "    print()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62451964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a45b973",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
