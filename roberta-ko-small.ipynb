{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81457231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b08f6a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('~/aiffel/Aiffelthon_koBART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcbfc787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'=1.10.0'\t\t\t\t        modeling_outputs.py\r\n",
      " configuration_utils.py\t\t\t        __pycache__\r\n",
      " data\t\t\t\t\t        requirements.txt\r\n",
      "'EDA result.ipynb'\t\t\t        roberta-ko-small.ipynb\r\n",
      " fine_tune_bart_summarization_two_langs.ipynb   robertatest.ipynb\r\n",
      "'hubbingface finetuning seq2seq.ipynb'\t        seq2seq_trainer.py\r\n",
      " import_utils.py\t\t\t        seq2seq_training_args.py\r\n",
      "'채팅 요약기 미세 조정.ipynb'\t\t        Untitled1.ipynb\r\n",
      " kobART_modelling.ipynb\t\t\t        Untitled2.ipynb\r\n",
      " koBART_modelling.ipynb\t\t\t        Untitled.ipynb\r\n",
      " modeling_encoder_decoder.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6693c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.9/site-packages (from rouge_score) (0.12.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.9/site-packages (from rouge_score) (3.6.5)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from rouge_score) (1.21.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.9/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (4.62.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (2021.11.10)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (1.1.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (8.0.3)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24955 sha256=a2873342779dc3b411a55a87dc168f02bbc7f3fe9b6bc9220e20e65f4d9c8162\n",
      "  Stored in directory: /aiffel/.cache/pip/wheels/9b/3d/39/09558097d3119ca0a4d462df68f22c6f3c1b345ac63a09b86e\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: rouge-score\n",
      "Successfully installed rouge-score-0.1.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting datasets==1.0.2\n",
      "  Downloading datasets-1.0.2-py3-none-any.whl (1.8 MB)\n",
      "     |████████████████████████████████| 1.8 MB 5.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (2.26.0)\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (6.0.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (1.21.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (4.62.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (3.4.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (2.0.2)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (0.3.4)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (1.3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.0.2) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.0.2) (2.0.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.0.2) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.0.2) (2.10)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets==1.0.2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets==1.0.2) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->datasets==1.0.2) (1.16.0)\n",
      "Installing collected packages: datasets\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 1.14.0\n",
      "    Uninstalling datasets-1.14.0:\n",
      "      Successfully uninstalled datasets-1.14.0\n",
      "Successfully installed datasets-1.0.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score\n",
    "!pip install datasets==1.0.2\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f50d4199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.24.0\n",
      "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
      "     |████████████████████████████████| 5.5 MB 6.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (2021.11.10)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (1.21.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (3.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (4.62.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (6.0)\n",
      "Collecting huggingface-hub<1.0,>=0.10.0\n",
      "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
      "     |████████████████████████████████| 163 kB 84.9 MB/s            \n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "     |████████████████████████████████| 7.6 MB 64.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (2.26.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.24.0) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->transformers==4.24.0) (3.0.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.24.0) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.24.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.24.0) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.24.0) (2.0.8)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.10.3\n",
      "    Uninstalling tokenizers-0.10.3:\n",
      "      Successfully uninstalled tokenizers-0.10.3\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.0.19\n",
      "    Uninstalling huggingface-hub-0.0.19:\n",
      "      Successfully uninstalled huggingface-hub-0.0.19\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.11.3\n",
      "    Uninstalling transformers-4.11.3:\n",
      "      Successfully uninstalled transformers-4.11.3\n",
      "Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.24.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers==4.24.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d7dee0f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformer-utils\n",
      "  Downloading transformer_utils-0.1.1-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.9/site-packages (from transformer-utils) (1.9.1+cu111)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.9/site-packages (from transformer-utils) (0.11.2)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.9/site-packages (from transformer-utils) (4.24.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from transformer-utils) (4.62.3)\n",
      "Collecting colorcet\n",
      "  Downloading colorcet-3.0.1-py2.py3-none-any.whl (1.7 MB)\n",
      "     |████████████████████████████████| 1.7 MB 9.8 MB/s            \n",
      "\u001b[?25hCollecting pyct>=0.4.4\n",
      "  Downloading pyct-0.4.8-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.9/site-packages (from seaborn->transformer-utils) (1.21.4)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.9/site-packages (from seaborn->transformer-utils) (1.7.1)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /opt/conda/lib/python3.9/site-packages (from seaborn->transformer-utils) (3.4.3)\n",
      "Requirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.9/site-packages (from seaborn->transformer-utils) (1.3.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch->transformer-utils) (4.0.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (3.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (0.10.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (21.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (0.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (2021.11.10)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (2.26.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (8.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (3.0.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.23->seaborn->transformer-utils) (2021.3)\n",
      "Collecting param>=1.7.0\n",
      "  Downloading param-1.12.2-py2.py3-none-any.whl (86 kB)\n",
      "     |████████████████████████████████| 86 kB 10.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers->transformer-utils) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers->transformer-utils) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers->transformer-utils) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->transformers->transformer-utils) (2.0.8)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn->transformer-utils) (1.16.0)\n",
      "Installing collected packages: param, pyct, colorcet, transformer-utils\n",
      "Successfully installed colorcet-3.0.1 param-1.12.2 pyct-0.4.8 transformer-utils-0.1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformer-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "046c77dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging) (3.0.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install packaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d9e5e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "import datasets\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "#Tokenizer\n",
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "#Encoder-Decoder Model\n",
    "from transformers import EncoderDecoderModel\n",
    "\n",
    "#Training\n",
    "from seq2seq_trainer import Seq2SeqTrainer\n",
    "from transformers import TrainingArguments\n",
    "from seq2seq_training_args import Seq2SeqTrainingArguments\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e38522d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 지정\n",
    "#%cd ~/aiffel/aiffelthon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "206b3521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/huggingface/transformers/main/examples/legacy/seq2seq/seq2seq_trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d223f737",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://github.com/huggingface/transformers/blob/main/src/transformers/utils/import_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b8c25e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/huggingface/transformers/main/src/transformers/models/encoder_decoder/modeling_encoder_decoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0fa88af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/huggingface/transformers/main/src/transformers/configuration_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fa8b829",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73431 9150\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>지어내버린 대목부터는 흥분이 버썩 줄어지었다 ──. \"선생님! 또 기침이 나고 토...</td>\n",
       "      <td>자신을 배반한 제 계집과 세상이 엎드려 죄 사하기를 빌 때까지 죽지 아니하겠다는 H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이 송아지가 젖을 떼우고 집으로 끌고 오던 날은 첨지는 개선장군이 성안 에 들어올...</td>\n",
       "      <td>젖뗀 송아지를 집으로 끌고 오던 날 어깨춤을 추면서 소 들어간다고 고함을 지르는 첨...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>어떤 여름날 밤 손주딸에게 관한 불길한 꿈을 꾼 이 한머니는 이튿날 조반 후에 생...</td>\n",
       "      <td>손주딸의 관한 불길한 꿈을 꾼 한머니는 백여 리 떨어진 손주딸의 집에를 가보기로 하...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이러한 가운데서 왕후는 자기의 입장을 위태롭게 여기고 겸하여 장래 자기 의 몸으로...</td>\n",
       "      <td>자기는 태자의 위를 동경하거나 부러워한 적이 없으며 이 나라의 충성된 신자로서 공주...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“가겠소.” “언니가 나오시면 일러드 리겠으니 그때까지는 찾아오지 않으시는 것이 ...</td>\n",
       "      <td>자신의 신변을 염려하여 빠른 걸음으로 골목을 빠져나와 침착한 의식을 회복하면서 어수...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0   지어내버린 대목부터는 흥분이 버썩 줄어지었다 ──. \"선생님! 또 기침이 나고 토...   \n",
       "1   이 송아지가 젖을 떼우고 집으로 끌고 오던 날은 첨지는 개선장군이 성안 에 들어올...   \n",
       "2   어떤 여름날 밤 손주딸에게 관한 불길한 꿈을 꾼 이 한머니는 이튿날 조반 후에 생...   \n",
       "3   이러한 가운데서 왕후는 자기의 입장을 위태롭게 여기고 겸하여 장래 자기 의 몸으로...   \n",
       "4   “가겠소.” “언니가 나오시면 일러드 리겠으니 그때까지는 찾아오지 않으시는 것이 ...   \n",
       "\n",
       "                                             Summary  \n",
       "0  자신을 배반한 제 계집과 세상이 엎드려 죄 사하기를 빌 때까지 죽지 아니하겠다는 H...  \n",
       "1  젖뗀 송아지를 집으로 끌고 오던 날 어깨춤을 추면서 소 들어간다고 고함을 지르는 첨...  \n",
       "2  손주딸의 관한 불길한 꿈을 꾼 한머니는 백여 리 떨어진 손주딸의 집에를 가보기로 하...  \n",
       "3  자기는 태자의 위를 동경하거나 부러워한 적이 없으며 이 나라의 충성된 신자로서 공주...  \n",
       "4  자신의 신변을 염려하여 빠른 걸음으로 골목을 빠져나와 침착한 의식을 회복하면서 어수...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "train_df = pd.read_csv('data/train_20per.csv')\n",
    "train_df.drop(labels = 'Unnamed: 0', axis = 1, inplace = True)\n",
    "train_df.rename(columns = {\"input_documant\": \"Text\"}, inplace = True)\n",
    "train_df.rename(columns = {\"sentence_20%\": \"Summary\"}, inplace = True)\n",
    "\n",
    "val_df = pd.read_csv('data/val_20per.csv')\n",
    "val_df.drop(labels = 'Unnamed: 0', axis = 1, inplace = True)\n",
    "val_df.rename(columns = {\"input_documant\": \"Text\"}, inplace = True)\n",
    "val_df.rename(columns = {\"sentence_20%\": \"Summary\"}, inplace = True)\n",
    "print(len(train_df), len(val_df))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54146490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14687 3050\n"
     ]
    }
   ],
   "source": [
    "# 10번째 row만 추출\n",
    "train_df = train_df.iloc[range(0, 73431, 5)]\n",
    "val_df = val_df.iloc[range(0, 9150, 3)]\n",
    "print(len(train_df), len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14dcb294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>지어내버린 대목부터는 흥분이 버썩 줄어지었다 ──. \"선생님! 또 기침이 나고 토...</td>\n",
       "      <td>자신을 배반한 제 계집과 세상이 엎드려 죄 사하기를 빌 때까지 죽지 아니하겠다는 H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"그래라.\" 용선은 선뜻 허락하는 말을 준다. \"네? 소승의 소원을 이루어주십니까...</td>\n",
       "      <td>조신이 목욕하고 새 옷을 갈아입고 관음전으로 들어가는 것을 본 용선 법사는 문을 밖...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>“왜.” 맹서방은 수방의 눈치를 살피며 한 걸음 다가섰다. 그리고 주인 마누라에 ...</td>\n",
       "      <td>부뚜막에서 밥이 끓어날 때에야 어머니가 나왔고 수방이는 어머니가 무엇을 또 잘못했다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>피아노 궐(厥)은 가정의 단란(團欒)에 흠씬 심신(心身)을 잠그게 되었다. 보기만 ...</td>\n",
       "      <td>궐은 중등교육을 마쳤으며 생글생글 웃는 눈매와 날씬날씬한 허리를 가진 새 안해와의 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>“오누, 오누.” “양……” “이리 온.” 이리하여 커다란 손으로 까맹이를 움켜쥔...</td>\n",
       "      <td>춘심이는 생전에 순 서방의 기쁨을 곱 되게 하고 근심은 사라지게 하였으며 모든 것의...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text  \\\n",
       "0    지어내버린 대목부터는 흥분이 버썩 줄어지었다 ──. \"선생님! 또 기침이 나고 토...   \n",
       "5    \"그래라.\" 용선은 선뜻 허락하는 말을 준다. \"네? 소승의 소원을 이루어주십니까...   \n",
       "10   “왜.” 맹서방은 수방의 눈치를 살피며 한 걸음 다가섰다. 그리고 주인 마누라에 ...   \n",
       "15  피아노 궐(厥)은 가정의 단란(團欒)에 흠씬 심신(心身)을 잠그게 되었다. 보기만 ...   \n",
       "20   “오누, 오누.” “양……” “이리 온.” 이리하여 커다란 손으로 까맹이를 움켜쥔...   \n",
       "\n",
       "                                              Summary  \n",
       "0   자신을 배반한 제 계집과 세상이 엎드려 죄 사하기를 빌 때까지 죽지 아니하겠다는 H...  \n",
       "5   조신이 목욕하고 새 옷을 갈아입고 관음전으로 들어가는 것을 본 용선 법사는 문을 밖...  \n",
       "10  부뚜막에서 밥이 끓어날 때에야 어머니가 나왔고 수방이는 어머니가 무엇을 또 잘못했다...  \n",
       "15  궐은 중등교육을 마쳤으며 생글생글 웃는 눈매와 날씬날씬한 허리를 가진 새 안해와의 ...  \n",
       "20  춘심이는 생전에 순 서방의 기쁨을 곱 되게 하고 근심은 사라지게 하였으며 모든 것의...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb1db201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.str.lower() # 텍스트 소문자화\n",
    "    sentence = sentence.str.replace(pat= r'([\\n])', repl=r'', regex=True)\n",
    "    sentence = sentence.str.replace(pat= r'(['\"\"'_])', repl=r'', regex=True)\n",
    "    sentence = sentence.str.replace(pat= r'([?.!])', repl=r' \\1', regex=True) #  구두점 분리\n",
    "    sentence = sentence.str.replace(pat=r'[^ㄱ-ㅎㅏ-ㅣ가-힣0-9!.?]+', repl =\" \",regex=True) # 0-9ㄱ-ㅎㅏ-ㅣ가-힣a-z!.?가 아닌 모든 문자를 하나의 공백으로 바꿉니다\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "833a8479",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Text','Summary']\n",
    "\n",
    "for col in cols:\n",
    "    train_df[col] = preprocess_sentence(train_df[col])\n",
    "    val_df[col] = preprocess_sentence(val_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df421f5d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>지어내버린 대목부터는 흥분이 버썩 줄어지었다 . 선생님 ! 또 기침이 나고 토혈이...</td>\n",
       "      <td>자신을 배반한 제 계집과 세상이 엎드려 죄 사하기를 빌 때까지 죽지 아니하겠다는 의...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>그래라 . 용선은 선뜻 허락하는 말을 준다 . 네 ? 소승의 소원을 이루어주십니까...</td>\n",
       "      <td>조신이 목욕하고 새 옷을 갈아입고 관음전으로 들어가는 것을 본 용선 법사는 문을 밖...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>왜 . 맹서방은 수방의 눈치를 살피며 한 걸음 다가섰다 . 그리고 주인 마누라에 ...</td>\n",
       "      <td>부뚜막에서 밥이 끓어날 때에야 어머니가 나왔고 수방이는 어머니가 무엇을 또 잘못했다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>피아노 궐 은 가정의 단란 에 흠씬 심신 을 잠그게 되었다 . 보기만 하여도 지긋지...</td>\n",
       "      <td>궐은 중등교육을 마쳤으며 생글생글 웃는 눈매와 날씬날씬한 허리를 가진 새 안해와의 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>오누 오누 . 양 이리 온 . 이리하여 커다란 손으로 까맹이를 움켜쥔 다음에는 논...</td>\n",
       "      <td>춘심이는 생전에 순 서방의 기쁨을 곱 되게 하고 근심은 사라지게 하였으며 모든 것의...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text  \\\n",
       "0    지어내버린 대목부터는 흥분이 버썩 줄어지었다 . 선생님 ! 또 기침이 나고 토혈이...   \n",
       "5    그래라 . 용선은 선뜻 허락하는 말을 준다 . 네 ? 소승의 소원을 이루어주십니까...   \n",
       "10   왜 . 맹서방은 수방의 눈치를 살피며 한 걸음 다가섰다 . 그리고 주인 마누라에 ...   \n",
       "15  피아노 궐 은 가정의 단란 에 흠씬 심신 을 잠그게 되었다 . 보기만 하여도 지긋지...   \n",
       "20   오누 오누 . 양 이리 온 . 이리하여 커다란 손으로 까맹이를 움켜쥔 다음에는 논...   \n",
       "\n",
       "                                              Summary  \n",
       "0   자신을 배반한 제 계집과 세상이 엎드려 죄 사하기를 빌 때까지 죽지 아니하겠다는 의...  \n",
       "5   조신이 목욕하고 새 옷을 갈아입고 관음전으로 들어가는 것을 본 용선 법사는 문을 밖...  \n",
       "10  부뚜막에서 밥이 끓어날 때에야 어머니가 나왔고 수방이는 어머니가 무엇을 또 잘못했다...  \n",
       "15  궐은 중등교육을 마쳤으며 생글생글 웃는 눈매와 날씬날씬한 허리를 가진 새 안해와의 ...  \n",
       "20  춘심이는 생전에 순 서방의 기쁨을 곱 되게 하고 근심은 사라지게 하였으며 모든 것의...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efbc0912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>러시아 황실이 제공한 임시공관에서 오전 내내 쉬며 지냈다 . 오늘 아침 우리 임시...</td>\n",
       "      <td>러시아에서 제공한 임시공관에서 쉬면서 아침에 태극기를 발코니 위에 게양했는데 모스크...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그런 점에서 볼 때 박영민씨 경우는 이례적인 케이스로 꼽힌다 . 프로게이머 특성상...</td>\n",
       "      <td>박 씨는 기초 지식이 부족해 영어 문답을 통째로 외우다시피 하며 공무원 시험 준비를...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>지난 9월 30일 스위스 세계경제포럼 은 140개국을 상대로 한 금융시장 성숙도 조...</td>\n",
       "      <td>스위스 세계경제포럼은 140개국을 상대로 한 금융시장 성숙도 조사에서 한국이 우간다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>이처럼 자체 기금운용계획 변경범위를 축소한 것은 기금변경에 대한 국회의 심의대상을 ...</td>\n",
       "      <td>기획예산처는 기금운용계획 수립 당시에는 예측할 수 없었으나 시급하게 추진할 필요가 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>보이어 기장은 물체들의 실체를 파악하기 위해 더 가까이 가고 싶었지만 승객들을 위...</td>\n",
       "      <td>보이어 기장은 목적지에 착륙한 뒤 승객들에게 무언가 특별한 것을 보지 못했는지 물었...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text  \\\n",
       "0    러시아 황실이 제공한 임시공관에서 오전 내내 쉬며 지냈다 . 오늘 아침 우리 임시...   \n",
       "3    그런 점에서 볼 때 박영민씨 경우는 이례적인 케이스로 꼽힌다 . 프로게이머 특성상...   \n",
       "6   지난 9월 30일 스위스 세계경제포럼 은 140개국을 상대로 한 금융시장 성숙도 조...   \n",
       "9   이처럼 자체 기금운용계획 변경범위를 축소한 것은 기금변경에 대한 국회의 심의대상을 ...   \n",
       "12   보이어 기장은 물체들의 실체를 파악하기 위해 더 가까이 가고 싶었지만 승객들을 위...   \n",
       "\n",
       "                                              Summary  \n",
       "0   러시아에서 제공한 임시공관에서 쉬면서 아침에 태극기를 발코니 위에 게양했는데 모스크...  \n",
       "3   박 씨는 기초 지식이 부족해 영어 문답을 통째로 외우다시피 하며 공무원 시험 준비를...  \n",
       "6   스위스 세계경제포럼은 140개국을 상대로 한 금융시장 성숙도 조사에서 한국이 우간다...  \n",
       "9   기획예산처는 기금운용계획 수립 당시에는 예측할 수 없었으나 시급하게 추진할 필요가 ...  \n",
       "12  보이어 기장은 목적지에 착륙한 뒤 승객들에게 무언가 특별한 것을 보지 못했는지 물었...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c52a460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset_index 사용\n",
    "train_df.reset_index(inplace=True, drop=True)\n",
    "val_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fec03d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF > data Set으로 전환\n",
    "train_data = Dataset.from_pandas(train_df) \n",
    "val_len = len(val_df) // 2\n",
    "val_data = Dataset.from_pandas(val_df[:val_len])\n",
    "test_data=Dataset.from_pandas(val_df[val_len:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d5102b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(features: {'Text': Value(dtype='string', id=None), 'Summary': Value(dtype='string', id=None)}, num_rows: 14687)\n",
      "Dataset(features: {'Text': Value(dtype='string', id=None), 'Summary': Value(dtype='string', id=None)}, num_rows: 1525)\n",
      "Dataset(features: {'Text': Value(dtype='string', id=None), 'Summary': Value(dtype='string', id=None)}, num_rows: 1525)\n"
     ]
    }
   ],
   "source": [
    "print(train_data)\n",
    "print(val_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7ade3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input = 512\n",
    "max_target = 128\n",
    "batch_size = 3\n",
    "model_checkpoints = \"gogamza/kobart-base-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "644cd117",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8d55d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c0ce058fea44f1aa1b61f7646e8dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b1231ffed5a4f4fa234dd9ec544d82b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/682k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc7d94ad94c4689ad13e7fa43ebb1ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f09a5aed4449eca8694441fe0ae363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60991492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data_to_process):\n",
    "  #get all the dialogues\n",
    "  inputs = [dialogue for dialogue in data_to_process['Text']]\n",
    "  #tokenize the dialogues\n",
    "  model_inputs = tokenizer(inputs,  max_length=max_input, padding='max_length', truncation=True)\n",
    "  #tokenize the summaries\n",
    "  with tokenizer.as_target_tokenizer():\n",
    "    targets = tokenizer(data_to_process['Summary'], max_length=max_target, padding='max_length', truncation=True)\n",
    "    \n",
    "  #set labels\n",
    "  model_inputs['labels'] = targets['input_ids']\n",
    "  #return the tokenized data\n",
    "  #input_ids, attention_mask and labels\n",
    "  return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e3369cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3546: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d08b3defb4284b8291320abe92252c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e64b6fca1c043c6b3d510940e1e5e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ttokenize_data = train_data.map(preprocess_data, batched = True)\n",
    "vtokenize_data = val_data.map(preprocess_data, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21d8ac0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(features: {'Summary': Value(dtype='string', id=None), 'Text': Value(dtype='string', id=None), 'attention_mask': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'input_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}, num_rows: 14687)\n",
      "\n",
      "<class 'datasets.arrow_dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "print(ttokenize_data)\n",
    "print()\n",
    "print(type(ttokenize_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87842910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51907900cc9471eadb5785a2d638320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fea37b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b55e69dd3840248d3c55e115399903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.66k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rouge = datasets.load_metric(\"rouge\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # all unnecessary tokens are removed\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
    "\n",
    "    return {\n",
    "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
    "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
    "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95a1e284",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"results\",\n",
    "    num_train_epochs=1,  # demo\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=4,  # demo\n",
    "    per_device_eval_batch_size=4,\n",
    "    # learning_rate=3e-05,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.1,\n",
    "    label_smoothing_factor=0.1,\n",
    "    predict_with_generate=True,\n",
    "    logging_dir=\"logs\",\n",
    "    logging_steps=50,\n",
    "    save_total_limit=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79ffb042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6e613b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce8753c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model, \n",
    "    training_args,\n",
    "    train_dataset=ttokenize_data,\n",
    "    eval_dataset=vtokenize_data,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c99d1f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids, Text, Summary. If token_type_ids, Text, Summary are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 14687\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3672\n",
      "  Number of trainable parameters = 123859968\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3672' max='3672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3672/3672 21:21, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>14.515900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.984300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.753300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.306300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.977400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.882200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.829500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.834400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.804500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.801800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.784100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.785900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.784700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.765600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.768200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.776900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.749900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.751200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>1.736400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.762300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>1.743300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.746000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>1.726100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.744900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>1.721400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.734400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>1.737900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.733500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>1.725200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.727600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>1.738400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.738200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>1.728500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>1.736800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>1.736200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.715300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>1.706200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>1.725100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>1.722200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.719800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>1.705500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.729200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>1.705200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.697500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>1.705800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>1.720900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>1.709400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.710800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>1.700700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.694700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>1.697400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>1.718400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>1.703900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>1.701100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>1.706300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>1.703700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>1.716300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>1.710700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>1.704200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.708900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>1.705100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>1.696400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>1.707700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>1.685200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>1.698800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>1.687300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>1.691900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>1.704500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>1.683600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.706200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>1.698900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>1.695200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>1.689800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to results/checkpoint-500\n",
      "Configuration saved in results/checkpoint-500/config.json\n",
      "Model weights saved in results/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-500/special_tokens_map.json\n",
      "Saving model checkpoint to results/checkpoint-1000\n",
      "Configuration saved in results/checkpoint-1000/config.json\n",
      "Model weights saved in results/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to results/checkpoint-1500\n",
      "Configuration saved in results/checkpoint-1500/config.json\n",
      "Model weights saved in results/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-1500/special_tokens_map.json\n",
      "Saving model checkpoint to results/checkpoint-2000\n",
      "Configuration saved in results/checkpoint-2000/config.json\n",
      "Model weights saved in results/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-500] due to args.save_total_limit\n",
      "Saving model checkpoint to results/checkpoint-2500\n",
      "Configuration saved in results/checkpoint-2500/config.json\n",
      "Model weights saved in results/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-2500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to results/checkpoint-3000\n",
      "Configuration saved in results/checkpoint-3000/config.json\n",
      "Model weights saved in results/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-3000/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-1500] due to args.save_total_limit\n",
      "Saving model checkpoint to results/checkpoint-3500\n",
      "Configuration saved in results/checkpoint-3500/config.json\n",
      "Model weights saved in results/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-3500/special_tokens_map.json\n",
      "Deleting older checkpoint [results/checkpoint-2000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3672, training_loss=2.000308951001801, metrics={'train_runtime': 1281.8624, 'train_samples_per_second': 11.458, 'train_steps_per_second': 2.865, 'total_flos': 4477599681085440.0, 'train_loss': 2.000308951001801, 'epoch': 1.0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cabcb6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids, Text, Summary. If token_type_ids, Text, Summary are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1525\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='382' max='382' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [382/382 01:57]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.6716617345809937,\n",
       " 'eval_rouge2_precision': 0.0163,\n",
       " 'eval_rouge2_recall': 0.0137,\n",
       " 'eval_rouge2_fmeasure': 0.0144,\n",
       " 'eval_runtime': 118.1053,\n",
       " 'eval_samples_per_second': 12.912,\n",
       " 'eval_steps_per_second': 3.234,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d3eaad51",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Column (pred) not in table columns (['Text', 'Summary']).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_34/2115584853.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1064\u001b[0m         \u001b[0mCan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m \u001b[0mto\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m \u001b[0mstring\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterable\u001b[0m \u001b[0mof\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m         \"\"\"\n\u001b[0;32m-> 1066\u001b[0;31m         return self._getitem(\n\u001b[0m\u001b[1;32m   1067\u001b[0m             \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m             \u001b[0mformat_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_getitem\u001b[0;34m(self, key, format_type, format_columns, output_all_columns, format_kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Column ({key}) not in table columns ({self._data.column_names}).\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m             \u001b[0;31m# Check if we need to convert indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Column (pred) not in table columns (['Text', 'Summary'])."
     ]
    }
   ],
   "source": [
    "val_data['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22ad5658",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_max_length = 256  # demo\n",
    "decoder_max_length = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3af4374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(val_data.select(range(16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a157777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(features: {'Text': Value(dtype='string', id=None), 'Summary': Value(dtype='string', id=None)}, num_rows: 16)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_samples = val_data.select(range(16))\n",
    "test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bc15bf56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /aiffel/.cache/huggingface/hub/models--gogamza--kobart-base-v1/snapshots/d7e64abd841bc1fa5d2939d14161124c51f29e8b/config.json\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"gogamza/kobart-base-v1\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.1,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"kobart_version\": 1.0,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 1026,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"tokenizer_class\": \"PreTrainedTokenizerFast\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /aiffel/.cache/huggingface/hub/models--gogamza--kobart-base-v1/snapshots/d7e64abd841bc1fa5d2939d14161124c51f29e8b/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at gogamza/kobart-base-v1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "통과2\n",
      "통과2\n"
     ]
    }
   ],
   "source": [
    "def generate_summary(test_samples, model):\n",
    "    inputs = tokenizer(\n",
    "        test_samples[\"Text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=encoder_max_length,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    print('통과2')\n",
    "    input_ids = inputs.input_ids.to(model.device)\n",
    "    \n",
    "    attention_mask = inputs.attention_mask.to(model.device)\n",
    "    outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
    "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return outputs, output_str\n",
    "\n",
    "\n",
    "model_before_tuning = AutoModelForSeq2SeqLM.from_pretrained(\"gogamza/kobart-base-v1\")\n",
    "\n",
    "test_samples = val_data.select(range(16))\n",
    "\n",
    "summaries_before_tuning = generate_summary(test_samples, model_before_tuning)[1]\n",
    "summaries_after_tuning = generate_summary(test_samples, model_before_tuning)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2f05f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "60971666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Id  Summary after                                                                                                  Summary before\n",
      "----  -------------------------------------------------------------------------------------------------------------  -------------------------------------------------------------------------------------------------------------\n",
      "   0  - 아침 우리 임시공관의 발코니 위에 태극기를 게양하다. 성스러운                                                 - 아침 우리 임시공관의 발코니 위에 태극기를 게양하다. 성스러운\n",
      "   1  그런 점에서 볼 때 박영민씨 경우는 이례적인 케이스로 꼽힌다. 프로게                                             그런 점에서 볼 때 박영민씨 경우는 이례적인 케이스로 꼽힌다. 프로게\n",
      "   2  지난 지난 세계경제포럼 은 140개국을 상대로 한 금융시장 성숙도 조사에서 한국이 87                               지난 지난 세계경제포럼 은 140개국을 상대로 한 금융시장 성숙도 조사에서 한국이 87\n",
      "   3  이처럼 이처럼 기금운용계획 변경범위를 축소한 것은 기금변경에 대한 국회의 심의대                                이처럼 이처럼 기금운용계획 변경범위를 축소한 것은 기금변경에 대한 국회의 심의대\n",
      "   4  보이어 기장은 물체들의 실체를 파악하기 위해 더 가까이 가고 싶었지만 승객                                       보이어 기장은 물체들의 실체를 파악하기 위해 더 가까이 가고 싶었지만 승객\n",
      "   5  폐지 기금의 융자사업의 어떻게 이루어질지에 대한 구체적인 방안이 필요하며 폐지 기금의                           폐지 기금의 융자사업의 어떻게 이루어질지에 대한 구체적인 방안이 필요하며 폐지 기금의\n",
      "   6  한 자리에서 그  식 아바이 순대는 불티나게 팔린다. 그                                                           한 자리에서 그  식 아바이 순대는 불티나게 팔린다. 그\n",
      "   7  지금으로부터 전 이 나라 역사에는 참으로 희한 한 광경이 벌어지고 있었다. 158                                    지금으로부터 전 이 나라 역사에는 참으로 희한 한 광경이 벌어지고 있었다. 158\n",
      "   8  한한한한한한 남아프리카프리카프리카프리카프리카프리카프리카프리카프리카프리카 나                               한한한한한한 남아프리카프리카프리카프리카프리카프리카프리카프리카프리카프리카 나\n",
      "   9  하지만 하지만는는 아니다. 강정호는 이제 꿈의 무대 로 불리는 메이저리그에서 살아남기                            하지만 하지만는는 아니다. 강정호는 이제 꿈의 무대 로 불리는 메이저리그에서 살아남기\n",
      "  10  적당한 적당한 육류 섭취는 건강에 도움이 된다고 했으니 현명하게 육류를                                          적당한 적당한 육류 섭취는 건강에 도움이 된다고 했으니 현명하게 육류를\n",
      "  11  그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그                                                          그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그\n",
      "  12  그 그에   오의 대표작 데카메론 의 서두 를 이해할                                                               그 그에   오의 대표작 데카메론 의 서두 를 이해할\n",
      "  13  엉엉 내가 길러내듯 한 아무개 놈이 나를 배반하였단 말이야                                                       엉엉 내가 길러내듯 한 아무개 놈이 나를 배반하였단 말이야\n",
      "  14  생각해 생각해 생각해 생각해 생각해 생각해 생각해 생각해 생각해 생각해 보니 보니 보니 보니 보니 보니 보니 보니  생각해 생각해 생각해 생각해 생각해 생각해 생각해 생각해 생각해 생각해 보니 보니 보니 보니 보니 보니 보니 보니\n",
      "  15  다섯째 밭기반정비사업 등 종래 총액계상예산사업으로사업으로사업으로사업으로                                     다섯째 밭기반정비사업 등 종래 총액계상예산사업으로사업으로사업으로사업으로\n",
      "\n",
      "Target summaries:\n",
      "\n",
      "  Id  Target summary\n",
      "----  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "   0  러시아에서 제공한 임시공관에서 쉬면서 아침에 태극기를 발코니 위에 게양했는데 모스크바 시내에 우리 국기가 빛을 발한 것은 러시아 역사상 처음이다 .\n",
      "   1  박 씨는 기초 지식이 부족해 영어 문답을 통째로 외우다시피 하며 공무원 시험 준비를 했다 .\n",
      "   2  스위스 세계경제포럼은 140개국을 상대로 한 금융시장 성숙도 조사에서 한국이 우간다 보다 뒤처진다고 발표하자 한국은 설문조사 위주이기 때문에 설득력이 떨어진다며 불만을 토로했다 .\n",
      "   3  기획예산처는 기금운용계획 수립 당시에는 예측할 수 없었으나 시급하게 추진할 필요가 있는 사업에 대해 기금운용계획을 변경해서 추진할 수 있도록 해야 한다 .\n",
      "   4  보이어 기장은 목적지에 착륙한 뒤 승객들에게 무언가 특별한 것을 보지 못했는지 물었고 조종석에서 세 칸 뒤에 있었던 러셀 부부는 물체를 봤다고 했다 .\n",
      "   5  폐지 기금의 적립금 처리와 활용 문제를 논의할 필요가 있으며 문화산업기반기금 소관부처 변경에 따른 긴밀한 업무협조도 필요하다 .\n",
      "   6  광장시장은 추운 겨울날 찬 바람 맞아가며 차가운 회를 먹는 맛이 일품인데 회 원조집 주인은 20대 후반부터 횟집을 하고 있다 .\n",
      "   7  임진왜란이 일어나자 의병을 일으켜 왜군과 싸우다 순절한 중봉 조헌은 도끼를 지니고 상소를 올리는 지부상소라는 방식을 택했다 .\n",
      "   8  아프리카 각지의 하나님의 교회 신자들은 타이거버그 종합병원 마푸투 종합병원과 중앙병원을 찾아 응원키트 350상자를 전달했다 .\n",
      "   9  강 씨는 인터뷰에서 수치상의 목표를 세우는 것보다 출전하는 매 경기에 최선을 다하고 싶은 것이 목표라고 말했다 .\n",
      "  10  소고기 돼지고기 등 붉은 고기보다는 오리고기 닭고기 등 흰 고기가 지방질이 적어 더 좋으며 오리기름까지도 좋은 줄 아는 사람이 있는데 이는 잘못된 생각이다 .\n",
      "  11  단 한 줄의 글을 쓰지 못하는 나는 가끔 나를 겉돈다는 것을 알고 있으며 어쩌면 내게서 가장 먼 나를 만나려 타인을 산책하고 있는지도 모른다 .\n",
      "  12  보카치오의 대표작 데카메론은 열흘간 7명의 숙녀와 3명의 신사들이 하루 10개씩 풀어 놓은 100개의 이야기이며 근대소설의 원조로 불린다 .\n",
      "  13  나는 조선일보 사장 조 선생을 생각할 때 얼굴도 퍽 위엄이 있고 옷도 좋은 양복을 입고 금테 안경을 쓸 것으로 믿었는데 정작 사장 선생을 보고는 깜짝 놀랐다 .\n",
      "  14  생원은 포상금에 눈이 멀어 형수인 할미를 고발하며 인륜을 저버렸다 .\n",
      "  15  총액계상예산사업이 예산편성단계에서 계상될 수 있다면 현행 일반회계의 총액계상예산사업 계획도 예산편성단계에서부터 수립 및 심사될 수 있을 것이라고 본다 .\n",
      "\n",
      "Source documents:\n",
      "\n",
      "  Id  Document\n",
      "----  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "   0  러시아 황실이 제공한 임시공관에서 오전 내내 쉬며 지냈다 . 오늘 아침 우리 임시공관의 발코니 위에 태극기를 게양하다 . 성스러운 모스크바 시내에 우리나라 국기가 빛을 발한 것은 러시아 역사상 처음이다 . 오후 2시 민영환 공과 물고기 김득련 그리고 나는 니콜라이 황제 폐하와 황후 입성을 보기 위해 모스크바 대공작의 궁전에 갔다 . 행진은 두 줄로 늘어선 병정들의 행렬 한가운데를 지나갔다 . 그 광경은 내가 전에 본 어떤 의식과도 비교할 수 없이 대단한 것이었다 . 병정 관리 시동 말들과 마차들을 모두 금과 은으로 입혀 놓은 것 같았다 . 황제는 홀로 말 위에 똑바로 앉은 자세로 가장 소박한 차림을 하고 들어섰다 . 황태후는 온통 은빛 나는 의상을 걸치고 황금마차에 혼자 올라앉아 양편에서 만세소리가 진동하자 그들에게 내내 고개를 숙여 인사하며 지나갔다 . 행차는 정해진 장소까지 한 시간 넘게 진행되었다 . 특별사절들 가운데 중국사절들은 화려한 비단에 수를 놓은 옷을 걸쳤음에도 불구하고 누런 이를 드러내고 길게 땋아 늘인 머리를 짧게 잘라 볼썽사나운 모습을 하고 있었다 . 일본 사절단들은 유럽식 복장에 가장 세련되고 부러운 동방의 나라로 군림하려고 기를 쓰고 있는 듯했다 . 페르시아 사절단은 화려한 정장에 잘생긴 친구가 등장했다 . 하지만 그런 유의 친구도 그 친구의 왕이 최근에 살해되고 그의 정부는 영국파와 러시아파로 갈라진 것으로 알고 있다 . 비참한 처지에 있는 우리나라의 상황을 생각할 때 불쌍한 우리 측 대표들은 다른 행복한 국가 대표들로부터 경멸과 조롱의 대상이 될 수밖에 없겠다는 생각이 든다 .\n",
      "   1  그런 점에서 볼 때 박영민씨 경우는 이례적인 케이스로 꼽힌다 . 프로게이머 특성상 선수 생명이 짧은 만큼 20대 후반에 진로 고민 을 했을 테지만 당장 벌 수 있는 수입을 버리고 출구가 좁은 공무원 시험 준비 를 한다는 게 쉽지는 않았을 것이었다 . 프로게이머들이 20대 중반 넘어가면 생각이 많아져요 . 군대 갔다 오면 다시 선수 생활하기도 힘들고 해봤자 1 2년밖에 못 할 텐데 그때가 인생에서는 중요한 시기잖아요 . 게임 말고 할 줄 아는 게 없었지만 코치 감독은 티오 정원 도 잘 안 나던 때였어요 . 마침 아버지께서 공무원이셨고 저도 생각해보니까 경력이나 베이스가 없어도 할 수 있는 게 공시 더라고요 . 시험 성적만 보니까요 . 물론 제가 처음 공부한다고 하니까 합격할 거라고 믿는 지인들이 10명 중 1명도 안 됐어요 . 다들 저보고 1인 인터넷 방송하자 고 자기가 매니저를 해줄 테니까 너는 게임만 하면 된다 고 많이 제안해왔는데 모두 거절했어요 . 말을 잘하는 편도 아니고 방송으로 성공하기까지 준비하는 시간이 아까웠어요 . 그렇게 상경한 박씨는 스마트폰을 구식 폴더폰으로 바꾸고 지인들과 연락을 끊었다 . 공시의 당락을 좌우하는 영어의 경우 기초 지식이 부족해 문답을 통째로 외우다시피 했다 . 손과 팔에 문신 처럼 단어와 문장을 적고 아침밥 먹을 때부터 잠자리에 들기까지 달달 외웠다 . 1년 반 동안 노력해 첫 번째 시험을 봤지만 고배를 마셨고 이후 6개월은 군산으로 다시 내려가 집중했다 . 의자에 오래 앉아 연습하던 프로게이머 때 습관이 공부에도 도움이 됐다 . 두 번째 시험에서는 3관왕은 물론 성적도 높게 받아 합격했다 .\n",
      "   2  지난 9월 30일 스위스 세계경제포럼 은 140개국을 상대로 한 금융시장 성숙도 조사에서 한국이 87위로 우간다 81위 보다 뒤처진다고 발표했다 . 이번 설문조사에 한국에서는 100명이 응했는데 주로 외국계 기업의 최고경영자나 금융회사의 간부들이 대상이었다 . 이에 한국 금융위원회는 조사 방식이 설문조사 위주이기 때문에 설득력이 떨어진다 며 만족도 조사의 성격이 높지 국가 간 경쟁력 비교 잣대로 보기엔 무리가 있다 며 불만을 토로했다 . 그러던 차에 10월 10일 페루 리마 컨벤션센터에서 열린 세계은행 개발위원회에 참석한 최경환 부총리 겸 기획재정부 장관이 한국 금융계 인사들을 모아 놓고 만찬 건배사로 우간다를 ! 이기자 ! 하고 외쳤다 하여 뒷말들이 많았다 . 세계경제포럼의 이 같은 발표가 유독 이번만이 아니란다 . 이전부터도 한국의 순위가 그랬다고 한다 . 그럼에도 한국 금융인들은 그때마다 매번 무시해 왔다 . 왜 그렇게 나왔는지 깊이 성찰해 보지 않았으니 대책 또한 있을 리가 없겠다 . 아무렴 세계경제포럼이 심심풀이로 그런 조사를 했을까 ? 만족도 라 하든 성숙도 라 하든 그건 곧 신뢰이고 신뢰가 곧 금융업의 출발점이자 경쟁력이라는 기본조차 망각하고 있으니 우리가 그토록 오매불망하던 고부가가치 서비스 산업의 글로벌화는 요원한 일이겠다 . 한국 금융인들의 글로벌 비즈니스 소통 매너가 그만큼 부족하다는 방증이기도 하다 .\n",
      "   3  이처럼 자체 기금운용계획 변경범위를 축소한 것은 기금변경에 대한 국회의 심의대상을 확대하여 기금에 대한 재정통제가 커져 바람직하다고 하겠으나 기금에 대한 실질적인 통제를 강화하기 위해서는 지출항목비율보다 항목금액으로 국회심의 대상으로 하거나 항간의 통합 또는 분할을 통해 금액편차를 축소하는 방안을 강구해야 할 것이다 .한편 자체 기금운용계획 변경을 통하여 신규사업을 추진함으로써 국회의 심의권을 침해하는 사례가 있는데 감사원 감사결과에 따르면 기획예산처는 2003년부터 2005년까지 문화관광부가 관광진흥개발기금의 계획변경을 통하여 31개의 신규사업 사업비 계 295억 4 000만원을 추진할 수 있도록 협의해 준 것으로 나타났다 .이처럼 자체 기금운용계획 변경을 통하여 신규사업을 추진하는 것은 국회의 기금에 대한 통제를 사실상 유명무실하게 하는 것이므로 기획예산처는 이에 대한 관리를 강화해야 할 것이다 . 즉 기금운용계획 변경을 통한 신규사업의 추진은 기금운용계획 수립 당시에는 예측할 수 없었으나 시급하게 추진할 필요가 있는 사업에 한하여 극히 제한적으로 추진할 수 있도록 해야 할 것이다 .2004년도 예비비결산 심의 시 지적된 사항은 일반예비비의 선집행 및 신대통령의 승인을 얻은 후 국회에 제출하여야 한다 . 다만 주요항목지출금액이 다음 각 호의 어느 하나에 해당하는 경우에는 기금운용계획변경안을 국회에 제출하지 아니하고 대통령령이 정하는 바에 따라 변경할 수 있다 .\n",
      "   4  보이어 기장은 물체들의 실체를 파악하기 위해 더 가까이 가고 싶었지만 승객들을 위험에 빠뜨릴 수 있다는 생각에 목적지에 착륙하는 방안을 택했다고 했다 . 보이어가 이 물체들 근처에서 비행한 시간은 약 15분이었다 . 그동안 비행기의 기계장치나 라디오 통신장치는 정상 작동했다 . 보이어는 착륙한 뒤 승객들에게 무언가 특별한 것을 보지 못했냐 고 물었다고 한다 . 선입견을 줄 수 있었기 때문에 자신이 본 것은 설명하지 않았다 . 공항 체크인 카운터에 하고 싶은 말을 메모로 남겨달라고 했다 . 조종석에서 세 칸 뒤에 있었던 케이트와 존 러셀 부부가 실명 으로 이를 봤다고 했다 . 또 다른 승객 중 최소 4명이 이를 봤다고 했고 조종석 바로 뒤에 앉아 있던 남성은 보이어로부터 망원경을 빌려 직접 보기도 했다 . 한편 영국 항공청은 이 사건에 대한 설명을 즉각 내놓지 않았다 . 언론의 압박이 거세지자 영국 국방부가 한 주 뒤 성명을 발표했다 . 이 물체를 목격했을 때 비행기는 프랑스 영공에 있었기 때문에 영국 정부가 공식 발표할 사안이 아니라고 했다 . 1976년 9월 18일 오후 11시 . 이란의 테헤란 인근에서 저고도로 비행하고 있는 미확인 물체로 인해 주민들이 겁을 집어먹었다 . 별같이 보이기도 했는데 더 크고 밝았다 . 일부 사람들이 메흐레파드 공항 관제탑에 전화를 걸었다 . 후세인 피로우지가 당직을 서고 있었다 . 피로우지는 네 통의 전화를 받은 뒤 밖으로 나가 망원경을 들고 사람들이 말한 곳을 바라봤다 . 그 역시도 6000피트 상공에서 움직이고 있는 밝게 빛나는 물체를 볼 수 있었다 . 이 물체는 모양이 수시로 바뀌고 있는 것처럼 보였다 .\n",
      "   5  즉 민간화기금에 대한 재정통제가 어떻게 이루어질지에 대한 구체적인 방안이 필요하며 폐지 기금의 융자사업의 이차보전 전환에 대한 지침을 만들 필요가 있다 . 또한 문화산업기반기금은 소관부처 변경에 따른 긴밀한 업무협조가 필요하며 폐지 기금의 적립금의 처리와 활용문제도 추후 논의될 필요가 있다 . 기금의 정비방안에서 폐지가 유보되었던 근로자복지진흥기금 과학기술진흥기금 축산발전기금은 기금 존치평가에서 지적되었던 사항들이 2006년도 기금운용계획안에서 반영된 사례가 거의 없었는데 이 기금들은 차기 존치평가 시에도 존폐 문제가 제기될 것이므로 기금 정비방안 원칙에 따른 예산과 기금의 사업편성에 대한 검토가 필요하다 . 이번 정비방안에서는 직접 다루어지지 않았지만 향후 기금정비방안을 마련함에 있어 검토되어야 할 과제를 정리하면 다음과 같다 . 신용보증기금과 기술신용보증기금은 통폐합 문제가 유보되었지만 신용보증기금의 통폐합의 찬반양론을 객관적으로 분석평가하면서 논의를 지속할 필요가 있으며 향후 통폐합 논의 시 다시 판단해야 할 것이다 .\n",
      "   6  할머니집 의 함경도식 아바이 순대는 불티나게 팔린다 . 그 자리에서 먹는 사람 포장해 가는 사람들로 정신이 없다 . 할머니는 8년 전 여름에 돌아가시고 17년 전부터 같이 해 온 외며느님이 대를 이어 장사하고 있다 . 며느님은 명문여대 출신이고 할머니 아드님도 명문대 출신이라 결혼할 때 시장 안이 떠들썩했다고 주위에서 귀띔해 준다 . 단골이 무려 1000명 이라고 아주머니는 단언한다 . 머릿고기가 냄새도 안 나고 맛도 깊이가 있다 . 돼지 얼굴 부위 중 쫄깃한 뺨과 오도독거리는 귀가 특히 맛있다 . 홀로 막걸리잔을 마주하고 앉은 손님은 25년째 단골 . 대학생 때 술과 고기를 먹고 돈이 없어 도망갔다가 후일 돈 벌어 외상값도 갚고 단골이 됐다고 털어놓는다 . 광장시장 한가운데엔 우리 엄마가 좋아하시던 죽집이 아직도 그대로 있고 즉석에서 만드는 이북 할머니 녹두빈대떡집 도 있었다 . 횟집도 서너 군데 있다 . 때 많이 없어졌다는데 지금은 회 원조집 이모횟집 강원횟집 등이 중앙을 차지하고 있다 . 한여름에도 좋지만 추운 겨울날 차가운 바람 맞아 가며 살얼음 끼어 있는 차가운 회를 먹는 맛이 일품이다 . 충남 예산이 고향인 회 원조집 주인 아주머니는 20대 후반부터 42년째 이곳에서 횟집을 하고 있다 . 선임하사 란 별명답게 성격도 시원시원하고 수완도 보통이 아니다 . 시장 한가운데 높이 자리 잡고 있는 좌판에 올라서서 입구에서부터 들어오는 손님들을 살피고 있으니 혹여 다른 안주가 먹고 싶더라도 뻔히 얼굴을 알고 있는 주인아줌마의 눈길을 피하기가 쉽지 않다고 회 원조집의 손님들은 너스레를 떤다 . 1인분에 1만원짜리 모듬회에는 배에서 급랭해서 1년 동안 숙성해 내왔다 는 아주머니식 자랑이 이어지며 문어며 참치며 고등어며 붕장어들이 소복이 쌓여 나온다 . 얼음상자에 놓인 생선들의 잇몸이 시려 보인다 .\n",
      "   7  지금으로부터 만 422년 전 이 나라 역사에는 참으로 희한 한 광경이 벌어지고 있었다 . 1589년 선조 22년 음력 4월에 초로 의 선비가 홀로 대궐문 앞에서 상소 를 올린 후 임금의 비답 을 기다리고 있었다 . 상소를 올리고 답변을 기다리는 것이야 그리 이상한 일은 아니다 . 하지만 엎드린 상소자의 옆에는 시퍼렇게 날이 선 도끼가 놓여 있었다 . 자신의 상소를 받아들이지 않겠다면 자신의 목을 이 도끼로 치라는 강력한 압박을 한 것이다 . 그 선비는 바로 임진왜란 이 일어나자 의병 을 일으켜 왜군 과 싸우다가 순절 한 중봉 조헌 1544 1592년 이었다 . 자기 목숨을 담보로 내놓은 상소문의 내용을 살펴보기에 앞서 조헌은 왜 도끼를 지니고 상소를 올리는 일명 지부상소 라는 방식을 택했는지를 한번 생각해 보자 . 조헌은 누구인가 ? 조헌은 본관은 백천 자는 여식 호는 중봉 도원 후율 등으로 경기도 김포에서 출생했다 . 율곡 과 토정 의 문인이었다 . 1565년 성균관에 입학하였으며 1567년 식년문과 에 병과 로 급제하였다 . 1568년 선조 1년 처음으로 관직에 올라 정주목 파주목 홍주목 등의 교수 조선 시대에 지방 유생의 교육을 맡아 보던 종6품 벼슬 를 역임하면서 사풍 을 바로잡았다 . 1572년부터 교서관 의 정자 조선 시대 홍문관 승문원 교서관에 속한 정9품 벼슬 저작 조선 시대 교서관 승문원 홍문관의 정8품 벼슬 박사 등을 지내면서 궁중의 불사봉향 에 반대하는 소 를 올려 국왕 선조 를 진노하게 하였다 .\n",
      "   8  아프리카 회원들도 남아프리카공화국 케이프타운 타이거버그 종합병원 마푸투 종합병원과 중앙병원을 찾아 손편지와 간식으로 꾸린 응원키트 350상자를 전달했다 . 가장 힘든 시기 우리와 함께해준 희생과 노력을 잊지 않겠다 희망을 준 의료진에 감사를 전한다 의료진의 희생으로 누군가는 가족 동료 친구와 함께할 수 있었다 등의 손편지에는 고마움과 응원이 여실히 적혀 있었다 .타이거버그 종합병원 코로나19 의료진 관리지원 책임자인 로시니 미스트리 박사는 주춤했던 코로나19 확진자 수가 다시 증가하면서 의료진이 힘을 내야 하는 상황이었는데 적절한 시기에 응원을 보내줬다 고 말했다 . 이 병원은 의 관심과 지원에 감동을 받았다며 감사편지를 보내오기도 했다 .이뿐만 아니라 아프리카 각지의 하나님의 교회 신자들은 환경정화운동도 활발히 전개해왔다 . 지난해 코로나19가 촉발한 개인위생과 방역 비대면 서비스 증가로 인해 일회용품 사용이 급증함에 따라 환경보호에 대한 관심이 높아졌다 .이에 신자들은 남아프리카공화국 케이프타운 요하네스버그 블룸폰테인 츠와네 더반 포트엘리자베스와 짐바브웨 하라레 카메룬 두알라 잠비아 루사카 르완다 키갈리 앙골라 루안다 토고 로메 등 각국 도시의 중심지 대학교 광장 경기장 강변 해변 등지에서 정화운동과 플라스틱 줄이기 캠페인을 펼치며 지역을 깨끗하게 가꾸고 시민들의 환경보호 경각심을 고취했다 .\n",
      "   9  강정호의 피츠버그 입단이 메이저리그 풀타임 선수를 보장하는 것은 아니다 . 강정호는 이제 꿈의 무대 로 불리는 메이저리그에서 살아남기 위해 무한경쟁을 펼쳐야 한다 . 하지만 분위기는 좋다 . 그를 향한 구단 내 평가도 호의적이다 . 피츠버그 단장도 강정호는 메이저리그 선수 라고 공언했다 . 또한 강정호는 피츠버그와 입단계약을 체결한 뒤 곧바로 피츠버그 40인 로스터 에 자신의 이름을 올렸다 . 메이저리그 구단은 팀당 총 40명과 메이저리그 계약을 맺는다 . 물론 시즌이 시작되면 경기에 출전할 수 있는 선수는 25명뿐이다 . 25인 로스터에 포함되지 못한 15명의 선수는 마이너리그에서 시즌을 시작해 메이저리그 콜업 을 기다리게 된다 . 때문에 강정호가 피츠버그에 입단한 뒤 곧바로 40인 로스터에 포함된 것은 스프링캠프 동안 자신의 실력만 입증한다면 올 시즌 출발을 메이저리그에서 할 수 있다는 뜻이다 . 피츠버그와 입단계약을 끝낸 강정호는 곧장 전 소속팀 넥센의 스프링캠프가 열리고 있는 미국 애리조나주 서프라이즈로 이동해 개인훈련에 돌입했다 . 강정호는 기자를 포함한 한국 취재진과의 합동인터뷰에서 먼저 메이저리그에 진출할 수 있도록 기회를 준 넥센구단에 진심으로 감사한다 는 말로 운을 뗀 뒤 수치상의 목표를 세우는 것보다 올 시즌 메이저리그에 출전하는 매 경기에 최선을 다하고 싶은 것이 선수의 임무이자 목표 라고 말했다 .\n",
      "  10  적당한 육류 섭취는 건강에 도움이 된다고 했으니 현명하게 육류를 섭취하는 법을 알아보자 . 붉은 고기보다는 흰 고기를 먹자 . 소고기 돼지고기 등 붉은 고기보다는 닭고기 오리고기 칠면조 등 흰 고기가 지방질이 적어 더 좋다 . 오리고기가 좋다고 하니까 어떤 분들은 오리기름까지도 좋은 줄 알고 있는데 이는 잘못된 생각이다 . 오리기름은 소고기나 돼지고기에 비해 불포화지방산 함량이 조금 더 높아 덜 해로울 뿐이다 . 이는 보신탕 즉 개고기에도 그대로 적용되는 얘기다 . 부위 선택이 중요하다 . 같은 고기라도 갈비 꽃등심 삼겹살처럼 지방이 많은 부위를 피하고 맛은 없지만 퍽퍽한 살코기를 먹으면 포화지방산의 피해를 최소화하면서 좋은 아미노산을 섭취할 수 있다 . 닭고기와 오리고기는 껍질에 지방이 많으므로 껍질을 없애고 먹으면 안전하고 가슴살은 지방이 전혀 없어 노화 방지에는 가장 좋은 부위이다 . 조리 방법도 중요한데 튀기거나 볶는 것보다는 삶거나 구워먹는 것이 지방 섭취를 줄일 수 있다 . 우리나라의 수육은 오키나와의 돼지고기 요리만큼 좋은 조리법이다 . 물론 이때도 기름을 제거하고 먹는 것이 좋다 . 삶으면 지방이 줄어들기는 해도 완전히 없어지는 것은 아니기 때문이다 . 채소와 과일을 많이 먹는다 . 고기를 먹을 때는 채소나 과일을 같이 먹는 것이 매우 중요하다 . 육류에 들어있는 효소는 조리 시 쉽게 파괴되는데 채소와 과일에 있는 효소를 이용 소화를 돕도록 하는 것이다 .\n",
      "  11  그 사이 나에게 많은 비유가 지났고 나는 단 한 줄의 글도 쓰지 못했다 . 나는 가끔 나를 겉돈다는 걸 안다 . 어쩌면 나는 내게서 가장 먼 나를 만나려 타인 을 산책하고 있는지도 모른다 . 나는 내가 무슨 일을 할 때마다 나라고 인정해야 하는 절박함 앞에 서성인다 . 나 라는 실체에 너무 많은 세월을 걸었으므로 이 도박은 진심만이 패를 쥐고 있는 형국 . 순간순간 내가 새로이 내어지는 일상 . 낮에 그토록 집착했던 몸이 꿈 속에서는 한없이 사소해진다 . 이곳에서 저곳으로 정처없이 떠도는 것은 분노나 욕심이 서린 일들뿐 . 마음은 가볍게 떠 있으나 그 마음을 띄우기 위해 눈물겹게 버티는 그 어떤 비중이 있다는 사실 . 은유가 직유를 살해하고 자살하는 것이 시 라면 나는 내 안에 일어나는 모든 일의 유서 . 그리고 꿈을 잠그고 아직도 돌아오지 않는 생의 내력 . 이제 그 첫 줄이 내 목을 감아 그들을 구한다 라고 하자 . 몸이 생각을 앓고 나면 다시 생각이 몸을 추슬러 한 사람이 된다 . 나도 모르게 어딘가에 부딪힌 멍을 샤워하다 발견할 때 차가운 물이 눈동자에 닿기 전 순식간에 감는 눈의 반응에 몸이 나보다 더 자신을 사랑한다는 걸 느낀다 . 화초 잎을 가위로 자른 다음 다시 가위를 화초에 가까이 대면 화초도 운다 . 잎맥 사이로 급속하게 전기저항이 일면서 안으로 부르르 떠는 것이다 . 식물에도 감정이 있으니 내 몸에도 나 아닌 마음이 있는 걸까 . 내 몸에 들어가 갑옷을 입듯 깨는 아침 . 내 몸이 가만히 부르르 떤다 .\n",
      "  12  그 모습을 보지 않았다면 보카치오의 대표작 데카메론 의 서두 를 이해할 수 없었을 것이라는 생각이 들었다 . 데카메론은 그리스어로 데카 는 열 10 메론 은 이야기라는 뜻이다 . 즉 열흘간 7명의 숙녀와 3명의 신사들이 하루 10개씩 풀어 놓은 100개의 이야기가 데카메론 인 것이다 . 왜 데카메론 이 근대소설의 원조 로 불리는 것일까 . 유럽은 알렉산더 대왕이 이룩한 다민족 다문화를 존중하는 헬레니즘 문화 오늘날의 세계화 가 야만족에 의해 짓밟힌 뒤 1000년가량 중세 시대를 겪었다 . 중세를 암흑기라 부르는 이유가 있다 . 모든 중심이 인간 아닌 신 이었다 . 중세 인간은 그저 신이 시키는 대로 하는 자주성을 상실한 존재였다 . 한형곤 외국어대 교수가 중세와 근대의 차이를 잘 설명해 준다 . 먼저 단테의 소네트 를 본다 . 소네트란 소곡 14행시 로 번역되는데 13세기 이탈리아의 민요에서 파생됐다 . 이것을 완성시킨 이가 르네상스의 삼총사 단테와 페트라르카다 . 이 가운데 백미 가 페트라르카의 칸초니에레 다 . 페트라르카 이후 셰익스피어가 영국형 소네트를 완성했고 훗날 프랑스의 보들레르에게까지 전통이 이어졌다 . 단테의 소네트 내 여인 이다 . 여기 등장하는 내 여인 은 단테가 일평생 사랑했던 베아트리체다 . 그런데 이 소네트에서 그녀는 평범한 인간이 아니라 고귀한 존재요 천사 같은 인물로 그려졌다 . 단테는 비록 중세의 문을 닫고 르네상스의 문을 열었지만 여전히 중세라는 굴레에 묶여 인간적인 사랑이 아닌 신적 인 사랑을 노래하고 있었던 것이다 .\n",
      "  13  엉엉 내가 길러내듯 한 아무개 놈이 나를 배반하였단 말이야 . 흐 흐흐 그놈이 하시는 겁니다 . 그때 나는 혹시 다른 방 손님이 이 소리를 듣고 그분이 송 선생인 줄 알든지 하면 어쩌나 하고 속으로 어찌나 송구하였는지 모릅니다 . 아마 선생은 평소에 가장 신뢰하던 어떤 분이 선생을 배반한 것이 뼈에 사무쳐서 원한이 되었던 모양이지요 . 그러기에 약주 잡수신 후 그 울분이 터져 나오셔서 주위와 환경을 모두 잊으시고 서러워하심인 줄 알았습니다 . 조선일보 사장 조만식 선생 ! 나는 이번 새로 속간되는 혜택에 처음으로 뽑혀 들어간 풋내기 급사인데 처음에 선생님을 생각할 때에는 얼굴도 퍽 위엄이 있고 또 옷도 좋은 양복을 입으시고 또 금테 안경을 쓰시고 금 시곗줄을 늘이시고 번쩍번쩍하는 칠피 구두를 신으시고 또 상아로 만든 단장을 들고 다니시리라고 믿었습니다 . 그런데 입사하던 날 정작 사장 선생님을 뵙고는 깜짝 놀랐습니다 . 사장실에를 들어가 보니까 웬 헙수룩한 어른 한 분이 앉아 계신데 암만 보아도 시골서 갓 올라오신 선비 같았습니다 . 그래서 처음에는 아마 사장 선생님을 찾아 뵈러 온 손님인 게다 생각하고 머뭇머뭇하고 있으려니까 왜 무슨 일이 있는가 ? 하고 물으시는 고로 네 네 저 저 사장 선생님을 뵈려고요 . 하고 우물쭈물 대답하였습니다 . 그럼 얼른 말을 하지 왜 그리 섰어 . 그제야 나는 이 어른이 사장 선생님인 줄 알고 인사를 하였습니다 .\n",
      "  14  이렇게 따지고 보니 임금의 명령대로 한 시동생 생원만 이상하게 되어 버렸다 . 잘 생각해 보면 사실 그는 왕의 명령대로 행동했다 . 몰래 술을 빚는 자를 적발하라고 해서 그렇게 했고 법이 정한 대로 포상금을 준다기에 그걸 받으려고 기다렸을 뿐이다 . 심지어 그는 가까운 혈육이지만 불법을 은닉하지 않고 그대로 드러내는 떳떳한 자세까지 있었다 . 그러니 마냥 생원을 매도할 건 아니다 . 하지만 이 시동생 생원은 옳지 않다 . 고얀 놈이다 . 진정이 아니었기 때문이다 . 겉으로 드러난 것과 번지르르한 명분은 모두 옳지만 그 내면은 야비하기 그지없다 . 생원은 왕의 명령과 법률이라는 외형을 빌미 삼아 그 뒤에 숨어서 더러운 짓을 했다 . 이 작자가 형수인 할미를 고발한 이유는 간단했다 . 국법을 지키자는 명분을 내세웠지만 법 때문이 아니라 포상금 때문이었다 . 벌금의 10분의 2를 받을 수 있는 절호의 기회를 놓치기 싫었던 거였다 . 이자가 얼마나 더러운 작자인지는 제가 받을 포상금이란 것이 결국은 가난에 찌든 형과 형수가 낼 벌금에서 받게 될 거란 점을 생각하면 분명해진다 . 포상금에 눈이 멀었다는 것보다 더 문제는 인륜 을 저버렸다는 점이다 . 그의 고발로 밀주가 적발되면 즉 그 술이 없어지면 제 친형이 죽을 수도 있었다 . 늙은 형이 제대로 소화도 시키지 못할 정도로 아프고 쇠약해 술을 조금씩 먹으며 곡기를 넘기는 상황이었다 . 만약 단속이 돼 술이 없어지면 형이 죽을 수도 있는 상황이었다 . 그런데도 이자는 고발한 것이다 . 만약 다모가 중간에 끼어들지 않았다면 아마도 형과 형수는 벌금을 내느라 더 가난해졌을 테고 그 겨울을 넘기지 못하고 굶어 죽었을지도 모른다 .\n",
      "  15  다섯째 밭기반정비사업 등 종래 총액계상예산사업으로 추진되었던 사업들이 균특회계로 이관된 경우가 많다 이런 경우는 올해 예산편성단계에서 사업계획수립에 적지않은 애로를 겪었을 것으로 생각된다 . 향후 사업계획이 좀더 심도있게 검토되어야 할 것으로 생각되는 한편 이렇듯 총액계상예산사업이 예산편성단계에서 계상될 수 있다면 현행 일반회계의 총액계상예산사업에 대해서도 예산편성단계에서부터 계획이 수립되고 세부내역이 심사될 수 있음을 의미한다고 본다 .여섯째 지자체 자율편성예산과 관련한 것으로 공공의 이익을 위해 꼭 필요한 예산이 축소되고 지방자치단체장의 이해관계에 따른 선심성 또는 이벤트성 사업이 증가할 가능성이 있다는 것이다 . 이번의 경우 지역주민의 안전 및 재해예방 분야의 예산이 축소 요구되어 기획예산처에서 증액조정하였으나 여전히 2004년 예산에 비해서도 부족한 실정이다 . 향후 필요 부문에 대해서는 자율편성 영역에서 제외하든지 지출한도 부여시 세부 지출한도를 부여하는 등의 방안을 강구할 필요가 있는 것으로 생각된다 . 일곱째 소관부처의 보조사업과 관련한 역할문제이다 균특회계가 도입되면서 보조사업의 계획수립과 예산 편성 사업의 집행과 성과 평가 등 모든 영역에 있어 많은 부분이 지방자율이나 국가균형발전위 또는 기획예산처로 이관되고 소관부처의 역할은 대폭 축소되었다 .\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    tabulate(\n",
    "        zip(\n",
    "            range(len(summaries_after_tuning)),\n",
    "            summaries_after_tuning,\n",
    "            summaries_before_tuning,\n",
    "        ),\n",
    "        headers=[\"Id\", \"Summary after\", \"Summary before\"],\n",
    "    )\n",
    ")\n",
    "print(\"\\nTarget summaries:\\n\")\n",
    "print(\n",
    "    tabulate(list(enumerate(test_samples[\"Summary\"])), headers=[\"Id\", \"Target summary\"])\n",
    ")\n",
    "print(\"\\nSource documents:\\n\")\n",
    "print(tabulate(list(enumerate(test_samples[\"Text\"])), headers=[\"Id\", \"Document\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8681b5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.json from cache at /aiffel/.cache/huggingface/hub/models--gogamza--kobart-base-v1/snapshots/d7e64abd841bc1fa5d2939d14161124c51f29e8b/vocab.json\n",
      "loading file merges.txt from cache at /aiffel/.cache/huggingface/hub/models--gogamza--kobart-base-v1/snapshots/d7e64abd841bc1fa5d2939d14161124c51f29e8b/merges.txt\n",
      "loading file tokenizer.json from cache at /aiffel/.cache/huggingface/hub/models--gogamza--kobart-base-v1/snapshots/d7e64abd841bc1fa5d2939d14161124c51f29e8b/tokenizer.json\n",
      "loading file added_tokens.json from cache at /aiffel/.cache/huggingface/hub/models--gogamza--kobart-base-v1/snapshots/d7e64abd841bc1fa5d2939d14161124c51f29e8b/added_tokens.json\n",
      "loading file special_tokens_map.json from cache at /aiffel/.cache/huggingface/hub/models--gogamza--kobart-base-v1/snapshots/d7e64abd841bc1fa5d2939d14161124c51f29e8b/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at None\n",
      "loading configuration file config.json from cache at /aiffel/.cache/huggingface/hub/models--gogamza--kobart-base-v1/snapshots/d7e64abd841bc1fa5d2939d14161124c51f29e8b/config.json\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"gogamza/kobart-base-v1\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.1,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"kobart_version\": 1.0,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 1026,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"tokenizer_class\": \"PreTrainedTokenizerFast\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'PreTrainedTokenizerFast'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't load the configuration of 'result/checkpoint-3500/'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'result/checkpoint-3500/' is the correct path to a directory containing a config.json file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    613\u001b[0m                 \u001b[0;31m# Load from local folder or from cache or download from model Hub and cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    615\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    410\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, use_auth_token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     storage_folder = os.path.join(\n\u001b[0;32m-> 1022\u001b[0;31m         \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_folder_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     )\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrepo_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0;34m\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'result/checkpoint-3500/'. Use `repo_type` argument if needed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1637/3920638260.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRobertaTokenizerFast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gogamza/kobart-base-v1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoderDecoderModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'result/checkpoint-3500/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_fast_init\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1964\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1965\u001b[0m             \u001b[0mconfig_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1966\u001b[0;31m             config, model_kwargs = cls.config_class.from_pretrained(\n\u001b[0m\u001b[1;32m   1967\u001b[0m                 \u001b[0mconfig_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m                 \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0munused_kwargs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"foo\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         ```\"\"\"\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             logger.warning(\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_commit_hash\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0moriginal_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m                 \u001b[0;31m# For any other exception, we throw a generic error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m                 raise EnvironmentError(\n\u001b[0m\u001b[1;32m    636\u001b[0m                     \u001b[0;34mf\"Can't load the configuration of '{pretrained_model_name_or_path}'. If you were trying to load it\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m                     \u001b[0;34m\" from 'https://huggingface.co/models', make sure you don't have a local directory with the same\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load the configuration of 'result/checkpoint-3500/'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'result/checkpoint-3500/' is the correct path to a directory containing a config.json file"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"gogamza/kobart-base-v1\")\n",
    "model = EncoderDecoderModel.from_pretrained('result/checkpoint-3500/')\n",
    "model.to(\"cuda\")\n",
    "batch_size = 32\n",
    "\n",
    "# map data correctly\n",
    "def generate_summary(batch):\n",
    "    # Tokenizer will automatically set [BOS] <text> [EOS]\n",
    "    inputs = tokenizer(batch[\"Text\"], padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids.to(\"cuda\")\n",
    "    attention_mask = inputs.attention_mask.to(\"cuda\")\n",
    "    outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
    "    # all special tokens including will be removed\n",
    "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    batch[\"pred\"] = output_str\n",
    "\n",
    "    return batch\n",
    "results = val_data.map(generate_summary, batched=True, batch_size=batch_size, remove_columns=[\"Text\"])\n",
    "pred_str = results[\"pred\"]\n",
    "label_str = results[\"Summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee0e9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in range(500,800,10):\n",
    "    print('predicted sentence : ',pred_str[num])\n",
    "    print('real sentence : ', label_str[num])\n",
    "    print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57358be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56232db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff37519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb6887d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad10c03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "032003c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]\n",
      "[SEP]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"klue/roberta-base\")\n",
    "\n",
    "tokenizer.bos_token = tokenizer.cls_token\n",
    "print(tokenizer.bos_token)\n",
    "tokenizer.eos_token = tokenizer.sep_token\n",
    "print(tokenizer.eos_token)\n",
    "#parameter setting\n",
    "batch_size=32  #\n",
    "encoder_max_length=256\n",
    "decoder_max_length=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b268dbdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4327e30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913d3a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2c001f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0c23c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_to_model_inputs(batch):\n",
    "    # tokenize the inputs and labels\n",
    "    inputs = tokenizer(batch[\"Text\"], padding=\"max_length\", truncation=True, max_length=encoder_max_length)\n",
    "    outputs = tokenizer(batch[\"Summary\"], padding=\"max_length\", truncation=True, max_length=decoder_max_length)\n",
    "\n",
    "    batch[\"input_ids\"] = inputs.input_ids\n",
    "    batch[\"attention_mask\"] = inputs.attention_mask\n",
    "    batch[\"decoder_input_ids\"] = outputs.input_ids\n",
    "    batch[\"decoder_attention_mask\"] = outputs.attention_mask\n",
    "    batch[\"labels\"] = outputs.input_ids.copy()\n",
    "\n",
    "    # because RoBERTa automatically shifts the labels, the labels correspond exactly to `decoder_input_ids`. \n",
    "    # We have to make sure that the PAD token is ignored\n",
    "    batch[\"labels\"] = [[-100 if token == tokenizer.pad_token_id else token for token in labels] for labels in batch[\"labels\"]]\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7bfedc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee8c5d021b0e46c68e017214b3d5b468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/459 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f678ed93c6243399cf4ba7834e4ddc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#processing training data\n",
    "train_data = train_data.map(\n",
    "    process_data_to_model_inputs, \n",
    "    batched=True, \n",
    "    batch_size=batch_size, \n",
    "    remove_columns=[\"Text\", \"Summary\"])\n",
    "train_data.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],)\n",
    "\n",
    "#processing validation data\n",
    "val_data = val_data.map(\n",
    "    process_data_to_model_inputs, \n",
    "    batched=True, \n",
    "    batch_size=batch_size, \n",
    "    remove_columns=[\"Text\", \"Summary\"])\n",
    "val_data.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d2bafce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7d32368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'decoder_attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'decoder_input_ids': tensor([    0,  3638,  2069, 18145,  2470,  1545, 14997,  2145,  3991,  2052,\n",
       "         17256,  1562, 20561,  2015,  2138,  1190,   904,  2299,  2118,  1565,\n",
       "          2118, 10983, 18395,  2259,  1503,  5318,  2138,  1122,  2088,   717,\n",
       "          2259,   597,  1972,  1513,  2259, 20588,  2069,  1351,  2062,    18,\n",
       "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1]),\n",
       " 'input_ids': tensor([    0, 21859,  2369, 16199,  7063,  3797,  2259,  8054,  2052,  1139,\n",
       "          3419,  6780,  2118,  2359,  2062,    18,  4179,  2098,     5,   918,\n",
       "         13394,  2052, 26354,  1793,  2023,  2052,  4844,    18,  3678,  4179,\n",
       "          2098,     5,  1535,  2259,  5080,  1889,  6901,  5121,  1565,  2118,\n",
       "         10983,  2918,  2219,  3606,    18,  1545,  2116, 10860,  2069,  4046,\n",
       "          2051,   717,  2138, 18145,  2470,  1545, 14997,  2145,   717,  2138,\n",
       "         13860,  2259,  1545,  3991,  6233,  7392,   732,  1388,  2170, 17256,\n",
       "          4998,  2069, 11213,  1562, 20561,  2015,  2138,  1190,  2015,  2299,\n",
       "          2118,  1535,  2259,  5231,  5231,  1565,  2118, 10983,  3147,  3606,\n",
       "            18,   717,  2259,  1504,  5318,  2138,  1122,  2088,  2259,  7740,\n",
       "          1513,  2069,  1295,  2116,  1415,  2359,  2062,    18,  5919,  2200,\n",
       "          2259,  1022,  5921,  2085,   848,  1028,  2138,  4033,  2275,  1889,\n",
       "          2918,  2088,  5532,  2200,  2259,  1503, 18505,  2069,  6761,  2227,\n",
       "          2275,  1889, 18395,  2088,  3628,  2205,  2507,   809,    18,  3775,\n",
       "           717,  2259,   597,  3608,  5324, 19521,  1972,  1513,  2259, 20588,\n",
       "          2069,  1351,  2062,    18,  3784,  2205,  2259,  6164,  2173,     5,\n",
       "           617,  2073,  3660,  4448,  2069,  1122,  2259,  1570, 28674,    18,\n",
       "          6635,  2170,   618,  2318, 30836,     5,  5771,   543,   617,  2069,\n",
       "         18145,  2205,  1436,  2062,  1889,  2460,  1022,  1632, 10592,  2181,\n",
       "            18,   617,  2052,  4333, 10597,  3784,  2085,  3985,  1415,  2259,\n",
       "          1517,  2138,  5418,  2173,  1460,  1443,  2650,  2205,  2259,  2116,\n",
       "            18, 29662,  2470,  3985,  1415,  2259,  3883,  2173, 22002, 16599,\n",
       "         19521,  1507,  2577,  2097, 10592,  2181,    18,   636, 19341,  1507,\n",
       "          2170,  7334, 29597,  7488,  4820,  2069,  5292, 19521,  9041,  2069,\n",
       "          5292,  2205,  2259,   575,  2073,   617,  2723,  2118,  4095,  1507,\n",
       "          2052,  5215,    18,  3673,   636,     2]),\n",
       " 'labels': tensor([    0,  3638,  2069, 18145,  2470,  1545, 14997,  2145,  3991,  2052,\n",
       "         17256,  1562, 20561,  2015,  2138,  1190,   904,  2299,  2118,  1565,\n",
       "          2118, 10983, 18395,  2259,  1503,  5318,  2138,  1122,  2088,   717,\n",
       "          2259,   597,  1972,  1513,  2259, 20588,  2069,  1351,  2062,    18,\n",
       "             2,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39691aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089a83d824974ce6935b34dee5810455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/546 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c52f63c1bf74a6d82dbc6247780345d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForCausalLM were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.encoder.layer.2.crossattention.output.dense.weight', 'roberta.encoder.layer.10.crossattention.self.key.bias', 'roberta.encoder.layer.7.crossattention.self.key.bias', 'roberta.encoder.layer.1.crossattention.output.dense.weight', 'roberta.encoder.layer.8.crossattention.output.dense.bias', 'roberta.encoder.layer.9.crossattention.output.dense.weight', 'roberta.encoder.layer.3.crossattention.self.key.bias', 'roberta.encoder.layer.8.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.self.query.weight', 'roberta.encoder.layer.7.crossattention.output.dense.bias', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.9.crossattention.self.key.weight', 'roberta.encoder.layer.11.crossattention.self.value.weight', 'roberta.encoder.layer.10.crossattention.output.dense.weight', 'roberta.encoder.layer.0.crossattention.self.query.weight', 'roberta.encoder.layer.4.crossattention.self.query.bias', 'roberta.encoder.layer.5.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.self.value.weight', 'roberta.encoder.layer.5.crossattention.self.value.bias', 'roberta.encoder.layer.5.crossattention.self.value.weight', 'roberta.encoder.layer.11.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.self.query.bias', 'roberta.encoder.layer.6.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.1.crossattention.self.query.weight', 'roberta.encoder.layer.0.crossattention.self.value.bias', 'roberta.encoder.layer.5.crossattention.output.dense.weight', 'roberta.encoder.layer.0.crossattention.self.value.weight', 'roberta.encoder.layer.8.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.11.crossattention.self.key.bias', 'roberta.encoder.layer.6.crossattention.output.dense.bias', 'roberta.encoder.layer.11.crossattention.self.query.weight', 'roberta.encoder.layer.7.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.self.value.weight', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.0.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.self.key.bias', 'roberta.encoder.layer.6.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.self.value.bias', 'roberta.encoder.layer.6.crossattention.self.key.weight', 'roberta.encoder.layer.7.crossattention.output.dense.weight', 'roberta.encoder.layer.8.crossattention.self.value.weight', 'roberta.encoder.layer.11.crossattention.self.key.weight', 'roberta.encoder.layer.10.crossattention.self.query.bias', 'roberta.encoder.layer.10.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.9.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.7.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.self.query.weight', 'roberta.encoder.layer.7.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.7.crossattention.self.value.weight', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.4.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.self.key.bias', 'roberta.encoder.layer.1.crossattention.self.value.bias', 'roberta.encoder.layer.0.crossattention.self.key.bias', 'roberta.encoder.layer.10.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.8.crossattention.self.key.bias', 'roberta.encoder.layer.8.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.5.crossattention.output.dense.bias', 'roberta.encoder.layer.6.crossattention.output.dense.weight', 'roberta.encoder.layer.1.crossattention.self.query.bias', 'roberta.encoder.layer.6.crossattention.self.query.bias', 'roberta.encoder.layer.2.crossattention.output.dense.bias', 'roberta.encoder.layer.3.crossattention.output.dense.weight', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.9.crossattention.output.dense.bias', 'roberta.encoder.layer.7.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.11.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.self.key.weight', 'roberta.encoder.layer.5.crossattention.self.query.weight', 'roberta.encoder.layer.0.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.self.query.bias', 'roberta.encoder.layer.10.crossattention.self.value.bias', 'roberta.encoder.layer.4.crossattention.self.key.bias', 'roberta.encoder.layer.10.crossattention.self.key.weight', 'roberta.encoder.layer.6.crossattention.self.key.bias', 'roberta.encoder.layer.5.crossattention.self.key.weight', 'roberta.encoder.layer.8.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.3.crossattention.self.key.weight', 'roberta.encoder.layer.2.crossattention.self.value.bias', 'roberta.encoder.layer.10.crossattention.self.query.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.8.crossattention.self.value.bias', 'roberta.encoder.layer.4.crossattention.self.key.weight', 'roberta.encoder.layer.3.crossattention.self.query.bias', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.6.crossattention.self.value.weight', 'roberta.encoder.layer.11.crossattention.output.dense.weight', 'roberta.encoder.layer.1.crossattention.self.value.weight', 'roberta.encoder.layer.9.crossattention.self.query.bias', 'roberta.encoder.layer.2.crossattention.self.query.bias', 'roberta.encoder.layer.6.crossattention.self.query.weight', 'roberta.encoder.layer.3.crossattention.output.dense.bias', 'roberta.encoder.layer.10.crossattention.self.value.weight', 'roberta.encoder.layer.7.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.self.key.weight', 'roberta.encoder.layer.9.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.11.crossattention.self.query.bias', 'roberta.encoder.layer.11.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.11.crossattention.self.value.bias', 'roberta.encoder.layer.0.crossattention.output.dense.weight', 'roberta.encoder.layer.8.crossattention.self.query.weight', 'roberta.encoder.layer.10.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.self.query.weight', 'roberta.encoder.layer.4.crossattention.output.dense.bias', 'roberta.encoder.layer.9.crossattention.self.key.bias', 'roberta.encoder.layer.9.crossattention.self.query.weight', 'roberta.encoder.layer.9.crossattention.self.value.bias', 'roberta.encoder.layer.9.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.4.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.output.dense.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.8.crossattention.self.query.bias', 'roberta.encoder.layer.6.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.7.crossattention.self.query.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following encoder weights were not tied to the decoder ['roberta/pooler']\n"
     ]
    }
   ],
   "source": [
    "# 인코더 모델 불러오기\n",
    "\n",
    "from transformers import EncoderDecoderModel\n",
    "\n",
    "roberta_shared = EncoderDecoderModel.from_encoder_decoder_pretrained(\"klue/roberta-base\", \"klue/roberta-base\", tie_encoder_decoder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47e676e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set special tokens\n",
    "from transformers import EncoderDecoderConfig\n",
    "roberta_shared.config.decoder_start_token_id = tokenizer.bos_token_id                                             \n",
    "roberta_shared.config.eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# sensible parameters for beam search\n",
    "# set decoding params                               \n",
    "roberta_shared.config.max_length = 128\n",
    "roberta_shared.config.early_stopping = True\n",
    "roberta_shared.config.no_repeat_ngram_size = 3\n",
    "roberta_shared.config.length_penalty = 2.0\n",
    "roberta_shared.config.num_beams = 4\n",
    "roberta_shared.config.vocab_size = roberta_shared.config.encoder.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36deb3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load rouge for validation\n",
    "rouge = datasets.load_metric(\"rouge\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # all unnecessary tokens are removed\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
    "\n",
    "    return {\n",
    "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
    "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
    "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df6e12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n",
      "The `config.pad_token_id` is `None`. Using `config.eos_token_id` = 2 for padding..\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 14687\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4590\n",
      "  Number of trainable parameters = 139609088\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1103' max='4590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1103/4590 30:00 < 1:35:02, 0.61 it/s, Epoch 2.40/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.251200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.002800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./checkpoint-16\n",
      "Configuration saved in ./checkpoint-16/config.json\n",
      "Model weights saved in ./checkpoint-16/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-32\n",
      "Configuration saved in ./checkpoint-32/config.json\n",
      "Model weights saved in ./checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-16] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-48\n",
      "Configuration saved in ./checkpoint-48/config.json\n",
      "Model weights saved in ./checkpoint-48/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-32] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-64\n",
      "Configuration saved in ./checkpoint-64/config.json\n",
      "Model weights saved in ./checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-48] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-80\n",
      "Configuration saved in ./checkpoint-80/config.json\n",
      "Model weights saved in ./checkpoint-80/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-64] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-96\n",
      "Configuration saved in ./checkpoint-96/config.json\n",
      "Model weights saved in ./checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-80] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-112\n",
      "Configuration saved in ./checkpoint-112/config.json\n",
      "Model weights saved in ./checkpoint-112/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-96] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-128\n",
      "Configuration saved in ./checkpoint-128/config.json\n",
      "Model weights saved in ./checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-112] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-144\n",
      "Configuration saved in ./checkpoint-144/config.json\n",
      "Model weights saved in ./checkpoint-144/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-128] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-160\n",
      "Configuration saved in ./checkpoint-160/config.json\n",
      "Model weights saved in ./checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-144] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-176\n",
      "Configuration saved in ./checkpoint-176/config.json\n",
      "Model weights saved in ./checkpoint-176/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-160] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./checkpoint-192\n",
      "Configuration saved in ./checkpoint-192/config.json\n",
      "Model weights saved in ./checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-176] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-208\n",
      "Configuration saved in ./checkpoint-208/config.json\n",
      "Model weights saved in ./checkpoint-208/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-192] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-224\n",
      "Configuration saved in ./checkpoint-224/config.json\n",
      "Model weights saved in ./checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-208] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-240\n",
      "Configuration saved in ./checkpoint-240/config.json\n",
      "Model weights saved in ./checkpoint-240/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-224] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-256\n",
      "Configuration saved in ./checkpoint-256/config.json\n",
      "Model weights saved in ./checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-240] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-272\n",
      "Configuration saved in ./checkpoint-272/config.json\n",
      "Model weights saved in ./checkpoint-272/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-256] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-288\n",
      "Configuration saved in ./checkpoint-288/config.json\n",
      "Model weights saved in ./checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-272] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-304\n",
      "Configuration saved in ./checkpoint-304/config.json\n",
      "Model weights saved in ./checkpoint-304/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-288] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-320\n",
      "Configuration saved in ./checkpoint-320/config.json\n",
      "Model weights saved in ./checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-304] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-336\n",
      "Configuration saved in ./checkpoint-336/config.json\n",
      "Model weights saved in ./checkpoint-336/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-320] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-352\n",
      "Configuration saved in ./checkpoint-352/config.json\n",
      "Model weights saved in ./checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-336] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./checkpoint-368\n",
      "Configuration saved in ./checkpoint-368/config.json\n",
      "Model weights saved in ./checkpoint-368/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-352] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-384\n",
      "Configuration saved in ./checkpoint-384/config.json\n",
      "Model weights saved in ./checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-368] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-400\n",
      "Configuration saved in ./checkpoint-400/config.json\n",
      "Model weights saved in ./checkpoint-400/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-384] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-416\n",
      "Configuration saved in ./checkpoint-416/config.json\n",
      "Model weights saved in ./checkpoint-416/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-400] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-432\n",
      "Configuration saved in ./checkpoint-432/config.json\n",
      "Model weights saved in ./checkpoint-432/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-416] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-448\n",
      "Configuration saved in ./checkpoint-448/config.json\n",
      "Model weights saved in ./checkpoint-448/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-432] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-464\n",
      "Configuration saved in ./checkpoint-464/config.json\n",
      "Model weights saved in ./checkpoint-464/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-448] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-480\n",
      "Configuration saved in ./checkpoint-480/config.json\n",
      "Model weights saved in ./checkpoint-480/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-464] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-496\n",
      "Configuration saved in ./checkpoint-496/config.json\n",
      "Model weights saved in ./checkpoint-496/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-480] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-512\n",
      "Configuration saved in ./checkpoint-512/config.json\n",
      "Model weights saved in ./checkpoint-512/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-496] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-528\n",
      "Configuration saved in ./checkpoint-528/config.json\n",
      "Model weights saved in ./checkpoint-528/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-512] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./checkpoint-544\n",
      "Configuration saved in ./checkpoint-544/config.json\n",
      "Model weights saved in ./checkpoint-544/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-528] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-560\n",
      "Configuration saved in ./checkpoint-560/config.json\n",
      "Model weights saved in ./checkpoint-560/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-544] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-576\n",
      "Configuration saved in ./checkpoint-576/config.json\n",
      "Model weights saved in ./checkpoint-576/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-560] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-592\n",
      "Configuration saved in ./checkpoint-592/config.json\n",
      "Model weights saved in ./checkpoint-592/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-576] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-608\n",
      "Configuration saved in ./checkpoint-608/config.json\n",
      "Model weights saved in ./checkpoint-608/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-592] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-624\n",
      "Configuration saved in ./checkpoint-624/config.json\n",
      "Model weights saved in ./checkpoint-624/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-608] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-640\n",
      "Configuration saved in ./checkpoint-640/config.json\n",
      "Model weights saved in ./checkpoint-640/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-624] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-656\n",
      "Configuration saved in ./checkpoint-656/config.json\n",
      "Model weights saved in ./checkpoint-656/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-640] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-672\n",
      "Configuration saved in ./checkpoint-672/config.json\n",
      "Model weights saved in ./checkpoint-672/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-656] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-688\n",
      "Configuration saved in ./checkpoint-688/config.json\n",
      "Model weights saved in ./checkpoint-688/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-672] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-704\n",
      "Configuration saved in ./checkpoint-704/config.json\n",
      "Model weights saved in ./checkpoint-704/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-688] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./checkpoint-720\n",
      "Configuration saved in ./checkpoint-720/config.json\n",
      "Model weights saved in ./checkpoint-720/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-704] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-736\n",
      "Configuration saved in ./checkpoint-736/config.json\n",
      "Model weights saved in ./checkpoint-736/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-720] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-752\n",
      "Configuration saved in ./checkpoint-752/config.json\n",
      "Model weights saved in ./checkpoint-752/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-736] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-768\n",
      "Configuration saved in ./checkpoint-768/config.json\n",
      "Model weights saved in ./checkpoint-768/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-752] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-784\n",
      "Configuration saved in ./checkpoint-784/config.json\n",
      "Model weights saved in ./checkpoint-784/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-768] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-800\n",
      "Configuration saved in ./checkpoint-800/config.json\n",
      "Model weights saved in ./checkpoint-800/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-784] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-816\n",
      "Configuration saved in ./checkpoint-816/config.json\n",
      "Model weights saved in ./checkpoint-816/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-800] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-832\n",
      "Configuration saved in ./checkpoint-832/config.json\n",
      "Model weights saved in ./checkpoint-832/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-816] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-848\n",
      "Configuration saved in ./checkpoint-848/config.json\n",
      "Model weights saved in ./checkpoint-848/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-832] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-864\n",
      "Configuration saved in ./checkpoint-864/config.json\n",
      "Model weights saved in ./checkpoint-864/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-848] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-880\n",
      "Configuration saved in ./checkpoint-880/config.json\n",
      "Model weights saved in ./checkpoint-880/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-864] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./checkpoint-896\n",
      "Configuration saved in ./checkpoint-896/config.json\n",
      "Model weights saved in ./checkpoint-896/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-880] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-912\n",
      "Configuration saved in ./checkpoint-912/config.json\n",
      "Model weights saved in ./checkpoint-912/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-896] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-928\n",
      "Configuration saved in ./checkpoint-928/config.json\n",
      "Model weights saved in ./checkpoint-928/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-912] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-944\n",
      "Configuration saved in ./checkpoint-944/config.json\n",
      "Model weights saved in ./checkpoint-944/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-928] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-960\n",
      "Configuration saved in ./checkpoint-960/config.json\n",
      "Model weights saved in ./checkpoint-960/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-944] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-976\n",
      "Configuration saved in ./checkpoint-976/config.json\n",
      "Model weights saved in ./checkpoint-976/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-960] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-992\n",
      "Configuration saved in ./checkpoint-992/config.json\n",
      "Model weights saved in ./checkpoint-992/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-976] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-1008\n",
      "Configuration saved in ./checkpoint-1008/config.json\n",
      "Model weights saved in ./checkpoint-1008/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-992] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-1024\n",
      "Configuration saved in ./checkpoint-1024/config.json\n",
      "Model weights saved in ./checkpoint-1024/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-1008] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-1040\n",
      "Configuration saved in ./checkpoint-1040/config.json\n",
      "Model weights saved in ./checkpoint-1040/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-1024] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-1056\n",
      "Configuration saved in ./checkpoint-1056/config.json\n",
      "Model weights saved in ./checkpoint-1056/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-1040] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./checkpoint-1072\n",
      "Configuration saved in ./checkpoint-1072/config.json\n",
      "Model weights saved in ./checkpoint-1072/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-1056] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./checkpoint-1088\n",
      "Configuration saved in ./checkpoint-1088/config.json\n",
      "Model weights saved in ./checkpoint-1088/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-1072] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./\",\n",
    "    num_train_epochs = 10,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    predict_with_generate=True,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    logging_steps=500, \n",
    "    save_steps=16, \n",
    "    eval_steps=500, \n",
    "    warmup_steps=500, \n",
    "    overwrite_output_dir=True,\n",
    "    save_total_limit=1,\n",
    "    fp16=True,)\n",
    "\n",
    "# instantiate trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=roberta_shared,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb2bfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"gogamza/kobart-base-v1\")\n",
    "model = EncoderDecoderModel.from_pretrained('/aiffel/aiffel/aiffelthon/checkpoint-2752/')\n",
    "model.to(\"cuda\")\n",
    "batch_size = 32\n",
    "\n",
    "# map data correctly\n",
    "def generate_summary(batch):\n",
    "    # Tokenizer will automatically set [BOS] <text> [EOS]\n",
    "    inputs = tokenizer(batch[\"Text\"], padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids.to(\"cuda\")\n",
    "    attention_mask = inputs.attention_mask.to(\"cuda\")\n",
    "    outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
    "    # all special tokens including will be removed\n",
    "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    batch[\"pred\"] = output_str\n",
    "\n",
    "    return batch\n",
    "results = test_data.map(generate_summary, batched=True, batch_size=batch_size, remove_columns=[\"Text\"])\n",
    "pred_str = results[\"pred\"]\n",
    "label_str = results[\"Summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b82f114",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for num in range(500,800,10):\n",
    "    print('predicted sentence : ',pred_str[num])\n",
    "    print('real sentence : ', label_str[num])\n",
    "    print('-'*30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
