{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64383083",
   "metadata": {},
   "source": [
    "## 1.Import 및 라이브러리 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "295323a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "sys.path.append('~/aiffel/Aiffelthon_koBART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4144ba9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge_score in /opt/conda/lib/python3.9/site-packages (0.1.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from rouge_score) (1.21.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.9/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.9/site-packages (from rouge_score) (0.12.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.9/site-packages (from rouge_score) (3.6.5)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (2021.11.10)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (8.0.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (4.62.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: datasets==1.0.2 in /opt/conda/lib/python3.9/site-packages (1.0.2)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (2.0.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (2.26.0)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (0.3.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (4.62.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (3.4.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (1.3.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (1.21.4)\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (6.0.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.0.2) (2.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.0.2) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.0.2) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.0.2) (2021.10.8)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets==1.0.2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets==1.0.2) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->datasets==1.0.2) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: transformers==4.24.0 in /opt/conda/lib/python3.9/site-packages (4.24.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (1.21.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (3.4.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (0.13.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (0.10.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (21.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (2.26.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (2021.11.10)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (4.62.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.24.0) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->transformers==4.24.0) (3.0.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.24.0) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.24.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.24.0) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.24.0) (2.0.8)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: transformer-utils in /opt/conda/lib/python3.9/site-packages (0.1.1)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.9/site-packages (from transformer-utils) (4.24.0)\n",
      "Requirement already satisfied: colorcet in /opt/conda/lib/python3.9/site-packages (from transformer-utils) (3.0.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from transformer-utils) (4.62.3)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.9/site-packages (from transformer-utils) (1.9.1+cu111)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.9/site-packages (from transformer-utils) (0.11.2)\n",
      "Requirement already satisfied: pyct>=0.4.4 in /opt/conda/lib/python3.9/site-packages (from colorcet->transformer-utils) (0.4.8)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.9/site-packages (from seaborn->transformer-utils) (1.7.1)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /opt/conda/lib/python3.9/site-packages (from seaborn->transformer-utils) (3.4.3)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.9/site-packages (from seaborn->transformer-utils) (1.21.4)\n",
      "Requirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.9/site-packages (from seaborn->transformer-utils) (1.3.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch->transformer-utils) (4.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (2.26.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (0.13.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (2021.11.10)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (3.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (0.10.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (3.0.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (8.3.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.23->seaborn->transformer-utils) (2021.3)\n",
      "Requirement already satisfied: param>=1.7.0 in /opt/conda/lib/python3.9/site-packages (from pyct>=0.4.4->colorcet->transformer-utils) (1.12.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->transformers->transformer-utils) (2.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers->transformer-utils) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers->transformer-utils) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers->transformer-utils) (2.10)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn->transformer-utils) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging) (3.0.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.9/site-packages (0.13.5)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.9/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (8.0.3)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.9/site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (1.10.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (2.26.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (3.1.29)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from wandb) (59.4.0)\n",
      "Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (3.19.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (1.0.9)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.9/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.9/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (1.26.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score\n",
    "!pip install datasets==1.0.2\n",
    "!pip install transformers==4.24.0\n",
    "!pip install transformer-utils\n",
    "!pip install packaging\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "934076b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "import datasets\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    TrainingArguments\n",
    "\n",
    ")\n",
    "\n",
    "from transformers import RobertaTokenizerFast\n",
    "from transformers import EncoderDecoderModel\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6cb6bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73431 9150\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "train_20sent = pd.read_csv('data/train_20per_Sum3.csv')\n",
    "#train_df.drop(labels = 'Unnamed: 0', axis = 1, inplace = True)\n",
    "train_20sent.rename(columns = {\"input\": \"Text\"}, inplace = True)\n",
    "#train_20sent.rename(columns = {\"sentence_per_20\": \"Summary\"}, inplace = True)\n",
    "train_20sent.rename(columns = {\"sentence_per_20\": \"Summary\"}, inplace = True)\n",
    "\n",
    "val_20sent = pd.read_csv('data/val_20per_Sum3.csv')\n",
    "#val_df.drop(labels = 'Unnamed: 0', axis = 1, inplace = True)\n",
    "val_20sent.rename(columns = {\"input\": \"Text\"}, inplace = True)\n",
    "#val_20sent.rename(columns = {\"summary_per_20\": \"Summary\"}, inplace = True)\n",
    "val_20sent.rename(columns = {\"summary_per_20\": \"Summary\"}, inplace = True)\n",
    "print(len(train_20sent), len(val_20sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "822b93f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 제거\n",
    "    sentence = re.sub(\"'\",'', sentence) # 따옴표 제거\n",
    "    sentence = re.sub('\\n','', sentence) # \\n \" 제거\n",
    "    sentence = re.sub('.{2,3}\\W{0,1}기자','', sentence) # 기자 이름 제거\n",
    "    sentence = re.sub(r'[?.!,][/?.!,]', '', sentence) # 여러개 문장 부호를 하나의 문장부호로 바꿉니다\n",
    "    sentence = re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣a-z0-9]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 여러개 공백을 하나의 공백으로 바꿉니다.\n",
    "    sentence = sentence.strip() # 문장 양쪽 공백 제거\n",
    "\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "181bd3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73431/73431 [00:14<00:00, 4919.16it/s]\n",
      "100%|██████████| 73431/73431 [00:03<00:00, 21255.59it/s]\n"
     ]
    }
   ],
   "source": [
    "clean_text = []\n",
    "clean_headlines = []\n",
    "\n",
    "for i in tqdm(train_20sent['Text']):\n",
    "    clean_text.append(preprocess_sentence(i))\n",
    "for i in tqdm(train_20sent['Summary']):\n",
    "    clean_headlines.append(preprocess_sentence(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cf45abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_20sent['Text'] = clean_text\n",
    "train_20sent['Summary'] = clean_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ed33224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF > data Set으로 전환\n",
    "train_data = Dataset.from_pandas(train_20sent) \n",
    "val_len = len(val_20sent) // 2\n",
    "val_data = Dataset.from_pandas(val_20sent[:val_len])\n",
    "test_data=Dataset.from_pandas(val_20sent[val_len:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d27fcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_len = len(train_20sent)//4\n",
    "# train_data = Dataset.from_pandas(train_20sent[:train_len]) \n",
    "# val_len = len(val_20sent) // 8\n",
    "# val_data = Dataset.from_pandas(val_20sent[:val_len])\n",
    "# test_data=Dataset.from_pandas(val_20sent[val_len:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f534fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(features: {'Text': Value(dtype='string', id=None), 'Summary': Value(dtype='string', id=None)}, num_rows: 73431)\n",
      "Dataset(features: {'Text': Value(dtype='string', id=None), 'Summary': Value(dtype='string', id=None)}, num_rows: 4575)\n",
      "Dataset(features: {'Text': Value(dtype='string', id=None), 'Summary': Value(dtype='string', id=None)}, num_rows: 4575)\n"
     ]
    }
   ],
   "source": [
    "print(train_data)\n",
    "print(val_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ded98ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input = 512\n",
    "max_target = 64\n",
    "batch_size = 3\n",
    "model_checkpoints = \"gogamza/kobart-base-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f2bbf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6583f469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data_to_process):\n",
    "  #get all the dialogues\n",
    "  inputs = [dialogue for dialogue in data_to_process['Text']]\n",
    "  #tokenize the dialogues\n",
    "  model_inputs = tokenizer(inputs,  max_length=max_input, padding='max_length', truncation=True)\n",
    "  #tokenize the summaries\n",
    "  with tokenizer.as_target_tokenizer():\n",
    "    targets = tokenizer(data_to_process['Summary'], max_length=max_target, padding='max_length', truncation=True)\n",
    "    \n",
    "  #set labels\n",
    "  model_inputs['labels'] = targets['input_ids']\n",
    "  #return the tokenized data\n",
    "  #input_ids, attention_mask and labels\n",
    "  return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ecb9d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3546: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "851dd140c0b24a1196af0fd6d118067d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270ac5ada1fb47249c16661e8a0cffb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_tokenize_data = train_data.map(preprocess_data, batched = True, remove_columns=['Text', 'Summary'])\n",
    "val_tokenize_data = val_data.map(preprocess_data, batched = True, remove_columns=['Text', 'Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ff70599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c1d42b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set special tokens\n",
    "#from transformers import EncoderDecoderConfig\n",
    "model.config.decoder_start_token_id = tokenizer.bos_token_id                                             \n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# sensible parameters for beam search\n",
    "# set decoding params                               \n",
    "model.config.max_length = 64\n",
    "model.config.early_stopping = True\n",
    "model.config.no_repeat_ngram_size = 2\n",
    "model.config.length_penalty = 2.0\n",
    "model.config.num_beams = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d988a9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = datasets.load_metric(\"rouge\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # all unnecessary tokens are removed\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
    "\n",
    "    return {\n",
    "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
    "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
    "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02cd446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"results_221109_3\",\n",
    "    num_train_epochs=1,  # demo\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=16,  # demo\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=3e-5,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.1,\n",
    "    label_smoothing_factor=0.1,\n",
    "    predict_with_generate=True,\n",
    "    logging_dir=\"logs2\",\n",
    "    logging_steps=500,\n",
    "    save_total_limit=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee0dffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9dad82d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model, \n",
    "    training_args,\n",
    "    train_dataset=train_tokenize_data,\n",
    "    eval_dataset=val_tokenize_data,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9437444a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 73431\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4590\n",
      "  Number of trainable parameters = 123859968\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjx7789\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/aiffel/aiffel/Aiffelthon_koBART/wandb/run-20221109_073508-1j0yt1ey</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jx7789/huggingface/runs/1j0yt1ey\" target=\"_blank\">results_221109_3</a></strong> to <a href=\"https://wandb.ai/jx7789/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4590' max='4590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4590/4590 1:25:54, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.367100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.582800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.549700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.532600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.525600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.514400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.511200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.508800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.504500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to results_221109_3/checkpoint-500\n",
      "Configuration saved in results_221109_3/checkpoint-500/config.json\n",
      "Model weights saved in results_221109_3/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in results_221109_3/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in results_221109_3/checkpoint-500/special_tokens_map.json\n",
      "Saving model checkpoint to results_221109_3/checkpoint-1000\n",
      "Configuration saved in results_221109_3/checkpoint-1000/config.json\n",
      "Model weights saved in results_221109_3/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in results_221109_3/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in results_221109_3/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to results_221109_3/checkpoint-1500\n",
      "Configuration saved in results_221109_3/checkpoint-1500/config.json\n",
      "Model weights saved in results_221109_3/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in results_221109_3/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in results_221109_3/checkpoint-1500/special_tokens_map.json\n",
      "Saving model checkpoint to results_221109_3/checkpoint-2000\n",
      "Configuration saved in results_221109_3/checkpoint-2000/config.json\n",
      "Model weights saved in results_221109_3/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in results_221109_3/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in results_221109_3/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [results_221109_3/checkpoint-500] due to args.save_total_limit\n",
      "Saving model checkpoint to results_221109_3/checkpoint-2500\n",
      "Configuration saved in results_221109_3/checkpoint-2500/config.json\n",
      "Model weights saved in results_221109_3/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in results_221109_3/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in results_221109_3/checkpoint-2500/special_tokens_map.json\n",
      "Deleting older checkpoint [results_221109_3/checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to results_221109_3/checkpoint-3000\n",
      "Configuration saved in results_221109_3/checkpoint-3000/config.json\n",
      "Model weights saved in results_221109_3/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in results_221109_3/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in results_221109_3/checkpoint-3000/special_tokens_map.json\n",
      "Deleting older checkpoint [results_221109_3/checkpoint-1500] due to args.save_total_limit\n",
      "Saving model checkpoint to results_221109_3/checkpoint-3500\n",
      "Configuration saved in results_221109_3/checkpoint-3500/config.json\n",
      "Model weights saved in results_221109_3/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in results_221109_3/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in results_221109_3/checkpoint-3500/special_tokens_map.json\n",
      "Deleting older checkpoint [results_221109_3/checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to results_221109_3/checkpoint-4000\n",
      "Configuration saved in results_221109_3/checkpoint-4000/config.json\n",
      "Model weights saved in results_221109_3/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in results_221109_3/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in results_221109_3/checkpoint-4000/special_tokens_map.json\n",
      "Deleting older checkpoint [results_221109_3/checkpoint-2500] due to args.save_total_limit\n",
      "Saving model checkpoint to results_221109_3/checkpoint-4500\n",
      "Configuration saved in results_221109_3/checkpoint-4500/config.json\n",
      "Model weights saved in results_221109_3/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in results_221109_3/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in results_221109_3/checkpoint-4500/special_tokens_map.json\n",
      "Deleting older checkpoint [results_221109_3/checkpoint-3000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4590, training_loss=1.619514312411705, metrics={'train_runtime': 5157.9983, 'train_samples_per_second': 14.236, 'train_steps_per_second': 0.89, 'total_flos': 2.238677893251072e+16, 'train_loss': 1.619514312411705, 'epoch': 1.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c49c1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4575\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='286' max='286' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [286/286 08:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.9964174032211304,\n",
       " 'eval_rouge2_precision': 0.1583,\n",
       " 'eval_rouge2_recall': 0.1585,\n",
       " 'eval_rouge2_fmeasure': 0.1519,\n",
       " 'eval_runtime': 505.8773,\n",
       " 'eval_samples_per_second': 9.044,\n",
       " 'eval_steps_per_second': 0.565,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d93fc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /aiffel/.cache/huggingface/hub/models--gogamza--kobart-base-v2/snapshots/d9a1f640896cef8dcfd693b1bc57510a2b09a18f/config.json\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"gogamza/kobart-base-v2\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.1,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"kobart_version\": 2.0,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 1026,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"tokenizer_class\": \"PreTrainedTokenizerFast\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /aiffel/.cache/huggingface/hub/models--gogamza--kobart-base-v2/snapshots/d9a1f640896cef8dcfd693b1bc57510a2b09a18f/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at gogamza/kobart-base-v2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 64 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def generate_summary(test_samples, model):\n",
    "    inputs = tokenizer(\n",
    "        test_samples[\"Text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_target,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    input_ids = inputs.input_ids.to(model.device)\n",
    "    \n",
    "    attention_mask = inputs.attention_mask.to(model.device)\n",
    "    outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
    "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return outputs, output_str\n",
    "\n",
    "\n",
    "model_before_tuning = AutoModelForSeq2SeqLM.from_pretrained(\"gogamza/kobart-base-v2\")# 여기에 기본 kobart가져오기?\n",
    "\n",
    "test_samples = val_data.select(range(16))\n",
    "\n",
    "summaries_before_tuning = generate_summary(test_samples, model_before_tuning)[1]\n",
    "summaries_after_tuning = generate_summary(test_samples, model)[1] # 여기에 체크포인트 가져오기 \n",
    "# 연구해봐야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8300df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "358cf70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx_0 \n",
      "Summary before \n",
      " 일본 사법당당국의 출국금지 명령이 내려져 있던 카를로스 곤(65)\n",
      "Summary after \n",
      " 일본 사법당국의 출국금지 명령이 내려져 있던 카를로스 곤(6 방송통신 산업통상자원 미래창조과학 한국 레바논으로 비밀리에 도주  30일(현지시간) 미 일간 월스트리트저널(WSJ)은 소식통을 인용해 곤 전 회장이 이날레바논 수도 베이루트 공항에 도착\n",
      "Target summary \n",
      " 일본 사법당국의 출국금지 명령이 내려져 있던 카를로스 곤(65) 전 르노닛산 회장이 레바논으로 비밀리에 도주했다. 이 때문에 곤 전 회장의 변호인은 물론 수사·출입국 당국까지 당혹스럽다는 반응을 보이는 상황이다. 곤 전 회장은 일본의 ‘정치적 박해’로부터 빠져나왔다고 주장하고 있다.\n",
      "Text 일본 사법당국의 출국금지 명령이 내려져 있던 카를로스 곤(65) 전 르노닛산 회장이 레바논으로 비밀리에 도주했다.\n",
      "  30일(현지시간) 미 일간 월스트리트저널(WSJ)은 소식통을 인용해 곤 전 회장이 이날 레바논 수도 베이루트 공항에 도착했다고 전했다.\n",
      "  곤 전 회장은 보도 이후 미국의 대변인을 통해 자신이 레바논에 머물고 있다는 내용의 성명을 발표했다.\n",
      "  이 때문에 곤 전 회장의 변호인은 물론 수사·출입국 당국까지 당혹스럽다는 반응을 보이는 상황이다.\n",
      "    곤 전 회장은 일본의 ‘정치적 박해’로부터 빠져나왔다고 주장하고 있다.\n",
      "  그는 성명을 통해 “유죄가 전제되고 차별이 만연하고 기본적 인권이 무시되는 잘못된 일본 사법제도의 ‘인질’이 되지 않겠다”고 밝혔다.\n",
      "  곤 전 회장은 르노닛산 회장 시절 회사 공금을 유용했다는 혐의 등으로 일본에서 재판을 받고 있다.\n",
      "  지난해 4월 두 번째 보석 당시 법원에서는 거주제한·출국금지 조치를 포함한 엄격한 감시 명령을 내렸다.\n",
      "  도쿄지방재판소는 도쿄도(東京都) 미나토(港)구 소재 단독 주택으로 곤의 주거지를 제한하고 일본에서 출국하는 것을 금지하는 등의 조건으로 보석을 인정했다.\n",
      "  곤 전 회장의 주거지 현관에 감시 카메라를 설치해 녹화된 내용을 정기적으로 법원에 제출하며, 휴대전화의 경우 인터넷 접속을 할 수 없는 1대만 변호인에게서 받아 사용하고 그 통화 이력도 법원에 제출하도록 하는 조건도 걸려 있었다.\n",
      "  곤 전 회장의 변호인 히로나카 준이치로(弘中惇一郞) 변호사는 “보도된 내용 이상의 것을 알지 못하며 현재 상황에 매우 놀랐다.\n",
      "  앞으로 정보가 들어오면 법원에 제공하겠다”고 반응했다.\n",
      "  그는 “곤 전 회장의 여권은 변호사가 보관하고 있으며 변호인단이 여권을 주는 일은 있을 수 없다”고 설명했다.\n",
      "  교도통신은 일본 출입국재류관리청의 데이터베이스에 곤 전 회장이 출국한 기록이 없는 것으로 확인됐다고 관계자의 설명을 토대로 전했다.\n",
      "  이와 관련해 레바논 치안 당국자는 곤 전 회장으로 보이는 인물이 개인용 제트기를 이용해 베이루트에 도착했다고 NHK에 설명했다.\n",
      "  이 인물의 입국 절차에 관해선 “다른 이름으로 입국했다.\n",
      "  카를로스 곤이라는 이름은 아니었다”고 말했다.\n",
      "  교도통신은 곤 전 회장이 터키에서부터 개인용 제트기를 이용한 것으로 보인다고 프랑스 일간지 레제코를 인용해 전했다.\n",
      "  교도통신에 따르면 레바논 유력 방송사인 MTV가 곤 전 회장이 악기 상자에 숨어 일본 지방공항을 통해 출국했다고 보도하는 등 의외의 경로가 이용됐을 가능성도 제기된다.\n",
      " \n",
      "----------------------------------------------------------------------------------------------------\n",
      "idx_1 \n",
      "Summary before \n",
      " 이이이이 김도읍 의원(재선)이 느닷없이 불출마를 선언하자\n",
      "Summary after \n",
      " 황교안 자유한국당 대표의 최측근인 김도읍 의원(재선)이 느닷없이 불출마를 선언하자 그 배경을 두고 설왕설래가 오가고 있다.\n",
      "워 그왕을왕의왕 방송통신 런던올림픽 가 이에 이상 백선에서왕이\n",
      "Target summary \n",
      " 김 의원은 황 대표에게도 불출마 소식을 미리 전하지 않았다. 소식을 전해 들은 황 대표는 \"(불출마를) 알았으면 말릴 걸 알고 나에게 미리 말을 안 한 것 같다\"고 말했다고 한다. 이와 관련 황 대표는 1일 기자 오찬 간담회에서 \"(김 의원의 불출마를) 언제 전해 들었느냐\"는 질문에 \"본인의 뜻을 존중했다. (언제 들었는지는) 크게 중요하지 않다\"고 답했다.\n",
      "Text 황교안 자유한국당 대표의 최측근인 김도읍 의원(재선)이 느닷없이 불출마를 선언하자 그 배경을 두고 설왕설래가 오가고 있다.\n",
      "   김 의원은 지난해 12월 31일 저녁 기자들에게 문자메시지를 보내 \"총선 압승을 위한 당의 쇄신에 밀알이 되고자 한다\"며 \"(21대) 총선에 출마하지 않겠다\"고 밝혔다.\n",
      "  검사 출신이자 국회 법제사법위원회 당 간사인 김 의원은 국회 본회의를 통과한 고위공직자범죄수사처(공수처) 설치법안을 막지 못했다는 것을 불출마 이유로 들었다.\n",
      "  그는 \"내년 총선 압승으로 (공수처법을) 반드시 바로 잡아야 한다\"고 했다.\n",
      "  \"저녁 7시에 쪽지 봐라\"…황교안도 몰랐다 김 의원의 불출마 선언은 의원실 소속 보좌진도 당일 오후 5시쯤 알게 됐다고 한다.\n",
      "  한 보좌관이 부산행 비행기를 타기 위해 공항으로 떠나는 김 의원을 배웅하러 갔는데, 그 자리에서 김 의원이 쪽지를 하나 건넸다고 한다.\n",
      "  김 의원은 보좌관에게 \"저녁 7시가 되면 쪽지를 열어보라\"고 당부한 뒤 \"쪽지에 적힌 내용을 기자들에게 그대로 발송하라\"고 지시했다고 한다.\n",
      "  이후 의원실 직원들이 거듭 만류했지만 김 의원은 뜻을 굽히지 않았다.\n",
      "  결국 불출마 선언이 담긴 문자는 이날 오후 7시 58분에 발송됐다.\n",
      "  김 의원은 황 대표에게도 불출마 소식을 미리 전하지 않았다.\n",
      "  소식을 전해 들은 황 대표는 \"(불출마를) 알았으면 말릴 걸 알고 나에게 미리 말을 안 한 것 같다\"고 말했다고 한다.\n",
      "  이와 관련 황 대표는 1일 기자 오찬 간담회에서 \"(김 의원의 불출마를) 언제 전해 들었느냐\"는 질문에 \"본인의 뜻을 존중했다.\n",
      "  (언제 들었는지는) 크게 중요하지 않다\"고 답했다.\n",
      "  김 의원과 가깝게 지낸 한 초선 의원은 \"소식을 듣자마자 놀라 전화도 하고 문자메시지까지 남겨 취소를 권유했지만, 하루가 지난 지금까지 답이 없다\"고 말했다.\n",
      "  김 의원은 최근 \"정치에 대해 환멸을 느낀다\"는 취지의 말을 종종 했다.\n",
      "  선거법 필리버스터(무제한 토론)가 진행 중이던 지난달 24일 밤, 국회의사당 7층 하늘정원에서 기자와 마주친 그는 \"배지를 달고서 앞만 보고 열심히 일했지만, 보람이 없다\"며 \"국회의원을 계속할 욕심 같은 건 없다\"고 말했다.\n",
      "  불출마 둘러싸고 해석 분분김 의원은 추경호 의원과 함께 황 대표의 '쌍두마차'로 불린다.\n",
      "  지난해 8월 황 대표의 두 번째 비서실장을 맡았다가 넉 달이 지난 지난달 초 \"황 대표의 쇄신에 보탬이 되겠다\"며 다른 당직자들과 함께 일괄 사퇴했다.\n",
      " \n",
      "----------------------------------------------------------------------------------------------------\n",
      "idx_2 \n",
      "Summary before \n",
      " 추울수록 위력이 강할 듯했다.\n",
      "   통영의 하루를 여는 음식이 시\n",
      "Summary after \n",
      " 1980년대 항남동 골목길 포장마차에서 우연히 개발한 메뉴가 해장 음식으로 입소 음식에 입소를 입소에 입소의 입소가 해 장 음식은 입소에서 입 소 음식 하루를 마감하는 음식이다.\n",
      " 한 데 섞어 우짜다.\n",
      " 마 카만\n",
      "Target summary \n",
      " 통영의 하루를 여는 음식이 시락국이라면 ‘우짜’는 하루를 마감하는 음식이다. 우동과 짜장을 한 데 섞어 우짜다. 1980년대 항남동 골목길 포장마차에서 우연히 개발한 메뉴가 해장 음식으로 입소문을 타면서 통영 명물로 자리 잡았단다. 처음엔 ‘이게 무슨 조화인가’ 싶지만, 입맛 당기는 마력이 있다.\n",
      "Text  추울수록 위력이 강할 듯했다.\n",
      "   통영의 하루를 여는 음식이 시락국이라면 ‘우짜’는 하루를 마감하는 음식이다.\n",
      "  우동과 짜장을 한 데 섞어 우짜다.\n",
      "  1980년대 항남동 골목길 포장마차에서 우연히 개발한 메뉴가 해장 음식으로 입소문을 타면서 통영 명물로 자리 잡았단다.\n",
      "  처음엔 ‘이게 무슨 조화인가’ 싶지만, 입맛 당기는 마력이 있다.\n",
      "  35년 내력의 ‘항남우짜’에서는 한 그릇에 4500원을 받는다.\n",
      "  해장하려는 손님을 위해 요즘도 새벽 4시까지 문을 연다.\n",
      "   충무김밥의 추억팔도 어디에나 널린 게 김밥집이지만, 김밥거리는 통영에만 있다.\n",
      "  강구안과 중앙시장 사이 통영해안로가 충무김밥거리인데, ‘원조’ ‘할매’ ‘3대’ 등의 문구를 내건 김밥집 17개가 줄줄이 늘어서 있다.\n",
      "   김밥과 반찬을 따로 내는 충무김밥은 81년 5월 서울 여의도광장에서 열린 ‘국풍81’ 행사 때 널리 알려졌다.\n",
      "  강구안에서 밥장사를 하던 어두리 할머니가 행사에서 통영식 김밥을 선보인 뒤 인기가 급부상했다.\n",
      "  당시 통영의 지명이 충무였기에 자연히 ‘충무김밥’으로 세상에 각인됐다.\n",
      "  충무김밥의 역사는 사실 더 뿌리 깊다.\n",
      "  40년대부터 부산~여수를 오가는 승객을 상대로 통영 할매들이 뱃머리에서 팔던 음식이다.\n",
      "  처음엔 김밥 안에 속을 넣어 말았는데 밥이 빨리 상해 버려 김밥 따로 반찬 따로 팔기 시작했단다.\n",
      "  여러 시행착오 끝에 매콤한 양념의 주꾸미(또는 오징어) 무침과, 무섞박지가 김밥의 짝으로 자리 잡았다.\n",
      "  삶은 계란과 사이다가 기차 여행의 필수였듯, 바다로 나설 땐 충무김밥이 먼저였다.\n",
      "  충무김밥은 김밥 8개와 오징어무침‧무섞박지‧시락국(또는 배춧국)이 기본 구성이다.\n",
      "  충무김밥거리에선 1인분에 죄 5500원을 받는다.\n",
      "  가격도, 구성도 비슷하지만 유독 ‘뚱보할매김밥집’에 사람이 많이 몰린다.\n",
      "  충무김밥을 세상에 알린 어두리 할머니가 이 집 창업주다.\n",
      "  꿀빵에는 꿀이 없다 통영을 대표하는 간식은 누가 뭐래도 꿀빵이다.\n",
      "  팥소가 가득 찬 밀가루 빵을 기름에 튀긴 뒤에, 물엿을 입힌 간식 거리다.\n",
      "  꿀빵이지만 ‘꿀’이 들어가지는 않는다.\n",
      "   강구안 앞은 한 집 걸러 김밥집 아니면 꿀빵집이다.\n",
      "  경쟁이 치열하다 보니 요즘은 맛 연구도 활발하다.\n",
      "  팥앙금만 넣는 것이 전통 방식이지만, 요즘은 고구마‧치즈‧딸기‧호박 등 첨가물이 점점 다양해지고 있다.\n",
      "  항남동의 ‘오미사꿀빵’이 통영식 꿀빵의 원조로 통한다.\n",
      " \n",
      "----------------------------------------------------------------------------------------------------\n",
      "idx_3 \n",
      "Summary before \n",
      " 조국 조모(24) 전 법무부 장관을 기소한 검찰의 공소장이 공개되자 2017년\n",
      "Summary after \n",
      " 조국(55) 전 법무부 장관을 기소한 검찰의 공소장이 공개되자 2017년 11월 아들 조모(2)’씨의 연세대 대학원 입학 과정에서 학교 측이 사실상 ‘특혜’가 제공했다는 의혹이 일고‘’ “박 대학원■” ‘한다”고 ‘이 ’”라며\n",
      "Target summary \n",
      " 조국(55) 전 법무부 장관을 기소한 검찰의 공소장이 공개되자 2017년 11월 아들 조모(24)씨의 연세대 대학원 입학 과정에서 학교 측이 사실상 ‘특혜’를 제공했다는 의혹이 일고 있다. 지난달 31일 공개된 검찰 공소장에 적시된 조 전 장관의 혐의 12개 중엔 조씨가 연세대 정치외교학과 대학원에 진학하는 과정에서 대학의 입학사정 업무를 방해한 혐의도 포함됐다.\n",
      "Text 조국(55) 전 법무부 장관을 기소한 검찰의 공소장이 공개되자 2017년 11월 아들 조모(24)씨의 연세대 대학원 입학 과정에서 학교 측이 사실상 ‘특혜’를 제공했다는 의혹이 일고 있다.\n",
      "  ‘온라인 원서를 접수 완료한 뒤엔 변경·취소를 할 수 없다’는 모집 요강과 달리 이미 접수된 원서를 조씨 가족의 요청에 따라 수정했기 때문이다.\n",
      "  조씨가 연세대 대학원에 지원·합격할 당시 조 전 장관은 청와대 민정수석으로 재직 중이었다.\n",
      "  지난달 31일 공개된 검찰 공소장에 적시된 조 전 장관의 혐의 12개 중엔 조씨가 연세대 정치외교학과 대학원에 진학하는 과정에서 대학의 입학사정 업무를 방해한 혐의도 포함됐다.\n",
      "   아들 입학원서, 온라인 접수 완료 뒤 수정 검찰 공소장에 따르면 조 전 장관과 정경심(58‧구속) 동양대 교수는 2018학년도 전기 연세대 대학원 원서 마감일인 2017년 11월 3일 아들이 온라인을 통해 제출한 입학원서의 경력란에 아무런 내용을 기재하지 않고 경력서류도 첨부하지 않은 사실을 알게 됐다.\n",
      "  조 전 장관 부부는 아들과 상의해 경력란을 추가 기재하고, 관련 경력서류를 제출하고자 했다.\n",
      "  하지만 원서 접수 절차를 완료한 상태여서 온라인으로 수정되지 않았다.\n",
      "  부부는 연세대 홈페이지에서 입학원서 양식을 다운받아 경력란에 법무법인 인턴 경력 등을 허위로 기재하고, 이를 학교 측에 제출했다고 검찰은 밝혔다.\n",
      " 모집 요강 \"입력 완료한 온라인 지원서 변경 불가\" 대학가에선 온라인 원서 접수 완료 뒤 수정된 지원서를 연세대 측이 받아들인 과정에 의문을 품고 있다.\n",
      "  조씨가 지원한 2018학년도 연세대 대학원 입학전형 모집요강엔 ‘수험생 유의사항’ 중 하나로 “입력 완료한 온라인 지원서 및 접수 완료된 서류는 변경‧취소할 수 없다”고 명시됐다.\n",
      "   하지만 공소장에 따르면 조 전 장관 부부는 온라인 원서 제출 완료 후 연세대 교학팀에 e메일로 수정된 원서 등을 제출했다.\n",
      "  학교 측은 이를 기초로 서류심사와 구술시험 등을 진행했고 그 결과 조씨가 최종 합격했다.\n",
      "  다른 대학의 입학 업무 종사자들은 연세대의 행위가 특혜 시비에 휘말릴 소지가 있다고 봤다.\n",
      "  모집요강에서 ‘변경·취소할 수 없다’고 못 박았는데도, 예외를 인정하는 건 입시의 전제인 공정성·형평성을 침해한 행위라는 지적이다.\n",
      "  서울 소재 사립대의 한 입학사정관은 “연세대가 다른 학생의 수정 요구도 받아들였는지 의문이다.\n",
      "  만약 조 전 장관의 아들에게만 수정을 허용했다면 특혜 시비를 피하기 어려울 것”이라고 밝혔다.\n",
      " \n",
      "----------------------------------------------------------------------------------------------------\n",
      "idx_4 \n",
      "Summary before \n",
      "  문 문 대통령은 이날 오전 11시 서울 대한 대한 대한 대한 대한상공회의소에서 열린 신년인사\n",
      "Summary after \n",
      "  문 대통령은 이날 오전 11시 서울 대한상공회의소에서 열린 신년인사회의 인사말에서 “어떠한 권력기관도 국민 위에 존재할 수 없다”며 이렇게 밝혔다.\n",
      "권력기관 개혁과 공정사회 개혁이 그 시작 “권권력은기관개혁과공정사회개혁이그 시작”라고 “그\n",
      "Target summary \n",
      " 문 대통령은 이날 오전 11시 서울 대한상공회의소에서 열린 신년인사회의 인사말에서 “어떠한 권력기관도 국민 위에 존재할 수 없다”며 이렇게 밝혔다. 문 대통령의 발언은 연말 고위공직자범죄수사처 관련 법안 통과, 이날 오전 추미애 법무부 장관의 임명 재가 등으로 이어지는 검찰개혁 속도전의 연장선으로 해석된다.\n",
      "Text  문재인 대통령은 2일 “새해에는 더욱 ‘확실한 변화’를 만들어내겠다”며 “권력기관 개혁과 공정사회 개혁이 그 시작”이라고 말했다.\n",
      "  문 대통령은 이날 오전 11시 서울 대한상공회의소에서 열린 신년인사회의 인사말에서 “어떠한 권력기관도 국민 위에 존재할 수 없다”며 이렇게 밝혔다.\n",
      "  문 대통령의 발언은 연말 고위공직자범죄수사처 관련 법안 통과, 이날 오전 추미애 법무부 장관의 임명 재가 등으로 이어지는 검찰개혁 속도전의 연장선으로 해석된다.\n",
      "   문 대통령은 “권력기관이 국민의 신뢰를 받을 수 있을 때까지 법적ㆍ제도적 개혁을 멈추지 않겠다”며 “권력기관 스스로 개혁에 앞장서 주길 기대한다”고 말했다.\n",
      "  특히 문 대통령은 “국민이 선출한 대통령으로서 헌법에 따라 권한을 다 하겠다”고 강조했다.\n",
      "  현직 대통령이 헌법에 따른 ‘의무’가 아니라 ‘권한’을 언급한 것은 드문 일로, 문 대통령이 직접 검찰개혁을 비롯한 권력기관 개편을 진두지휘하겠다는 의지를 드러낸 셈이다.\n",
      "  문 대통령이 새해 첫 대국민 메시지인 신년인사에서 권력기관 개혁을 부각하면서 조만간 검찰에 한바탕 소용돌이가 불어닥칠 가능성이 커졌다.\n",
      "  그 첫 번째 수순은 검사장급 이상 검찰 고위직에 대한 인사권 행사가 될 것으로 보인다.\n",
      "  신년인사회에는 이날 오전 임명이 재가된 추미애 법무부 장관과 윤석열 검찰총장도 참석했기 때문에 문 대통령을 발언을 두고 미묘한 장면이 연출됐다.\n",
      "    공정사회와 관련해 문 대통령은 “우리 정부 출범 이후 대기업집단의 순환출자가 대부분 해소되고 불공정거래 관행이 크게 개선되는 등 공정경제에서 일부 성과가 나타나고 있다”면서도 “교육ㆍ사회ㆍ문화 전반에서 국민 눈높이에 맞는 ‘공정사회 개혁’은 아직 갈 길이 멀다”고 말했다.\n",
      "  문 대통령은 이어 “정부는 같은 기회와 공정한 경쟁을 바라는 국민들, 특히 청년들의 높은 요구를 절감했고 반드시 이에 부응할 것”이라고 말했다.\n",
      "  그러면서 “공정사회 없이는 상생 도약도 없다는 각오로 교육과 채용에서 탈세ㆍ병역ㆍ직장에 이르기까지 우리 삶의 모든 영역에 존재하는 불공정을 개선하겠다”고 강조했다.\n",
      "   그간 문재인 정부가 최대 업적으로 자랑해 온 북한과의 관계 재설정에 대해서는 “한반도 평화를 위한 우리 국민의 열망으로 반드시 ‘상생 번영의 평화공동체’를 이뤄낼 것”이라며 “지난해에도 우리는 국제사회와 보조를 맞추며, 한반도 평화를 향해 조금씩 앞으로 나아갔고, 북미 정상 간의 대화 의지도 지속되고 있다”고만 말했다.\n",
      " \n",
      "----------------------------------------------------------------------------------------------------\n",
      "idx_5 \n",
      "Summary before \n",
      "  물가가 너무 낮아 ‘디플레이션’을 걱정하는 목소리가 나온다.\n",
      "  소비자 입장에선 전혀\n",
      "Summary after \n",
      " 지난해 소비자 물가 상승률은 전년 대비 0 4% 작년 소비자물가 상승률이 전년대비 0.\n",
      " 4 지난해 2011년 아우성 워 ‘ ‘아 ‘이 모두샌 다 ‘신)’ ‘201만 ‘한’〈 ‘제\n",
      "Target summary \n",
      " 통계청이 발표하는 소비자물가지수는 소비 비중이 큰 460개 품목을 골라 이들의 물가를 지수화한 뒤 가격 변동을 월별로, 연도별로 산출한다. 소비 생활에 미치는 영향을 따져 각각에 가중치를 둔다. 가중치가 가장 큰 건 전세다. 그다음이 월세로 44. 8이다. 물가 산정 과정에서 전ㆍ월세가 차지하는 비중이 9%를 넘는다.\n",
      "Text 지난해 소비자 물가 상승률은 전년 대비 0.\n",
      " 4%다.\n",
      "  사상 최저 수준이다.\n",
      "  물가가 너무 낮아 ‘디플레이션’을 걱정하는 목소리가 나온다.\n",
      "  소비자 입장에선 전혀 와 닿지 않는다.\n",
      "  공식 물가는 끝 모르게 떨어지는데, 소비자는 “월급 빼고 다 오른다”고 아우성이다.\n",
      "  이런 지표 물가와 체감 물가 간의 간극은 왜 생기는 걸까? 물가 가중치 전세는 48.\n",
      " 9, 배는 0.\n",
      " 8 해답의 실마리는 ‘가중치’에서 찾을 수 있다.\n",
      "  통계청이 발표하는 소비자물가지수는 소비 비중이 큰 460개 품목을 골라 이들의 물가를 지수화한 뒤 가격 변동을 월별로, 연도별로 산출한다.\n",
      "  그런데 이를 단순 평균하는 게 아니다.\n",
      "  소비 생활에 미치는 영향을 따져 각각에 가중치를 둔다.\n",
      "   가중치가 가장 큰 건 전세다.\n",
      "  총합 1000중 48.\n",
      " 9에 이른다.\n",
      "  그다음이 월세로 44.\n",
      " 8이다.\n",
      "  물가 산정 과정에서 전ㆍ월세가 차지하는 비중이 9%를 넘는다.\n",
      "  휴대전화료(36.\n",
      " 1), 휘발유(23.\n",
      " 4), 공동주택관리비(19)에도 높은 가중치가 매겨진다.\n",
      "  그런데 가중치가 높은 품목의 물가 상승률이 높지 않다.\n",
      "  되려 떨어진 것도 많다.\n",
      "  지난해 가중치 상위 10개 품목 중 3개, 20개 품목 중 10개의 물가지수가 1년 전 보다 떨어졌다.\n",
      "  가중치 1위인 전세는 0.\n",
      " 2% 오르는 데 그쳤다.\n",
      "  월세는 0.\n",
      " 4% 떨어졌다.\n",
      "  가중치가 10이 넘는 휴대전화료(-3.\n",
      " 3%), 휘발유(-7.\n",
      " 1%), 경유(-3.\n",
      " 9%), 해외단체여행비(-1.\n",
      " 6%)의 물가지수도 하락했다.\n",
      "  1년에 한 번 지출하는 전셋값이 안정되고, 한 달에 한 번 내지만 가격은 계약 기간 내내 변동이 없는 월세, 휴대전화료가 떨어졌다고 물가 하락을 크게 체감하긴 어렵다.\n",
      "   반면 지난해 물가가 많이 오른 품목의 가중치는 대체로 낮다.\n",
      "  지난해 물가지수가 가장 많이 오른 3개 품목은 생강(61.\n",
      " 6%), 배(28.\n",
      " 1%), 현미(16.\n",
      " 1%)다.\n",
      "  그런데 이들 품목의 가중치는 생강 0.\n",
      " 1, 배 0.\n",
      " 8, 현미 0.\n",
      " 7로 물가상승률에 미치는 영향이 극히 적다.\n",
      "  지난해 가장 많이 오른 물가 품목 20개 중 가중치가 가장 높은 게 쌀인데, 4.\n",
      " 3에 그친다.\n",
      "  많이 오른 품목 중 가중치 3을 넘기는 것도 쌀과 함께 택시료(3.\n",
      " 5), 한방약(3.\n",
      " 1)뿐이다.\n",
      "  마트에서 자주 사는 먹거리나 택시 가격이 많이 올랐으니 서민의 ‘물가 고통’은 크다.\n",
      " \n",
      "----------------------------------------------------------------------------------------------------\n",
      "idx_6 \n",
      "Summary before \n",
      " 대충 어디에나 어울리는 한국인의 단백질  도저히 어울리지 않을 것 같은 곳에도\n",
      "Summary after \n",
      " 김치찌개에서부터 김밥에 라면에 부침개에, 심지어 밥에 비벼 먹는다는 사람도 있다.\n",
      "   ‘동원’하면 떠오르는 것은 단연 참치 ‘ ‘아 또한하기에 모두워만시장의도’, ‘이 ‘제\n",
      "Target summary \n",
      " 동원그룹 창업주인 김재철 명예회장은 1980년대 초 참치캔 개발에 착수했다. 우리 식문화에 어울릴 수 있도록 기름기가 들어간 살코기 참치캔 개발에 돌입했다. 면실유를 듬뿍 담은 국내 첫 참치 캔 탄생 배경이다. 동원참치 살코기캔은 1982년 12월 국내 첫 출시 이후 37년 동안 한국인의 식탁을 지켰다.\n",
      "Text 대충 어디에나 어울리는 한국인의 단백질  도저히 어울리지 않을 것 같은 곳에도 막상 넣으면, 또 잘 어울린다.\n",
      "  김치찌개에서부터 김밥에 라면에 부침개에, 심지어 밥에 비벼 먹는다는 사람도 있다.\n",
      "  ‘동원’하면 떠오르는 것은 단연 참치.\n",
      "  이름이 동원이란 이유 만으로 자타공인 미남 배우 강동원의 별명까지 ‘강참치’로 만들어버렸다.\n",
      "      동원참치 살코기캔은 1982년 12월 국내 첫 출시 이후 37년 동안 한국인의 식탁을 지켰다.\n",
      "  지난 2014년에는 통조림 업계 최초로 총 누적 판매량 50억캔을 돌파했고, 2018년 말까지 62억 캔이 팔렸다.\n",
      "  국민(5100만명 기준)이 1인당 121.\n",
      " 6개를 먹었다.\n",
      "  한 해 2억 캔이 팔린다.\n",
      "  한국인 1인당 1년에 최소 4캔은 먹게 된다는 계산이다.\n",
      "  동원참치 62억 캔은 일렬로 늘어놓으면 지구를 약 13.\n",
      " 2바퀴(약 50만km) 돌 수 있는 거리가 되며, 수직으로 쌓아 올리면 에베레스트 산(8,848m)의 약 2만8000배 높이가 되는 수량이다.\n",
      "  매년 국내에서만 4500억원어치가 팔린다.\n",
      "  도대체 우린 왜 이렇게 참치를 많이 먹게 됐을까.\n",
      "    동원그룹 창업주인 김재철 명예회장은 1980년대 초 참치캔 개발에 착수했다.\n",
      "  참치캔은 국민소득 2000달러 이상 국가에서만 팔리는 고급 식품이다.\n",
      "  미국에서는 수산 캔이라 하면, 투나 캔(Tuna Can)을 떠올릴 만큼 참치캔이 보편화해 있었지만, 한국에선 당시 꽁치 캔, 고등어 캔 정도가 보급돼 있었다.\n",
      "   동원이 참치캔 개발에 들어간 81년 당시 1인당 국민소득이 1200~1300달러 수준이었다.\n",
      "  김 명예회장은 2000달러 시대가 곧 오고, 고로 참치캔의 시대도 열릴 것이라고 믿었다.\n",
      "  우리 식문화에 어울릴 수 있도록 기름기가 들어간 살코기 참치캔 개발에 돌입했다.\n",
      "  면실유를 듬뿍 담은 국내 첫 참치 캔 탄생 배경이다.\n",
      "    소득 1200달러 시대, ‘살코기’ 강조해 인기동원은 그야말로 캔 하나로 국민기업 반열에 올랐다.\n",
      "  69년 창업 후 원양에서 참치를 잡아 미국이나 일본 등 선진국에 참치를 수출하는 사업을 운영하던 동원산업은 캔을 내기 전까지는 일반 소비자에겐 무명의 기업이었다.\n",
      "  참치캔 출시로 종합식품회사로 도약하는 발판을 마련했다.\n",
      "  살코기캔의 성공으로 금융업, 물류업, 종합포장재 산업 등으로 사업을 확장했다.\n",
      "  현재 연 매출 7조2000억원 규모의 생활산업 기업집단으로 성장을 이뤘다.\n",
      " \n",
      "----------------------------------------------------------------------------------------------------\n",
      "idx_7 \n",
      "Summary before \n",
      " \n",
      "Summary after \n",
      "   하지만 이런 결과는 현대차그룹이 미래 시장 리더십 확보에 주력하면서 ‘양보다 질보다질 8 9 모두 하지만 2011년 그래서마저 그런데들까지 경우도 또한 답변만 문화체육관광 방송통신 반면에한다”고 부진한들도9년\n",
      "Target summary \n",
      " 현대·기아차의 2019년 국내·국외 합산 판매량이 719만3337대로 전년 대비 2. 8% 감소한 것으로 나타났다. 해외의 경우 미·중 무역갈등 등으로 인한 중국 등 신흥시장 판매 부진이 영향을 미쳤다. 하지만 이런 결과는 현대차그룹이 미래 시장 리더십 확보에 주력하면서 ‘양보다 질’을 선택한 때문이라는 평가가 나온다. 무리한 판매목표치 달성보다 수익성 강화를 중시했다는 얘기다.\n",
      "Text 현대·기아차의 2019년 국내·국외 합산 판매량이 719만3337대로 전년 대비 2.\n",
      " 8% 감소한 것으로 나타났다.\n",
      "  지난해 초 제시한 판매목표 760만대보다도 약 41만대 적다.\n",
      "   하지만 이런 결과는 현대차그룹이 미래 시장 리더십 확보에 주력하면서 ‘양보다 질’을 선택한 때문이라는 평가가 나온다.\n",
      "  무리한 판매목표치 달성보다 수익성 강화를 중시했다는 얘기다.\n",
      "  현대차는 지난해 국내 74만1842대, 해외 368만802대 등 총 442만2644대를 판매했다.\n",
      "  국내 판매는 2.\n",
      " 9% 증가했고, 해외 판매는 4.\n",
      " 8% 감소했다.\n",
      "  해외의 경우 미·중 무역갈등 등으로 인한 중국 등 신흥시장 판매 부진이 영향을 미쳤다.\n",
      "  투싼이 글로벌 67만2141대가 팔리며 최다 판매 차종에 올랐다.\n",
      "  이어 아반떼 55만8255대, 코나 30만7152대, 싼타페 27만4025대 순이었다.\n",
      "    세단의 경우 그랜저가 10만3349대(하이브리드 모델 2만9708대 포함) 팔리며 국내 판매를 이끌었고, 쏘나타가 10만3대(하이브리드 모델 7666대 포함), 아반떼가 6만2104대 등 총 27만9242대 판매를 기록했다.\n",
      "  특히 쏘나타와 그랜저를 합쳐 연간 10만대 판매를 돌파하며 지난 2015년 아반떼와 쏘나타가 달성했던 연간 10만대 판매 동반 돌파를 4년 만에 달성했다.\n",
      "  올해 실적을 보면 북미 지역 판매가 스포츠유틸리티차량(SUV)을 중심으로 늘었고 판매촉진비 절감, 악성 재고 감소로 수익은 강화하는 모습이다.\n",
      "    기아차는 지난해 국내 52만205대, 해외 225만488대 등 총 277만693대를 판매했다.\n",
      "  국내 판매는 전년 대비 2.\n",
      " 2% 줄어든 52만205대를 기록했다.\n",
      "  수출 실적은 중국시장 부진으로 전년보다 1.\n",
      " 3% 감소한 225만488대를 기록했다.\n",
      "      기아차 관계자는 “감소세로 전환했으나 권역별 책임경영 체제를 강화하고 공격적 신차를 출시하는 전략을 통해 중국을 제외한 북미·유럽·인도·중동 등 주요 시장에서 판매가 늘었다”고 설명했다.\n",
      "  실제로 중국을 제외한 기아차 해외판매는 전년 대비 4.\n",
      " 3% 증가한 199만2488대로 나타났다.\n",
      "  정의선 현대차그룹 수석부회장은 지난해 10월 타운홀 미팅에서 “전 세계적으로 자동차 시장이 2500만대 공급과잉이다.\n",
      "  미래 자동차 업계에서 사라지는 회사가 많아질 것”이라며 양적 성과에 연연하지 않겠다는 입장을 밝혔다.\n",
      "   실제로 현대차그룹은 과거 ‘연말 물량 밀어내기’ 등으로 목표치 달성에 안간힘을 쓰던 관행을 버렸다.\n",
      " \n",
      "----------------------------------------------------------------------------------------------------\n",
      "idx_8 \n",
      "Summary before \n",
      " [ [ 경제석학 진단 2] 대니 로드릭 하버드대 케네디\n",
      "Summary after \n",
      " 대니 로드릭 하버드대 케네디스쿨 국제정치경제학과 교수 “부자 나라의 가난한 사람과 가난한 나라의 부자 중 어느 쪽이 되고 싶나 “어 경제를 ’ ‘제 ‘ ‘이 “‘ ‘한 ‘무 “ “박‘ 〈 “그 “한국\n",
      "Target summary \n",
      " 대니 로드릭 하버드대 케네디스쿨 국제정치경제학과 교수 “부자 나라의 가난한 사람과 가난한 나라의 부자 중 어느 쪽이 되고 싶나?” 대니 로드릭(62) 하버드대 케네디스쿨 국제정치경제학과 교수가 가을 학기 첫 수업에서 농담 반 진담 반으로 던지는 질문이다. 학생들은 대부분 후자를 고른다. 가난한 나라의 부자라면 하인을 여럿 두고 호화로운 자동차가 즐비한 저택에 사는 거물을 상상하기 때문이다.\n",
      "Text [세계 경제석학 진단 ②] 대니 로드릭 하버드대 케네디스쿨 국제정치경제학과 교수 “부자 나라의 가난한 사람과 가난한 나라의 부자 중 어느 쪽이 되고 싶나?”   대니 로드릭(62) 하버드대 케네디스쿨 국제정치경제학과 교수가 가을 학기 첫 수업에서 농담 반 진담 반으로 던지는 질문이다.\n",
      "  학생들은 대부분 후자를 고른다.\n",
      "  가난한 나라의 부자라면 하인을 여럿 두고 호화로운 자동차가 즐비한 저택에 사는 거물을 상상하기 때문이다.\n",
      "      그렇다면 둘 중 소득은 누가 더 많을까.\n",
      "  통상 잘사는 나라의 하위 5%는 국민소득의 1%만을 가져간다.\n",
      "  가난한 나라에 대한 자료는 많지 않지만, 최상위 5%가 국민소득의 25%를 가져간다고 가정해 볼 수 있다.\n",
      "  전형적인 부국인 스위스·노르웨이 등의 1인당 국내총생산(GDP)는 6만5000달러, 라이베리아 등 전형적인 빈국의 1인당 GDP는 약 1000달러다.\n",
      "  그렇다면 부국의 빈곤층 소득은 1만3000달러(6만5000달러x0.\n",
      " 01x20), 빈국의 부자 소득은 5000달러(1000달러x0.\n",
      " 25x20)로 계산된다.\n",
      "  스위스 빈곤층이 라이베리아 부유층보다 두세 배 소득이 많다는 얘기다.\n",
      "    노벨경제학상 수상 후보로 거론되는 로드릭 교수는 ‘세계화 및 경제발전 이론’의 대가다.\n",
      "  그는 2010년 저서 『자본주의 새판짜기』(원제:The globalization paradox)에서 ‘세계화·민주주의·국민국가’의 세 마리 토끼를 동시에 잡을 수 없다고 했다.\n",
      "  미국 동부 케임브리지의 하버드대 케네디스쿨 루벤스타인 건물 3층 연구실에서 로드릭 교수를 만났다.\n",
      "  문 앞에는 그가 설립한 정책 연구소인 ‘포괄적 번영을 위한 경제학(EfIP)’의 포스터가 붙어있었다.\n",
      "  약속한 시간에 정확히 맞춰 나타난 로드릭 교수는 시종일관 진지하고 차분한 어조로 인터뷰에 응했다.\n",
      "  터키에서 태어난 유대인인 그에게 ‘한국과 터키는 형제의 나라인걸 아느냐’고 물으니 ‘들어본 것 같다’며 겸연쩍게 웃었다    첫 수업에서 학생에게 던지는 질문이 흥미롭다.\n",
      "   =“국가 내 불평등만큼 국가 간의 불평등도 중요한 이슈라는 점을 강조하기 위해서다.\n",
      "  하지만 빈국의 생활 수준이 높아지면서 선진국 중산층이 상대적으로 박탈감을 느끼기 시작했다.\n",
      "  도널드 트럼프 미국 대통령, 보리스 존슨 영국 총리 등 선진국에서 포퓰리즘과 민족주의가 부상한 이유도 여기에 있다.\n",
      "  결국 ‘내 나라만 잘 먹고 잘살게 하겠다’고 외치는 지도자를 뽑는 거다.\n",
      " \n",
      "----------------------------------------------------------------------------------------------------\n",
      "idx_9 \n",
      "Summary before \n",
      " 올해 올해 올해포인트, 8월 0.\n",
      " 11포인트, 8월 0.\n",
      " 11포인트 하락하며\n",
      "Summary after \n",
      " 부진이 바닥을 찍었다는 찍었다고 기대경기 부진은 바닥이 찍렸다는 찍었다 기대 경기 부진을 바닥를 찍 했다는 찍 않았다는 찍이었다는 찍했다는 증가 기대 답변 모두워 장관 감염 6월 7월 하락 가장바닥 기간 이진 코\n",
      "Target summary \n",
      " 교역량이 일부 회복되겠지만 미국과 중국이 무역갈등을 겪기 이전 수준으로 돌아가기는 어렵다는 예상이 지배적이다. 3단계까지 협상이 진행될 것으로 예상되는 상황에서 이제 겨우 첫 단계에 발을 떼고 있는 상황인데도 긴장감이 여전하다. 더구나 지금까지 도널드 트럼프 미국 대통령의 행보를 볼 때 언제 갈등이 다시 심화될지 모르는 상황이다.\n",
      "Text  한국 CLI는 2019년 5월 전월 대비 0.\n",
      " 14포인트나 하락했지만, 6월에는 0.\n",
      " 13포인트, 7월 0.\n",
      " 12포인트, 8월 0.\n",
      " 11포인트 하락하며 하락폭이 지속적으로 줄어드는 모습이다.\n",
      "   미·중 무역갈등 완화에 교역량 증가 기대경기 부진이 바닥을 찍었다는 신호는 기업과 소비자 심리지표에서도 나타난다.\n",
      "  한국은행에 따르면 2019년 11월 소비자심리지수(CCSI)는 100.\n",
      " 9로 집계됐다.\n",
      "  CCSI는 국내 가계의 현재 생활형편, 가계수입전망, 생활형편전망, 소비지출전망, 현재 경기판단, 향후 경기전망 등 6개 지표를 수치화한 것으로 100을 넘으면 소비심리가 긍정적이라고 해석한다.\n",
      "  국내 제조업 업황실적 기업경기실사지수(BSI)도 2019년 8월 68을 기록한 후 석달 연속 상승해 74를 기록했다.\n",
      "  BSI는 기업들의 경기 판단을 나타내는 지수로 100을 넘으면 체감경기를 부정적으로 느끼는 기업보다 긍정적으로 보는 기업이 더 많다는 것을 의미한다.\n",
      "  2019년 한국 경제의 발목을 잡았던 미·중 무역갈등이 완화 국면을 맞이하고 있다는 점도 긍정적 요소다.\n",
      "  2018년 미국의 중국산 수입품 관세 부과로 전면전에 돌입한 미·중 무역갈등은 2019년에도 파열음을 냈다.\n",
      "  긴장감을 이어가던 양국은 2019년 9월 재협상에 들어갔고 10월에는 1단계 스몰딜 합의가 임박했다는 소식이 나오면서 완화 국면에 들어갔다.\n",
      "  결국 12월에 1단계 합의에 이르렀다.\n",
      "  IMF는 2020년 세계 교역량이 전년 대비 3.\n",
      " 2% 늘어날 것으로 예상하고 있다.\n",
      "  2019년 1.\n",
      " 1% 증가에 그쳤지만 바닥을 치고 2.\n",
      " 1%포인트 늘어날 것이란 전망이다.\n",
      "  동시에 세계 경제성장률은 3.\n",
      " 4%로 예상해 전년 대비 0.\n",
      " 4%포인트 높아질 것으로 봤다.\n",
      "  세계무역기구(WTO)도 2020년 세계 교역 성장률이 3%에 이를 것으로 내다봤다.\n",
      "  2019년 1.\n",
      " 2%에 비해 1.\n",
      " 8%포인트 높아질 것이란 예상이다.\n",
      "  긍정적 전망에도 한계는 있다.\n",
      "  교역량이 일부 회복되겠지만 미국과 중국이 무역갈등을 겪기 이전 수준으로 돌아가기는 어렵다는 예상이 지배적이다.\n",
      "  3단계까지 협상이 진행될 것으로 예상되는 상황에서 이제 겨우 첫 단계에 발을 떼고 있는 상황인데도 긴장감이 여전하다.\n",
      "  더구나 지금까지 도널드 트럼프 미국 대통령의 행보를 볼 때 언제 갈등이 다시 심화될지 모르는 상황이다.\n",
      "  실제로 트럼프 대통령은 2019년 12월 중국과의 합의가 미국 대선 이후로 미뤄질 수 있다는 언급을 내놓으면서 미·중 갈등이 다시 부각되기도 했다.\n",
      " \n",
      "----------------------------------------------------------------------------------------------------\n",
      "idx_10 \n",
      "Summary before \n",
      " 로스 곤 전 닛산자동차 회장이 레바논으로 도주한지 나흘이 지났지만\n",
      "Summary after \n",
      " 카를로스 곤 전 닛산자동차 회장이 레바논으로 도주한지 나흘이 지났지만 그의 출국 경위에 대한 미스터리는 여전히 풀리지 않고 있다.\n",
      "  카을로스곤 전 한 카를 로스 곤전 요타산 자동차 회장이레바논을 도망한 지 나흘을 지났\n",
      "Target summary \n",
      " 카를로스 곤 전 닛산자동차 회장이 레바논으로 도주한지 나흘이 지났지만 그의 출국 경위에 대한 미스터리는 여전히 풀리지 않고 있다. 따라서 일본 경찰은 곤이 별도의 장소에서 누군가와 합류해 공항으로 향했을 가능성이 있다고 보고 수사를 진행하고 있다. 곤은 “캐롤이나 가족이 일본을 출국하기 위해 역할을 했다는 미디어의 억측이 있었으나 모두 부정확하며 거짓말이다. 나 혼자서 출국 준비를했다. 가족은 어떤 역할도 하지 않았다”고 밝혔다.\n",
      "Text 카를로스 곤 전 닛산자동차 회장이 레바논으로 도주한지 나흘이 지났지만 그의 출국 경위에 대한 미스터리는 여전히 풀리지 않고 있다.\n",
      "  3일 NHK에 따르면 곤은 지난달 29일 낮 도쿄 미나토구의 집에서 혼자 외출하는 모습이 집에 설치된 CCTV 카메라에 포착됐다.\n",
      "  이 시간대에 수상한 사람이 집을 드나든 흔적은 없었으며, 그 뒤로 곤이 귀가한 모습은 확인되지 않았다.\n",
      "   따라서 일본 경찰은 곤이 별도의 장소에서 누군가와 합류해 공항으로 향했을 가능성이 있다고 보고 수사를 진행하고 있다.\n",
      "     경찰이 확보한 정황대로라면, 곤이 악기 상자에 몸을 숨겨 집 밖으로 나왔다는 그동안의 언론 보도는 사실이 아닐 가능성이 있다.\n",
      "  실제 곤의 부인 캐롤은 2일 로이터통신에 일부 레바논 언론이 “악기 보관용 상자에 숨어서 출국했다”고 보도한데 대해 “날조”라고 주장했다.\n",
      "  곤은 3일 오전 미국의 공보담당자를 통해 성명을 내고, 자신이 레바논으로 입국하는 과정에 부인 캐롤이 주도적인 역할을 했다는 일부 언론 보도 내용을 부인했다.\n",
      "  곤은 “캐롤이나 가족이 일본을 출국하기 위해 역할을 했다는 미디어의 억측이 있었으나 모두 부정확하며 거짓말이다.\n",
      "  나 혼자서 출국 준비를했다.\n",
      "  가족은 어떤 역할도 하지 않았다”고 밝혔다.\n",
      "   월스트리트저널(WSJ)에 따르면 캐롤이 곤과 합류한 것은 레바논인 것으로 전해졌다.\n",
      "  캐롤은 WSJ 취재진에게 “(부부의 재회는) 인생 최고의 선물”이라는 문자 메시지를 보내왔다고 한다.\n",
      "  곤은 프랑스, 브라질, 미국 등으로 도주하는 것도 검토했으나 “보다 우호적인 법적 환경”을 갖춘 레바논에서 재판을 받는 방안을 모색해왔다.\n",
      "  곤은 브라질에서 태어나 레바논, 프랑스에서 교육을 받았으며 기독교 마론파다.\n",
      "   르몽드에 따르면 레바논행을 택한 건 부인 캐롤의 영향도 컸을 것으로 전해진다.\n",
      "  캐롤의 모친이 레바논 북부 출신의 남성과 재혼해, 이슬람교 수니파의 친인척이 여럿 있기 때문에 수니파가 많은 터키와 “상당히 좋은 관계”인 친인척들이 도주 계획을 지원해줬을 가능성이 있다는 것이다.\n",
      "   프랑스 공영방송인 ‘프랑스2’는 레바논의 수도 베이루트에서 찍힌 곤 부부의 사진을 내보냈다고 NHK가 보도했다.\n",
      "  사진에는 곤과 캐롤이 와인병이 놓인 테이블 앞에서 여유로운 시간을 보내고 있는 모습이 찍혔다.\n",
      "  프랑스2는 “사진은 지난달 31일 레바논에서 곤의 가족들이 저녁식사 모습이다.\n",
      "  곤 가족의 친구가 촬영한 것”이라고 전했다.\n",
      " \n",
      "----------------------------------------------------------------------------------------------------\n",
      "idx_11 \n",
      "Summary before \n",
      " 알래래스카 우트키아비크 ‘하얀 사막’.\n",
      "  인천공항\n",
      "Summary after \n",
      " 9 알래스카 최북단 우트키아비크의 첫 인상  해발 고도가 3m에에 3 m에 도착한 곳 워 모두아웠 김 김유”,얀 ‘아 아 비 이탈리아다”, 세 갈아\n",
      "Target summary \n",
      " 우트키아비크는 이곳 원주민 이누피앗의 말로 ‘흰올빼미 사냥터’라는 뜻이지만, 오랫동안 영어식 도시명인 ‘배로우’로 불렸다 이곳 원주민들은 1000년 넘게 이어온 그들의 생존 방식인 북극곰과 고래사냥이 왜 타지사람이나 국제규범 등 외부의 힘에 의해 의사결정이 이루어지는지에 대해 쉽게 수긍하지 못하고 있었고 그 권리를 되찾기 위해 노력하고 있었다.\n",
      "Text  ⑨ 알래스카 우트키아비크 ‘하얀 사막’.\n",
      "  인천공항에서 시애틀, 다시 앵커리지를 거쳐 도착한 곳, 비행기를 세 번 갈아타고서야 도착한 미국 알래스카 최북단 우트키아비크의 첫 인상이었다.\n",
      "  해발 고도가 3m에 불과한 드넓은 평원은 얼음과 눈으로 덮혀 있었다.\n",
      "  영하 23도 체감온도 영하 37도.\n",
      "  2016년 3월 알래스카 북쪽 꼭대기 첫 마을 우트키아비크와의 첫 인사는 겨울 끝자락의 매서운 추위였다.\n",
      "  얼어붙은 활주로를 벗어나 시내에 들어가자 낮 시간임에도 불구하고 간간이 지나가는 트럭과 스노우모빌을 제외하고는 인적을 찾아보기 어려웠다.\n",
      "    우트키아비크는 이곳 원주민 이누피앗의 말로  ‘흰올빼미 사냥터’라는 뜻이지만, 오랫동안 영어식 도시명인 ‘배로우’로 불렸다.\n",
      "  19세기초 이곳을 탐험했던 영국의 해군상이자 탐험가인 존 배로우의 이름을 땄다.\n",
      "  2016년 12월에 들어서야 주민들은 투표를 통해 자신들이 부르던 옛 이름인 우트키아비크를 되찾았다.\n",
      "  이 곳 사람들은 이것이 진정한 자치권 쟁취를 위한 노력의 일환이라고 한다.\n",
      "   천년 넘게 고래와 함께 살아온 마을 오후 6시반, 하얀 사막 너머로 붉은 해가 사라졌다.\n",
      "  지난 1월 중순까지만 하더라도 한달여 이상 24시간 밤만 계속되던 극야(極夜)의 동토다.\n",
      "  시간이 흐르고, 하늘이 흑막으로 뒤덮이자 잊을 수 없는 장관이 펼쳐졌다.\n",
      "  오로라.\n",
      "  녹색의 커튼이 밤하늘에 일렁였다.\n",
      "  아이러니하게도 이방인인 우리에게는 아름답기 그지없는 오로라를 이곳 사람들은 그렇게 생각하지 않았다.\n",
      "  북극곰과 고래ㆍ물개 등 이곳 사람들이 생존을 위해 잡아먹었던 동물들의 영혼들이 떠돌아다니는 것이라고 한다 9세기부터 사람이 살기 시작한 우트키아비크의 주변 바다인 축치해는 북극해에서 가장 오래된 고래 사냥터이기도 하다.\n",
      "  나의 친구인 알래스카 환이누잇위원회(ICC) 의장 짐 스토츠는 고향인 우트키아비크에 올 때면 친척들이 마련해준 고래고기를 소중히 받고 어린아이처럼 즐거워한다.\n",
      "  이곳 원주민들은 1000년 넘게 이어온 그들의 생존 방식인 북극곰과 고래사냥이 왜 타지사람이나 국제규범 등 외부의 힘에 의해 의사결정이 이루어지는지에 대해 쉽게 수긍하지 못하고 있었고 그 권리를 되찾기 위해 노력하고 있었다.\n",
      "  자신들은 꼭 필요한 사냥만을 하늘에 감사하며 해왔으며 그 동물들의 멸종위기는 자신들의 탓이 아니라고 생각하기 때문이다.\n",
      "  고래사냥의 흔적은 마을 여기저기서 볼 수 있다.\n",
      " \n",
      "----------------------------------------------------------------------------------------------------\n",
      "idx_12 \n",
      "Summary before \n",
      "  퇴행성 관절염 말기로 무릎 연골이 모두 닳으면 통증이\n",
      "Summary after \n",
      " 활기찬 노년은 건강한 무릎에서 시작된  퇴행성 관절염 말기로 무릎 연골이 모두 닳으면 통증이 심해져 두 다리로 걷기 어려워지며 인공관절 수술 활 기찬노년에서 닳 무릎 관절어야 또한\n",
      "Target summary \n",
      " 퇴행성 관절염 말기로 무릎 연골이 모두 닳으면 통증이 심해져 두 다리로 걷기 어려워진다. 망가진 무릎관절을 깎아낸 뒤 이를 대체할 인공관절을 끼워 넣어야 한다. 연세사랑병원은 3D프린터로 자신의 무릎 상태에 맞춘 인공관절 수술 도구를 출력해 수술 정확성을 높이는 방식으로 치료한다. 3D프린터 맞춤형 인공관절 수술이다.\n",
      "Text  맞춤형 무릎 인공관절 수술 활기찬 노년은 건강한 무릎에서 시작된다.\n",
      "  퇴행성 관절염 말기로 무릎 연골이 모두 닳으면 통증이 심해져 두 다리로 걷기 어려워진다.\n",
      "  망가진 무릎관절을 깎아낸 뒤 이를 대체할 인공관절을 끼워 넣어야 한다.\n",
      "  연세사랑병원은 3D프린터로 자신의 무릎 상태에 맞춘 인공관절 수술 도구를 출력해 수술 정확성을 높이는 방식으로 치료한다.\n",
      "  3D프린터 맞춤형 인공관절 수술이다.\n",
      "  체형에 따라 옷을 맞춰 입듯이 환자의 무릎 크기·생김새·손상도 등을 종합적으로 반영해 무릎의 운동성을 복원한다.\n",
      "   무릎 인공관절 수술은 정확도가 생명이다.\n",
      "  인체 해부학적으로 정면·측면에서 봤을 때 엉덩이뼈인 고관절과 무릎·발목의 중심을 잇는 축이 정확하게 맞아야 한다.\n",
      "  이뿐이 아니다.\n",
      "  무릎을 구부리고 펴면서 움직일 때마다 바뀌는 운동 역학적인 회전축도 고려해야 한다.\n",
      "  연세사랑병원 고용곤 병원장은 “3D프린터 기술을 활용하면 무릎 인공관절을 보다 정교하게 삽입할 수 있다”고 말했다.\n",
      "  기존 해부학적 각도만 고려해 일괄적으로 어느 부위를 절삭할지 결정하는 방식보다 한 단계 진보한 수술법이다.\n",
      "  국내에서는 연세사랑병원이 3D프린터 맞춤형 무릎 인공관절 수술을 처음 도입하면서 긍정적인 성과를 내고 있다.\n",
      "   연세사랑병원에서 시행하는 3D프린터 맞춤형 인공관절 수술은 3D시뮬레이션·3D프린팅 같은 첨단 공학기술이 접목된 치료법이다.\n",
      "  이식한 무릎 인공관절이 편하면서 오래 쓸 수 있도록 엉덩이·무릎·발목으로 이어지는 하체의 정렬 정확도를 높여주는 비결이다.\n",
      "   첨단 공학기술 접목해 정확도 향상 먼저 자기공명영상(MRI)·컴퓨터단층촬영(CT) 영상을 바탕으로 환자의 무릎 상태를 3차원 입체 영상을 구현한다.\n",
      "  그다음 관련 정보를 3D프린터로 전송해 모형으로 출력한다.\n",
      "  이렇게 만든 모형은 닳아 없어진 연골 두께와 모양을 눈으로 정확하게 확인할 수 있다.\n",
      "  이를 통해   ▶어떤 인공관절이 가장 적합한지 ▶무릎관절은 어떻게 절삭할지 ▶엉덩이·무릎·발목 관절 정렬은 어떤 각도로 맞출지 등을 살펴볼 수 있다.\n",
      "  의료진은 가상 수술을 통해 오차 범위를 최소화한 수술 계획을 세울 수 있다.\n",
      "   연세사랑병원에서는 인공관절 수술에 사용하는 수술 도구도 출력·제작한다.\n",
      "  일종의 맞춤형 수술 도구다.\n",
      "  망가진 연골 조직의 위치·각도를 정확하게 측정해 가장 이상적인 위치에 인공관절을 삽입하도록 돕는다.\n",
      " \n",
      "----------------------------------------------------------------------------------------------------\n",
      "idx_13 \n",
      "Summary before \n",
      " 새 새법을 적용하는 맥주와 막걸리다.\n",
      "  새해 첫날부터 바뀐 주세법을\n",
      "Summary after \n",
      " 새해 첫날부터 바뀐 주세법을 적용하는 맥주와 막걸리다.\n",
      "  국세청은 바뀐 법을 적용하면 캔맥주는 1l당 291원, 고급 막걸리다(출고가 1만5000당 주세는법 개정에 술값 얼마나 내릴까 올라도 올해부터 가격 하락이 확실시되는 상품이\n",
      "Target summary \n",
      " 이인우 국세청 소비세과 주세1팀장은 \"주세법 개정으로 수제 맥주와 고급 막걸리의 출고가가 낮아져 소비자 만족도도 높아질 것\"이라고 기대했다. 새해 첫날부터 바뀐 주세법을 적용하는 맥주와 막걸리다. 주류 제조사는 줄어든 세 부담만큼 유통업자·식당 등에 판매하는 술값을 낮출 수 있다. 국세청은 바뀐 법을 적용하면 캔맥주는 1ℓ당 291원, 고급 막걸리(출고가 1만5000원)는 500㎖당 729원의 주세 절감 효과가 있다고 밝혔다.\n",
      "Text 주세법 개정에 술값 얼마나 내릴까 월급 빼고 다 올라도 올해부터 가격 하락이 확실시되는 상품이 있다.\n",
      "  새해 첫날부터 바뀐 주세법을 적용하는 맥주와 막걸리다.\n",
      "  국세청은 바뀐 법을 적용하면 캔맥주는 1ℓ당 291원, 고급 막걸리(출고가 1만5000원)는 500㎖당 729원의 주세 절감 효과가 있다고 밝혔다.\n",
      "  주류 제조사는 줄어든 세 부담만큼 유통업자·식당 등에 판매하는 술값을 낮출 수 있다.\n",
      "  당장 롯데칠성음료는 연초부터 500㎖짜리 클라우드 캔맥주 출고가격을 기존 1880원에서 1565원으로 16.\n",
      " 7% 내렸다.\n",
      "  이인우 국세청 소비세과 주세1팀장은 \"주세법 개정으로 수제 맥주와 고급 막걸리의 출고가가 낮아져 소비자 만족도도 높아질 것\"이라고 기대했다.\n",
      "  수제맥주 '4캔 만원' 시작되나 5일 국세청에 따르면 맥주·막걸리에 붙는 주세를 올해부터 주류 가격 기준(종가세)에서 용량 기준(종량세)으로 바꾼 것은 52년 만이다.\n",
      "  1949년 주세법이 제정될 때는 종량세 체계였지만 박정희 대통령 재임기인 68년부터 주류 소비 억제와 세수 증대를 목적으로 종가세 체계로 바뀌었다.\n",
      "  종가세 체계에선 같은 술이라도 고급 원료, 양질의 주조 공법을 활용해 제품 가격이 오르면 세금도 더 많이 내야 했다.\n",
      "  반면 종량세 기준을 적용하면 가격이 올라도 용량만 같다면 같은 세금을 부과한다.\n",
      "  일반 맥주든 고급 수제 맥주든 같은 세금이 적용되기 때문에 '애주가' 기호에 맞는 다양한 수제 맥주가 싼 가격에 판매될 수 있는 것이다.\n",
      "  도자기 용기에 파는 고급 막걸리의 경우 종가세 체계에선 제품가격에 포함된 용기 비용에도 세금이 부과됐지만, 용량만 따져 세금을 매기면 '도자기값'에는 세금이 붙지 않는다.\n",
      "  국세청 관계자는 \"수제맥주도 '4캔에 만원' 이벤트나 '호리병 막걸리' 등 고급 탁주들이 대중화하는 데 긍정적인 영향을 줄 것\"이라고 관측했다.\n",
      " 국산vs수입 맥주 경쟁에 영향은 세정당국은 또 종량세 도입이 수입 맥주와 국산 맥주 간 '불평등 경쟁'을 해소하는 데 도움을 줄 것으로 내다봤다.\n",
      "  종가세 체계에서 국산 맥주는 제품 출고 시점 가격 기준으로 세금을 매기다 보니 출고가에 반영된 주류 제조원가와 판매관리비, 기업 이윤 등이 모두 과세 대상이 된다.\n",
      "  반면 수입 맥주는 수입 업자가 해외 맥주 제조사로부터 수입한 가격(수입가액)과 관세에만 주세가 붙기 때문에 수입업자의 판매관리비·이윤 등은 과세 대상에서 제외된다.\n",
      " \n",
      "----------------------------------------------------------------------------------------------------\n",
      "idx_14 \n",
      "Summary before \n",
      " 검찰 검찰 인사를 간부 인사를 논의하는 검찰 고위 간부 인사를 논의하는 검찰 고위 간부 인사를 논의\n",
      "Summary after \n",
      " 법무부는 윤 총장과의 상견례 일정을 조율하는 동시에 검찰 고위 간부 인사를 논의하는 검찰인사위원회 일정도 맞춰보고 있다.\n",
      "  워 모두 참고도퀘취를 코위웨이만 잡고위는 관계자는하게 방송통신맛\n",
      "Target summary \n",
      " 추 장관은 이미 후보자 시절부터 검찰 인사의 퍼즐을 맞춰 놓은 것으로 알려졌다. 그런데도 윤 총장과의 대면 상견례를 추진하는 건 공식적이고 합법적인 인사 절차를 밟고 있다는 ‘명분 쌓기용’이라는 게 법조계의 해석이다.  추미애 신임 법무부 장관이 윤석열(사법연수원 23기) 검찰총장과 상견례 직후 검찰 고위 간부 인사를 단행할 것으로 알려졌다.\n",
      "Text 추미애 신임 법무부 장관이 윤석열(사법연수원 23기) 검찰총장과 상견례 직후 검찰 고위 간부 인사를 단행할 것으로 알려졌다.\n",
      "  법무부는 윤 총장과의 상견례 일정을 조율하는 동시에 검찰 고위 간부 인사를 논의하는 검찰인사위원회 일정도 맞춰보고 있다.\n",
      "    추 장관은 이미 후보자 시절부터 검찰 인사의 퍼즐을 맞춰 놓은 것으로 알려졌다.\n",
      "  그런데도 윤 총장과의 대면 상견례를 추진하는 건 공식적이고 합법적인 인사 절차를 밟고 있다는 ‘명분 쌓기용’이라는 게 법조계의 해석이다.\n",
      "    인사 관전 포인트는 윤 총장의 최측근이자 조국 일가 비리, 청와대 하명수사 의혹 수사 책임자들에 대한 인사 조치다.\n",
      "  대검찰청의 한동훈(27기) 반부패강력부장, 박찬호(26기) 공공수사부장, 배성범(23기) 서울중앙지검장의 인사에서 추 장관의 첫 번째 검찰 개혁 메시지를 읽을 수 있다는 게 법조계의 중론이다.\n",
      "    법무부 “추미애·윤석열 조만간 만난다…6일 인사는 힘들 것” 법무부 고위 관계자는 5일 “일부 언론에서 곧 인사가 날 것처럼 보도하는데, 당장 내일(6일) 검찰 인사가 나기는 어려울 것 같다”며 “장관과 검찰총장은 조만간 만날 것”이라고 말했다.\n",
      "  대검 관계자도 “아직 상견례 일정이 잡히진 않았지만, 법무부에서 상견례 얘기가 나온다면 그쪽 이야기가 맞을 것”이라며 “법무부 장관은 통상 절차에 따라 검찰 인사 전 검찰총장을 직접 만나왔다”고 말했다.\n",
      "    법무부가 추 장관과 윤 총장의 상견례를 추진하는 건 검찰 인사상의 절차를 지키기 위해서다.\n",
      "  검찰청법 34조 1항은 검사 인사와 관련해 법무부 장관이 검찰총장의 의견을 듣도록 하고 있다.\n",
      "  물론 직접 대면하지 않고 인사 실무를 총괄하는 법무부 검찰국장이 추 장관의 의견을 윤 총장에게 전달하는 방식도 가능하다.\n",
      "  상견례가 진행돼도 이는 병행될 수 있다.\n",
      "  다만 법무부가 ‘법령이 정한 절차’를 강조하고 있는 만큼 대외적 명분을 위해 직접 만남을 추진하고 있다는 게 법조계의 해석이다.\n",
      "    법조계의 한 관계자는 “둘의 만남 전에 실무 작업이 끝나 상견례 자리에서 인사 관련 이야기가 직접적으로 나오지는 않겠지만, 대외적으로 검찰총장의 의견을 듣고 있다는 모습을 보여주는 자리가 될 것”이라고 말했다.\n",
      "  법무부는 동시에 조만간 검찰인사위원회를 열고 검사장급 이상 고위 간부의 인사를 논의할 것으로 알려졌다.\n",
      "  이르면 6일 개최될 수도 있다.\n",
      "  인사위가 열리면 그 이후로는 언제든 인사 발령이 이뤄질 수 있다.\n",
      " \n",
      "----------------------------------------------------------------------------------------------------\n",
      "idx_15 \n",
      "Summary before \n",
      " ‘탄소년단(BTS)부터 ‘트로트 여신’ 송가인까지 무한확\n",
      "Summary after \n",
      "  4 4일 서울 고척스카이돔에서 열린 제34회 골든디스크어워즈즈는 이틀간 120여 명의 스타가 모여 스타를 모여 명의스타가 모인 스타는 모여 ‘제 ‘대 ‘신 ‘ ‘이워 ‘한 ‘무 ‘아‘\n",
      "Target summary \n",
      " ‘기록제조기’ 방탄소년단(BTS)부터 ‘트로트 여신’ 송가인까지 무한확장 중인 K팝의 넓어진 면모를 한눈에 보여주는 무대였다. 4~5일 서울 고척스카이돔에서 열린 제34회 골든디스크어워즈는 이틀간 120여 명의 스타가 모여 성대한 축제를 펼쳤다. 방탄소년단은 음반과 디지털 음원 부문 모두 대상을 거머쥐었다. 2006년 대상을 두 부문으로 나눠서 시상한 이래 동시 수상은 이번이 처음이다. 3연속 미국 빌보드 정상을 차지한 방탄소년단은 한국 음반사도 새로 써내려갔다.\n",
      "Text ‘기록제조기’ 방탄소년단(BTS)부터 ‘트로트 여신’ 송가인까지 무한확장 중인 K팝의 넓어진 면모를 한눈에 보여주는 무대였다.\n",
      "  4~5일 서울 고척스카이돔에서 열린 제34회 골든디스크어워즈는 이틀간 120여 명의 스타가 모여 성대한 축제를 펼쳤다.\n",
      "  ◆인기상까지 6관왕 BTS=방탄소년단은 음반과 디지털 음원 부문 모두 대상을 거머쥐었다.\n",
      "  지난해 4월 발매한 미니앨범 ‘맵 오브 더 솔: 페르소나’로 369만장의 판매고를 기록한 이들은 3년 연속 ‘음반킹’의 자리를 지킨 데 이어 타이틀곡 ‘작은 것들을 위한 시’로 첫 ‘음원킹’의 영예를 안았다.\n",
      "  2006년 대상을 두 부문으로 나눠서 시상한 이래 동시 수상은 이번이 처음이다.\n",
      "  3연속 미국 빌보드 정상을 차지한 방탄소년단은 한국 음반사도 새로 써내려갔다.\n",
      "  1995년 김건모 3집(330만장) 이후 24년 만에 기네스 한국 기록을 경신한 데 이어 게임 OST ‘BTS 월드’ 등으로 한 해 동안 총 602만장을 팔아치웠다.\n",
      "  이는 지난해 전체 앨범 판매량 2459만장(12월 둘째 주 기준)의 29.\n",
      " 6%에 달하는 수치로 음반 시장의 성장을 견인했다.\n",
      "  2014년 신인상을 시작으로 6년 연속 본상 트로피를 챙긴 이들은 인기상 2개를 휩쓸며 최다 수상인 6관왕에 올랐다.\n",
      "  RM은 “10년 전 2010년 봄 방시혁 피디님을 처음 봤던 날이 기억난다”며 “2010년대는 방탄소년단의 이름이 가득 쓰여져 있었다면 2020년대는 아미의 이름으로 가득 찬 연대가 됐으면 좋겠다”고 소감을 밝혔다.\n",
      "  연일 불거지고 있는 사재기 논란을 겨냥한 듯 “2010년대의 잘못된 점은 2010년대에 끝내고, 2020년대에는 진심을 다해서 음악을 만드는 아티스트들의 노력이 헛되지 않게 대중에게 가닿고 공명할 수 있길 바란다”고 덧붙였다.\n",
      "  제작자상을 받은 빅히트엔터테인먼트 방시혁 대표는 “방탄소년단이 앞으로 더 큰 결실을 이뤄갈 것이라고 확신한다”며 “제작자로서 더 좋은 환경을 만들어가겠다”고 말했다.\n",
      "  총 10팀이 수상한 음반 본상에서는 보이그룹 간 경쟁이 치열했다.\n",
      "  갓세븐·몬스타엑스·세븐틴은 4년 연속 본상을 받았다.\n",
      "  특히 세븐틴은 3집 ‘언 오드’로 빌보드에서 ‘비평가가 선정한 2019년 최고의 K팝 앨범’ 1위에 오르는 등 차세대 주자로서 입지를 굳혔다.\n",
      "  엑소의 백현, 세훈&찬열은 각각 솔로와 듀엣 앨범으로 본상을 받는 저력을 보였다.\n",
      "  ◆태연·청하·제니…걸그룹 강세=트와이스는 4년 연속 본상을 수상하며 걸그룹의 저력을 과시했다.\n",
      " \n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(summaries_after_tuning)):\n",
    "    print('idx_{} '.format(i))\n",
    "    print(\"Summary before \\n\", summaries_before_tuning[i])\n",
    "    print(\"Summary after \\n\", summaries_after_tuning[i])\n",
    "    print(\"Target summary \\n\", test_samples[\"Summary\"][i])\n",
    "    print('Text', test_samples[\"Text\"][i])\n",
    "    print('-'*100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a935ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\n",
    "#     tabulate(\n",
    "#         zip(\n",
    "#             range(len(summaries_after_tuning)),\n",
    "#             summaries_after_tuning,\n",
    "#             summaries_before_tuning,\n",
    "#         ),\n",
    "#         headers=[\"Id\", \"Summary after\", \"Summary before\"]\n",
    "#     )\n",
    "# )\n",
    "# print(\"\\nTarget summaries:\\n\")\n",
    "# print(\n",
    "#     tabulate(list(enumerate(test_samples[\"Summary\"])), headers=[\"Id\", \"Target summary\"])\n",
    "# )\n",
    "# print(\"\\nSource documents:\\n\")\n",
    "# print(tabulate(list(enumerate(test_samples[\"Text\"])), headers=[\"Id\", \"Text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f624d705",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
